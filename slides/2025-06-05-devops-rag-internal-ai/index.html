<!doctype html><html lang=en><head><meta charset=utf-8><title>Workshop: RAG打造企業AI知識庫：把一甲子功力傳給新人</title><meta name=description content="學員將學會如何利用 RAG 技術，結合 OpenAI、LangChain、Qdrant 向量數據庫，構建企業內部文檔的智能知識庫，並能設計與實作一個基於自然語言處理（NLP）的查詢系統，來提升開發團隊的效率與知識管理能力。"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="black-translucent"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><link rel=stylesheet href=/reveal-js/dist/reset.css><link rel=stylesheet href=/reveal-js/dist/reveal.css><link rel=stylesheet href=/reveal-hugo/themes/robot-lung.css id=theme><link rel=stylesheet href=/highlight-js/color-brewer.min.css></head><body><div class=reveal><div class=slides><section><h3 id=rag-workshop-行前通知基本需求>RAG workshop 行前通知：基本需求</h3><ol><li>當天帶自己的電腦。當天建議自備手機網路</li><li>選項1: 用電腦在 docker 運行開發環境</li><li>選項2: 用電腦遠端連線講師提供的 VM，在遠端VM 中運行 docker 開發環境</li><li>會使用 docker</li><li>會使用 python 與 jupyter notebook</li></ol></section><section><h5 id=選項1-使用自己的電腦-computer>選項1: 使用自己的電腦 &#x1f4bb;</h5><p>在 workshop 開始前，在自己的電腦上</p><ol><li>安裝 <a href=https://docs.docker.com/get-started/get-docker/>docker</a></li><li>git clone 教材</li><li>啟動 docker 開發環境，下載 docker images</li><li>安裝所需的 Python 套件</li><li>開啟瀏覽器，連線到<a href=http://localhost:8888>http://localhost:8888</a></li><li>登入token=<code>workshop1234!</code></li></ol><pre><code class=language-bash>git clone https://github.com/chechiachang/rag-workshop.git
cd rag-workshop
docker compose up -d
docker exec -it notebook pip install pandas openai qdrant_client tqdm tenacity wget tenacity unstructured markdown ragas sacrebleu langchain_qdrant langchain-openai langchain_openai langchain_community tiktoken ipywidgets
</code></pre></section><section><h5 id=選項2-使用遠端-vm>選項2: 使用遠端 VM</h5><ol><li>有自己的電腦，當天建議自備手機網路，連線到遠端 VM</li><li>提前註冊 tunnel 工具（沒有業配）</li><li><a href=https://dashboard.ngrok.com/login>Ngrok</a> 登入 Login -> 左手邊 Identity & Access -> Authtokens -> Add Tunnel authtoken -> 記在安全的地方</li><li>也可以使用 <a href=https://pinggy.io/>Pinggy</a>，但免費有限時</li></ol></section><section><h3 id=建議>建議</h3><ol><li>優先使用個人電腦。會盡量提供免費 VM 名額，但依參與人數不保證現場有</li><li>在家先試跑一遍，把 docker image 跟 pip 套件都下載好，現場要載很久</li><li>試完後記得關掉 ngrok，以免用完每月的免費額度</li><li>事先看完內容覺得太簡單可以不用來，但歡迎會後找我聊天ＸＤ</li></ol></section><section><h3 id=投影片與教材與完整程式碼放在網站上>投影片與教材與完整程式碼放在網站上</h3><ul><li><a href=https://chechia.net>https://chechia.net</a></li><li><a href=https://chechia.net/zh-hant/slides/2025-06-05-devops-rag-internal-ai/>https://chechia.net/zh-hant/slides/2025-06-05-devops-rag-internal-ai/</a></li><li>&#x1f4dd; <a href=https://github.com/chechiachang/chechiachang.github.io-src/blob/master/content/zh-hant/slides/2025-06-05-devops-rag-internal-ai/index.md>Github 投影片原始碼與講稿</a></li></ul></section><section><h5 id=以下是-rag-workshop-當天內容>以下是 RAG Workshop 當天內容</h5><p>可以先看，也可以當天再看</p><p><img loading=lazy src=https://media.tenor.com/aRF-Uwyl0p8AAAAM/frozen2.gif></p></section><section><h3 id=rag-workshop>RAG Workshop</h3></section><section><h3 id=關於我>關於我</h3><ul><li>Che Chia Chang</li><li>SRE @ <a href=https://www.cake.me/companies/maicoin/jobs>Maicoin</a></li><li><a href=https://mvp.microsoft.com/zh-TW/MVP/profile/e407d0b9-5c01-eb11-a815-000d3a8ccaf5>Microsoft MVP</a></li><li>個人部落格<a href=https://chechia.net/>chechia.net</a> 投影片講稿，鐵人賽 (Terraform / Vault 手把手入門 / Etcd Workshop)</li><li>&#x1f4dd; <a href=https://github.com/chechiachang/chechiachang.github.io-src/blob/master/content/zh-hant/slides/2025-06-05-devops-rag-internal-ai/index.md>今天的投影片原始碼與講稿</a></li></ul></section><section><h3 id=rag-workshop-流程>RAG Workshop 流程</h3><ol><li>10min - <strong>環境設定：確定參與者都有設定好開發環境</strong></li><li>10min - 為什麼需要 RAG（Retrieval-Augmented Generation）</li><li>10min - Notebook 2 Embedding 與向量數據庫</li><li>10min - Notebook 3 Embedding Search</li><li>10min - Notebook 4 DIY</li><li>10min - Notebook 5 Evaluation</li><li>10min - Notebook 6 k8s RAG QA</li><li>20min - DIY + Q&amp;A</li></ol></section><section><h5 id=選項1-使用自己的電腦>選項1: 使用自己的電腦</h5><ol><li>有在家先試跑一遍，應該可以在本地存取 Notebook <a href=http://localhost:8888>http://localhost:8888</a></li><li>到 <a href=https://workshop.chechia.net>workshop.chechia.net</a> 取得 OpenAI Key</li><li>可以試著跑 notebook 2-5</li><li>忘記怎麼啟動，可以回到投影片最開始</li></ol><pre><code>notebook token: workshop1234!
AZURE_OPENAI_API_KEY=&quot;&quot;
AZURE_OPENAI_ENDPOINT=&quot;&quot;
</code></pre></section><section><h5 id=選項2-使用遠端-vm-1>選項2: 使用遠端 VM</h5><ol><li>至<a href=https://workshop.chechia.net>workshop.chechia.net</a> 領取一台 VM 並簽名</li><li>googel sheet 左邊 url，開啟 bastion 連線</li><li>Protocol: SSH，port 22，authentication type: password</li><li>帳號密碼在<a href=https://workshop.chechia.net>workshop.chechia.net</a></li></ol></section><section><p><img loading=lazy src=/slides/2025-06-05-devops-rag-internal-ai/azure-bastion.png></p></section><section><h5 id=選項2-使用-ngrok-連線到-jupyter-notebook>選項2: 使用 ngrok 連線到 jupyter notebook</h5><ol><li>進入 VM 後，修改下面 ngrok authtoken。指令一行一行貼上（右鍵）到 bastion 中執行</li><li>透過 <a href=https://4d11-52-230-24-207.ngrok-free.app/>https://4d11-52-230-24-207.ngrok-free.app/</a> 就可以使用 notebook (每個人不一樣)</li></ol><pre><code>cd rag-workshop
NGROK_AUTHTOKEN=&lt;改成你的token&gt;
sed -i &quot;s/your-token/$NGROK_AUTHTOKEN/&quot; docker-compose.yaml
docker compose up -d
docker logs ngrok

t=2025-06-02T06:17:41+0000 lvl=info msg=&quot;started tunnel&quot; obj=tunnels name=command_line addr=http://notebook:8888 url=https://4d11-52-230-24-207.ngrok-free.app
</code></pre></section><section><h3 id=以上是-workshop-環境設定>以上是 Workshop 環境設定</h3><ol><li>後面上課都透過這個網址操作</li><li>還沒有看到 jupyter notebook 的人，請舉手</li></ol></section><section><p><img loading=lazy src=https://miro.medium.com/v2/resize:fit:996/1*ByWkrjbyWmC9W_uWjI1qrw.gif></p></section><section><h3 id=rag-workshop-流程-1>RAG Workshop 流程</h3><ol><li>環境設定：確定參與者都有設定好開發環境</li><li><strong>為什麼需要 RAG（Retrieval-Augmented Generation）</strong></li><li>Embedding 與向量數據庫</li><li>Embedding Search</li><li>DIY</li><li>Evaluation</li><li>實際應用: 以 k8s official docs 為例</li><li>DIY + Q&amp;A</li></ol></section><section><h3 id=什麼是-rag>什麼是 RAG</h3><h5 id=ragretrieval-augmented-generation-檢索增強生成結合檢索系統與生成式模型如-gpt的自然語言處理架構在生成答案時引用外部知識使模型回答更準確且具事實根據>RAG（Retrieval-Augmented Generation 檢索增強生成）結合檢索系統與生成式模型（如 GPT）的自然語言處理架構，在生成答案時引用外部知識，使模型回答更準確且具事實根據</h5><ol><li><strong>Retrieval（檢索）：</strong> 從一個外部知識庫（如文件、向量資料庫等）中找到與問題相關的資訊。通常會用語意向量（embeddings）做相似度搜尋。</li><li><strong>Generation（生成）：</strong> 把檢索到的內容與使用者問題一起丟給 LLM（如 GPT、Claude 等）去生成答案。生成的內容會更具事實根據，並能引用具體資料。</li></ol></section><section><p><img loading=lazy src=https://cookbook.openai.com/images/llamaindex_rag_overview.png></p><p><a href=https://cookbook.openai.com/images/llamaindex_rag_overview.png>https://cookbook.openai.com/images/llamaindex_rag_overview.png</a></p></section><section><h3 id=知識獲取效率在-devops-的難題>知識獲取效率在 DevOps 的難題</h3><p>在快速變動、資訊分散的環境中，難以即時取得需要的知識。「有但找不到、看不懂、用不起來」</p><ol><li>知識分散在多個系統、格式與工具中</li><li>知識多為「靜態文件」，難以互動問答，舉例，或是換句話說</li><li>隱性知識未被系統化儲存(例如：口頭傳承、slack 討論、會議紀錄等)</li><li>查詢流程與開發流程脫節</li></ol></section><section><h3 id=情境新人工程師要如何到-k8s-doc-查到想要的內容>情境：新人工程師要如何到 k8s doc 查到想要的內容？</h3><ol><li>有問題去 google / stack overflow</li><li>需要搜尋引擎(k8s doc 有提供，但內部文件系統不一定有)</li><li>需要關鍵字(新人怎麼知道要查 Dynamic Persistent Volume Resizing)</li><li>協助理解（舉例，換句話說）</li><li>跨語言門檻</li></ol><aside class=notes><p>k8s doc 有提供關鍵字搜尋，這個搜尋功能是怎麼做的？
Programmable Search Engine（PSE）https://developers.google.com/custom-search/docs/tutorial/introduction
Fulltext Search Engine 例如 elasticsearch 使用 Lucene</p></aside></section><section><p><img loading=lazy src=https://www.wackybuttons.com/designcodes/0/110/1100986.png></p></section><section><p><img loading=lazy src=/slides/2025-06-05-devops-rag-internal-ai/search-in-k8s-official-doc.png></p><p><a href=https://kubernetes.io/search/>https://kubernetes.io/search/</a></p><aside class=notes></aside></section><section><h3 id=情境senior-工程師要如何分享知識>情境：Senior 工程師要如何分享知識？</h3><ol><li>『我有寫一篇文件在某個地方，你找一下』</li><li>『我忘記去年為什麼這樣做了』</li><li>『我去 Slack 上找一下』</li><li>『你要不要先去問 ChatGPT？』</li></ol><aside class=notes></aside></section><section><p><img loading=lazy src=https://ih1.redbubble.net/image.4690208405.0033/st,small,507x507-pad,600x600,f8f8f8.jpg></p><aside class=notes><p>我們不是懶，而是現在要解答許多基本問題，LLM 回答得比人好</p></aside></section><section><h3 id=rag-讓-devops-更智慧的即時反應>RAG 讓 DevOps 更智慧的即時反應</h3><ol><li>提升知識獲取效率: 內部文檔知識AI助手</li><li>知識留存與新人 Onboarding</li><li>加速故障排查: 根據錯誤訊息自動從 Runbook 中檢索處理方式</li><li>優化流程自動化與提升決策品質: 通訊軟體對話 bot，自動生成建議</li></ol></section><section><blockquote><p>DevOps AI Copilot 不應該像圖書館守門員等人來借書，
而應該像導航系統，在你開車時主動告訴你：前方有彎道。</p></blockquote><p>RAG + Context-Aware Knowledge Copilot</p><aside class=notes><p>基本上我們期待的解決方案是這樣</p></aside></section><section><h3 id=rag-vs-其他工具>RAG vs 其他工具</h3><ul><li>需要工具提升知識獲取效率，如何選擇 RAG 或是其他 non-LLM 工具？例如 search engine / fulltext search engine / search algorithm</li><li>特定任務的效能是否優於人類</li><li>哪裡適合用 RAG，哪裡適合用 non-LLM 工具</li></ul><aside class=notes><p>例如
google search engine 但當然我們不知道他背後的實作
elasticsearch / lucene / fulltext search engine
GNU grep 的 Boyer–Moore string-search algorithm</p></aside></section><section><p><img loading=lazy src=/slides/2025-06-05-devops-rag-internal-ai/rag-vs-code.png></p><aside class=notes><p>適合用 RAG 的情境：客服問答、技術搜尋、知識型 Chatbot、內部知識導航。
適合用傳統程式的情境：金流控制、流程引擎、帳務系統、安全控制。</p></aside></section><section><h3 id=有了大語言模型後>有了大語言模型後</h3><ol><li>去 google -> 先問 chatgpt，初步問答理解問題，找到關鍵字</li><li>需要搜尋引擎 -> chatgpt 整合，直接上網搜尋</li><li>需要關鍵字 -> chatgpt 幫你找到關鍵字</li><li>協助理解 -> chatgpt 舉例，換句話說</li><li>跨語言門檻 -> chatgpt 翻譯</li></ol><aside class=notes><p>chatgpt 會用通順的語言回答問題（優於平均工程師）</p></aside></section><section><ul><li>chatgpt 會用通順的語言，快速（數秒內）上網搜尋，回答問題</li><li>過程中不厭其煩地問答，換句話說</li><li>回答的格式高度客製化</li></ul></section><section><h5 id=llm-不具備專業知識缺乏內容根據時容易產生幻覺hallucination>LLM 不具備專業知識。缺乏內容根據時，容易產生幻覺(hallucination)</h5><p><img loading=lazy src=/slides/2025-06-05-devops-rag-internal-ai/llm-hallucination.png></p><aside class=notes><p>LLM（大型語言模型）本身並不具備事實知識，而是依賴訓練時的語料與提示輸入來生成回答。當缺乏明確上下文或內容根據時，LLM 容易出現「幻覺」現象，即生成看似合理但實際不正確的資訊。專業領域問題若未提供準確資料支撐，也容易導致錯誤回答。</p></aside></section><section><h3 id=rag-workshop-流程-2>RAG Workshop 流程</h3><ol><li>環境設定：確定參與者都有設定好開發環境</li><li>為什麼需要 RAG（Retrieval-Augmented Generation）<ol><li>RAG 在「文件檢索與提示」上優於人類</li><li>LLM 補強工程師的語言能力</li></ol></li><li><strong>Embedding 與向量數據庫</strong></li><li>Embedding Search</li><li>DIY</li><li>Evaluation</li><li>k8s RAG QA.ipynb</li></ol></section><section><h3 id=rag-workshop-流程-3>RAG Workshop 流程</h3><ol><li>確定參與者都有跑一套RAG起來</li><li><strong>Evaluation</strong></li><li>k8s RAG QA.ipynb</li></ol></section><section><h3 id=如何評估-rag-系統的品質>如何評估 RAG 系統的品質?</h3><ol><li>人人都會下 prompt，但是誰的 prompt 更好？或是沒差別？</li><li>如何選擇 vector store 的 chunking 策略？</li><li>哪個 retriever 更好？</li><li>要如何持續改善 RAG 系統？下個迭代的改善方向是什麼？</li><li>是否符合 production criteria？</li></ol></section><section><h3 id=評估確保回答品質可靠性與可控性>評估：確保回答品質可靠性與可控性</h3><ol><li>保證正確性：檢索出的資訊是正確的，生成的答案忠實於原始 context</li><li>降低幻覺風險：即使有資料，LLM 仍可能亂編</li><li>測量系統品質</li><li>改善依據：幫助驗證Chunking 策略，Prompt 設計，Retriever 模型調整</li><li>自動化監控：品質追蹤、問題定位，建立類似 APM 的 QA 指標</li><li>對 Stakeholder 展示成效：可視化與量化指標，有助溝通與資源投入</li></ol><aside class=notes><p>評估方式建議</p><ul><li>Retrieval：Recall@K, MRR, nDCG</li><li>Generation：ROUGE, BERTScore, GPTScore</li><li>Faithfulness：依據來源資料生成？</li><li>人工標註：相關性、正確性、幫助程度</li></ul></aside></section><section><h3 id=rag-應用-以-k8s-official-docs-為例>RAG 應用: 以 k8s official docs 為例</h3></section><section><h3 id=總結>總結</h3><ol><li>為什麼需要 RAG</li><li>Embedding 與向量數據庫</li><li>Embedding Search</li><li>DIY</li><li>Evaluation</li><li>k8s RAG QA</li></ol></section><section><h5 id=由衷地感謝為-workshop-提供協助的夥伴>由衷地感謝為 workshop 提供協助的夥伴!</h5><p><a href=https://github.com/pymia>Mia // Huai-Wen Chang</a></p><p><a href=https://github.com/hunkue>hunkue</a></p></section><section><h3 id=maicoin-we-are-hiring>MaiCoin: We are Hiring!!</h3><ul><li><a href=https://www.linkedin.com/jobs/view/4236558674/>Senior Site Reliability Engineer</a></li><li><a href=https://www.linkedin.com/jobs/view/4236555801>Senior Data Engineer</a></li><li><a href=https://www.linkedin.com/jobs/view/4236555811>Senior IT Engineer</a></li><li><a href=https://www.linkedin.com/jobs/view/4236556713>Blockchain Engineer (Wallet Team)</a></li><li><a href=https://www.linkedin.com/jobs/view/4236558714>Senior Backend Engineer</a></li><li><a href=https://www.linkedin.com/jobs/view/4236523560/>Micro Service Software Engineer</a></li><li><a href=https://www.linkedin.com/jobs/view/4236559632>Cyber Security Engineer</a></li></ul></section><section><h3 id=diy--qa--建議>DIY + Q&amp;A + 建議</h3><ol><li>下次會改用 Colab</li></ol></section></div></div><script type=text/javascript src=/reveal-hugo/object-assign.js></script><script src=/reveal-js/dist/reveal.js></script><script type=text/javascript src=/reveal-js/plugin/markdown/markdown.js></script><script type=text/javascript src=/reveal-js/plugin/highlight/highlight.js></script><script type=text/javascript src=/reveal-js/plugin/zoom/zoom.js></script><script type=text/javascript src=/reveal-js/plugin/notes/notes.js></script><script type=text/javascript>function camelize(e){return e&&Object.keys(e).forEach(function(t){newK=t.replace(/(_\w)/g,function(e){return e[1].toUpperCase()}),newK!=t&&(e[newK]=e[t],delete e[t])}),e}var revealHugoDefaults={center:!0,controls:!0,history:!0,progress:!0,transition:"slide"},revealHugoSiteParams={},revealHugoPageParams={custom_theme:"reveal-hugo/themes/robot-lung.css",highlight_theme:"color-brewer",margin:.2,templates:{hotpink:{background:"#FF4081",class:"hotpink"}},transition:"slide",transition_speed:"fast"},revealHugoPlugins={plugins:[RevealMarkdown,RevealHighlight,RevealZoom,RevealNotes]},options=Object.assign({},camelize(revealHugoDefaults),camelize(revealHugoSiteParams),camelize(revealHugoPageParams),camelize(revealHugoPlugins));Reveal.initialize(options)</script><script type=text/javascript src=/mermaid.min_16862243754454536095.js></script><script type=text/javascript>mermaid.initialize({startOnLoad:!1});let render=e=>{let t=e.currentSlide.querySelectorAll(".mermaid");if(!t.length)return;t.forEach(e=>{let t=e.getAttribute("data-processed");t||mermaid.init(0[0],e)})};render({currentSlide:Reveal.getCurrentSlide()}),Reveal.on("slidechanged",render),Reveal.on("ready",render)</script></body></html>