<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>redis on Che-Chia Chang</title>
    <link>https://chechia.net/tags/redis/</link>
    <description>Recent content in redis on Che-Chia Chang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>chechiachang &amp;copy; 2016</copyright>
    <lastBuildDate>Mon, 07 Oct 2019 08:12:10 +0800</lastBuildDate>
    
	    <atom:link href="https://chechia.net/tags/redis/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus &amp; Kubernetes State Metrics Exporter</title>
      <link>https://chechia.net/post/prometheus-kube-state-metrics-exporter/</link>
      <pubDate>Mon, 07 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/prometheus-kube-state-metrics-exporter/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus / Grafana (5)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deployment-on-kubernetes/&#34;&gt;GKE 上自架 Prometheus / Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GKE 上自架 Grafana 與設定&lt;/li&gt;
&lt;li&gt;使用 exporter 監測 GKE 上的各項服務&lt;/li&gt;
&lt;li&gt;輸出 redis-ha 的監測數據&lt;/li&gt;
&lt;li&gt;Node Exporter 與 kube metrics exporter&lt;/li&gt;
&lt;li&gt;輸出 kafka 的監測數據&lt;/li&gt;
&lt;li&gt;自幹 exporter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;如果要透過 prometheus 來監控集群的運行狀況，有兩個 exporter 是必裝的，一個是把 node 狀態 export 出來的 node exporter，一個是把 kubernetes 集群狀態 export 出來的 kube state metrics exporter。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Node Exporter 簡介&lt;/li&gt;
&lt;li&gt;kube metrics exporter 安裝與設定&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;node-exporter&#34;&gt;Node Exporter&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/prometheus/node_exporter&#34;&gt;Node Exporter&lt;/a&gt; 是 prometheus 官方維護的一個子項目，主要在把類 unix 硬體 kernel 的 metrics 送出來。官方也支援 windows node 與 nvidia gpu metrics，可以說是功能強大。&lt;/p&gt;
&lt;p&gt;為了能夠監測 kubernetes node 的基礎設施狀態，通常都會使用 node exporter。&lt;/p&gt;
&lt;p&gt;node exporter 安裝，我們在安裝 prometheus helm chart 時就一並安裝了。這邊看一下設定與運行。&lt;/p&gt;
&lt;h1 id=&#34;collectors&#34;&gt;Collectors&lt;/h1&gt;
&lt;p&gt;Node exporter 把不同位置收集到的不同類型的 metrics ，做成各自獨立的 colletor，使用者可以根據求需求來啟用或是不啟用 collector，&lt;a href=&#34;https://github.com/prometheus/node_exporter#enabled-by-default&#34;&gt;完整的 collector 目錄&lt;/a&gt; 在這邊。&lt;/p&gt;
&lt;p&gt;如果有看我們第一部份的 ELK part，應該會覺得這裡的設定，跟 metricbeat 非常像，基本上這兩者做的事情是大同小異的，收集 metrics 來源都是同樣的類 unix 系統，只是往後送的目標不一樣 (雖然現在兩者都可以兼容混搭了)。如果有接觸過其他平台的 metrics collector，也會發現其實大家做的都差不多。&lt;/p&gt;
&lt;h1 id=&#34;textfile-collector&#34;&gt;Textfile Collector&lt;/h1&gt;
&lt;p&gt;Prometheus 除了有 scrape 機制，讓 prometheus 去 exporter 撈資料外，還有另外一個機制，叫做 &lt;a href=&#34;https://github.com/prometheus/pushgateway&#34;&gt;Pushgateway&lt;/a&gt;，這個我們在部屬 prometheus 時也部屬了一個。這邊簡單說明一下。&lt;/p&gt;
&lt;p&gt;經常性執行的服務(redis, kafka,&amp;hellip;)會一直運行，prometheus 透過這些服務的 metrics 取得 runtime metrics，作為監控資料。可是有一些 job 是暫時性的任務，例如果一個 batch job，這些服務不會有一直運行的 runtime metrics，也不會有 exporter。但這時又希望監控這些 job 的狀態，就可以使用 Pushgateway。&lt;/p&gt;
&lt;p&gt;Pushgateway 的作用機制，就是指定收集的目標資料夾，需要監測的 batch job，只要把希望監測的資料，寫到該資料夾。Pushgateway 會依據寫入的資料，轉成 time series metrics，並且 export 出來。&lt;/p&gt;
&lt;p&gt;這種去 tail 指定目錄檔案，然後把 metrics 後送的機制，是否跟 filebeat 有一點類似? 只是 filebeat 一般取得資料後，會主動推送到 ELK 上，prometheus pushgateway 會暴露出 metrics 後，讓 prometheus server 來 scrape。&lt;/p&gt;
&lt;p&gt;Pushgateway 也會在收集資料時打上需要的 label，方面後段處理資料。&lt;/p&gt;
&lt;h1 id=&#34;kubernetes-state-metrics-exporter&#34;&gt;Kubernetes State Metrics (Exporter)&lt;/h1&gt;
&lt;p&gt;Node Exporter 將 kubernetes 集群底下的 Node 的硬體狀態，例如 cpu, memory, storage,&amp;hellip; expose 出來，然而我們在維運 kubernetes 還需要從 api server 獲得集群內部的資料，例如說 pod state, container state, endpoints, service, &amp;hellip;等，這邊可以使用 kube-state-metrics 來處理。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics&#34;&gt;kube-state-metrics&lt;/a&gt; 是 kubernetes 官方維護的專案，做的事情就是向 api server 詢問 kubernetes 的 state，例如 pod state, deployment state，然後跟 prometheus exporter 一，開放一個 http endpoint，讓需要的服務來 scrape metrics。&lt;/p&gt;
&lt;p&gt;工作雲裡也很單純，kubernetes api server 可以查詢 pod 當下的狀態，kube-state-metrics 則會把當下的狀態依照時間序，做成 time series 的 metrics，例如這個 pod 什麼時候是活著，什麼時候因為故障而 error。&lt;/p&gt;
&lt;p&gt;kube-state-metrics 預設的輸出格式是 plaintext，直接符合 Prometheus client endpoint 的格式&lt;/p&gt;
&lt;h1 id=&#34;deployment&#34;&gt;Deployment&lt;/h1&gt;
&lt;p&gt;如果依照第一篇安裝 prometheus helm 的步驟，現在應該已經安裝完 kube-state-metrics 了。如果沒有安裝，也可以依照官方說明的基本範例安裝。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone git@github.com:kubernetes/kube-state-metrics.git

cd kube-state-metrics

kubectl apply -f examples/standard/*.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安裝完可以看到&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get pods --selector &#39;app=prometheus,component=kube-state-metrics&#39;

NAME                                             READY   STATUS    RESTARTS   AGE
prometheus-kube-state-metrics-85f6d75f8b-7vlkp   1/1     Running   0          201d

$ kubectl get svc --selector &#39;app=prometheus,component=kube-state-metrics&#39;

NAME                            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
prometheus-kube-state-metrics   ClusterIP   None         &amp;lt;none&amp;gt;        80/TCP    201d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我們可以透過 service 打到 pod 的 /metrics 來取得 metrics。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl exec -it busybox sh

curl prometheus-kube-state-metrics:8080
&amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Kube Metrics Server&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
    &amp;lt;h1&amp;gt;Kube Metrics&amp;lt;/h1&amp;gt;
    &amp;lt;ul&amp;gt;
    	&amp;lt;li&amp;gt;&amp;lt;a href=&#39;https://chechia.net/metrics&#39;&amp;gt;metrics&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
    	&amp;lt;li&amp;gt;&amp;lt;a href=&#39;https://chechia.net/healthz&#39;&amp;gt;healthz&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;
    &amp;lt;/ul&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;

curl prometheus-kube-state-metrics:8081

&amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Kube-State-Metrics Metrics Server&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
    &amp;lt;h1&amp;gt;Kube-State-Metrics Metrics&amp;lt;/h1&amp;gt;
    &amp;lt;ul&amp;gt;
    	&amp;lt;li&amp;gt;
			&amp;lt;a href=&#39;https://chechia.net/metrics&#39;&amp;gt;metrics&amp;lt;/a&amp;gt;
		&amp;lt;/li&amp;gt;
    &amp;lt;/ul&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;這邊有兩套 metrics，一個是 kube-state-metrics 自己自我監測的 metrics，在 8081，另外一個才是 kube metrics，在 8080，兩個都要收，記得不要收錯了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl prometheus-kube-state-metrics:8080/metrics

打下去就可以看到超多 metrics 。
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics/tree/master/docs&#34;&gt;Metrics 的清單與說明文件&lt;/a&gt;，有用到的 metrics 使用前都可以來查一下定義解釋。&lt;/p&gt;
&lt;p&gt;理論上不用每個 metrics 都 expose 出來，有需要可以把不會用到的 metrics 關一關，可以節省 kube-state-metrics 的 cpu 消耗。&lt;/p&gt;
&lt;h1 id=&#34;resource-recommendation&#34;&gt;Resource Recommendation&lt;/h1&gt;
&lt;p&gt;kube-state-metrics 很貼心的還附上&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics#scaling-kube-state-metrics&#34;&gt;建議的資源分配&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;As a general rule, you should allocate

200MiB memory
0.1 cores
For clusters of more than 100 nodes, allocate at least

2MiB memory per node
0.001 cores per node
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;scaling&#34;&gt;Scaling&lt;/h1&gt;
&lt;p&gt;kube-state-metrics 還有提供 horizontal scaling 的解決方案，如果你的集群很大，node 數量已經讓 kube-state-metrics 無法負荷，也可以使用 sharding 的機制，把 metrics 的工作散布到多個 kube-state-metrics，再讓 prometheus 去收集統整。這部分我覺得很有趣，但還沒實作過，我把&lt;a href=&#34;https://github.com/kubernetes/kube-state-metrics#horizontal-scaling-sharding&#34;&gt;文件&lt;/a&gt; 放在這邊，有緣大德有時做過請來討論分享。&lt;/p&gt;
&lt;h1 id=&#34;dashboard&#34;&gt;Dashboard&lt;/h1&gt;
&lt;p&gt;metrics 抓出來，當然要開一下 dashboard，這邊使用的是這個&lt;a href=&#34;https://grafana.com/grafana/dashboards/7249&#34;&gt;kubernetes cluster&lt;/a&gt;，支援&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;node exporter&lt;/li&gt;
&lt;li&gt;kube state metrics&lt;/li&gt;
&lt;li&gt;nginx ingress controller&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三個願望一次滿足~&lt;/p&gt;
&lt;h1 id=&#34;小結&#34;&gt;小結&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;跑 kubernetes 務必使用這兩個 exporter&lt;/li&gt;
&lt;li&gt;kube-state-metrics 整理得很舒服，有時間可以多看看這個專案&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Prometheus Exporter Library &amp; Redis Exporter</title>
      <link>https://chechia.net/post/prometheus-exporter-library-redis-exporter/</link>
      <pubDate>Sun, 06 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/prometheus-exporter-library-redis-exporter/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus / Grafana (5)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deployment-on-kubernetes/&#34;&gt;GKE 上自架 Prometheus / Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GKE 上自架 Grafana 與設定&lt;/li&gt;
&lt;li&gt;使用 exporter 監測 GKE 上的各項服務&lt;/li&gt;
&lt;li&gt;輸出 redis-ha 的監測數據&lt;/li&gt;
&lt;li&gt;自幹 exporter&lt;/li&gt;
&lt;li&gt;輸出 kafka 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 kubernetes 的監測數據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Exporter 工作原理簡介&lt;/li&gt;
&lt;li&gt;Prometheus exporter library&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;exporter-workflow&#34;&gt;Exporter workflow&lt;/h1&gt;
&lt;p&gt;上次講到 exporter 可以從服務端把運行資料抽出來，並開成 http endpoint，讓 prometheus 來 scrape metrics。那 exporter 本身是如何取得服務內部的 metrics 呢? 我們今天就稍微看一下。&lt;/p&gt;
&lt;h1 id=&#34;redis-exporter&#34;&gt;Redis Exporter&lt;/h1&gt;
&lt;p&gt;我們今天以 &lt;a href=&#34;https://github.com/oliver006/redis_exporter&#34;&gt;Redis Exporter&lt;/a&gt; 為例，研究一下外部的 exporter 是如何取得 redis 內部的 metrcs。&lt;/p&gt;
&lt;p&gt;Redis exporter 是用 golang 寫的一個小程式，總共算算才 1000 行，而且很多都是對 redis 內部 metrics 的清單，以及轉化成 prometheus metrics 的 tool functions，主要的邏輯非常簡單。我們簡單看一下源碼。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/oliver006/redis_exporter/blob/master/exporter.go#L386&#34;&gt;Collect&lt;/a&gt; 是主要的收集邏輯，就是執行 scrapeRedisHost(ch) ，然後把收集到的資訊，使用 &lt;a href=&#34;https://github.com/prometheus/client_golang&#34;&gt;Prometheus Go Client Library&lt;/a&gt; 的工具將資料註冊成 prometheus metrics&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func (e *Exporter) Collect(ch chan&amp;lt;- prometheus.Metric) {
	e.Lock()
	defer e.Unlock()
	e.totalScrapes.Inc()

	if e.redisAddr != &amp;quot;&amp;quot; {
		start := time.Now().UnixNano()
		var up float64 = 1

    // 從 host scrape 資料，然後塞進 channel streaming 出來。
		if err := e.scrapeRedisHost(ch); err != nil {
			up = 0
			e.registerConstMetricGauge(ch, &amp;quot;exporter_last_scrape_error&amp;quot;, 1.0, fmt.Sprintf(&amp;quot;%s&amp;quot;, err))
		} else {
			e.registerConstMetricGauge(ch, &amp;quot;exporter_last_scrape_error&amp;quot;, 0, &amp;quot;&amp;quot;)
		}

		e.registerConstMetricGauge(ch, &amp;quot;up&amp;quot;, up)
		e.registerConstMetricGauge(ch, &amp;quot;exporter_last_scrape_duration_seconds&amp;quot;, float64(time.Now().UnixNano()-start)/1000000000)
	}

	ch &amp;lt;- e.totalScrapes
	ch &amp;lt;- e.scrapeDuration
	ch &amp;lt;- e.targetScrapeRequestErrors
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;scrapeRedisHost 內部的主要邏輯，又集中在&lt;a href=&#34;https://github.com/oliver006/redis_exporter/blob/master/exporter.go#L1144&#34;&gt;執行 Info&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  // 執行 info 
	infoAll, err := redis.String(doRedisCmd(c, &amp;quot;INFO&amp;quot;, &amp;quot;ALL&amp;quot;))
	if err != nil {
		infoAll, err = redis.String(doRedisCmd(c, &amp;quot;INFO&amp;quot;))
		if err != nil {
			log.Errorf(&amp;quot;Redis INFO err: %s&amp;quot;, err)
			return err
		}
	}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也就是說當我們在 redis-cli 連入 redis 時，可以執行 Info command，取得 redis 內部的資訊，包含節點設店與狀態，集群設定，資料的統計數據等等。然後 exporter 這邊維護持續去向 redis 更新 info ，並且把 info data 轉化成 time series 的 metrcs，再透過 &lt;a href=&#34;https://github.com/prometheus/client_golang/tree/master/prometheus/promhttp&#34;&gt;Prometheus Client promhttp&lt;/a&gt; 提供的 http endpoint library，變成 http endpoint。&lt;/p&gt;
&lt;p&gt;首先看一下 &lt;a href=&#34;https://redis.io/commands/info&#34;&gt;redis info command 的文件&lt;/a&gt;，這邊有說明 info 的 option ，以及 option 各自提供的資料，包括 server 狀態，賀戶端連線狀況，系統資源，複本狀態等等。我們也可以自己透過 info 取得資料。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl get po | grep redis

redis-2-redis-ha-server-0                                3/3     Running     0          11d
redis-2-redis-ha-server-1                                3/3     Running     0          11d
redis-2-redis-ha-server-2                                3/3     Running     0          11d

$ kubectl exec -it redis-2-redis-ha-server-0  sh
$ redis-cli -h haproxy-service  -a REDIS_PASSWORD
$ haproxy-service:6379&amp;gt;

$ haproxy-service:6379&amp;gt; info server
# Server
redis_version:5.0.5
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:4d072dc1c62d5672
redis_mode:standalone
os:Linux 4.14.127+ x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:8.3.0
process_id:1
run_id:63a97460b7c3745577931dad406df9609c4e2464
tcp_port:6379
uptime_in_seconds:976082
uptime_in_days:11
...

$ haproxy-service:6379&amp;gt; info clients
# Clients
connected_clients:100
client_recent_max_input_buffer:2
client_recent_max_output_buffer:0
blocked_clients:1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Redis exporter 收集這些數據，透過 prometheus client library 把資料轉成 time series prometheus metrics。然後透過 library 放在 http enpoint 上。&lt;/p&gt;
&lt;p&gt;配合上次說過的 redis overview dashboard，可以直接在 Grafana 上使用&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cloud.githubusercontent.com/assets/1222339/19412031/897549c6-92da-11e6-84a0-b091f9deb81d.png&#34; alt=&#34;Redis Overvies library&#34;&gt;&lt;/p&gt;
&lt;p&gt;這邊 dashboard 顯示幾個重要的 metrics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uptime&lt;/li&gt;
&lt;li&gt;Memory Usage，要設定用量太高自動報警&lt;/li&gt;
&lt;li&gt;Command 的執行狀況，回應時間&lt;/li&gt;
&lt;li&gt;訊息的流量，以及超出 time-to-live 的資料清除。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都是需要好好加上 alert 的核心 metrics&lt;/p&gt;
&lt;h1 id=&#34;貢獻-exporter&#34;&gt;貢獻 exporter&lt;/h1&gt;
&lt;p&gt;其他服務的 exporter 工作原理也相似，如果服務本身有內部的 metrics，可以透過 client command 或是 API 取得，exporter 的工作就只是轉成 time series data。&lt;/p&gt;
&lt;p&gt;如果有比較特殊的 metrics 沒有匯出，例如說自家的 metrics ，但又希望能放到 prometheus 上監測，例如每秒收到多少 request count，回應速度，錯誤訊息的統計&amp;hellip;&amp;hellip;等，這點也可以使用 client library 自幹 exporter 然後 expose http endpoint，這樣在 prometheus 上也可以看到自家產品的 metrics，非常好用。有機會我們來聊自幹 exporter。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prometheus Deployment on Kubernetes</title>
      <link>https://chechia.net/post/prometheus-deployment-on-kubernetes/</link>
      <pubDate>Fri, 04 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/prometheus-deployment-on-kubernetes/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus / Grafana (5)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deployment-on-kubernetes/&#34;&gt;GKE 上自架 Prometheus / Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deploy-grafana/&#34;&gt;GKE 上自架 Grafana 與設定&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;使用 exporter 監測 GKE 上的各項服務&lt;/li&gt;
&lt;li&gt;輸出 kubernetes 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 redis-ha 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 kafka 的監測數據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus Introduction&lt;/li&gt;
&lt;li&gt;Deploy Prometheus&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;prometheus-introduction&#34;&gt;Prometheus Introduction&lt;/h1&gt;
&lt;p&gt;生產環境與非生產環境，其中的一指標就是有沒有足夠完整的服務監測系統，這句話可以看出服務監測對於產品化是多麼重要。而監控資料 (metrics) 的收集與可視化工具其實非常多，例如上周介紹的 ELK Stack，這次我們要來介紹另外一個很多人使用的 prometheus。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://prometheus.io/&#34;&gt;Promethues 在官網上提到&lt;/a&gt; 是一個 Monitoring system and time series database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以收集高維度的資料&lt;/li&gt;
&lt;li&gt;使用自己的 PromQL 做有效且精簡的資料查詢&lt;/li&gt;
&lt;li&gt;內建資料瀏覽器，並且與 Grafana 高度整合&lt;/li&gt;
&lt;li&gt;支援 sharding 與 federation，來達到水平擴展&lt;/li&gt;
&lt;li&gt;有許多隨插即用的整合 exporter，例如 redis-exporter, kafka-exporter，kubernetes-exporter ，都可以直接取得資料&lt;/li&gt;
&lt;li&gt;支援 alert，使用 PromQL 以及多功能的告警，可以設定精準的告警條件&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;與-elk-做比較&#34;&gt;與 ELK 做比較&lt;/h1&gt;
&lt;p&gt;基本上 Prometheus 跟 ELK 比，其實是很奇怪的一件事，但這也是最常被問的一個問題。兩者在本質上是完全不同的系統。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus 是 based on time series database 的資料收集系統&lt;/li&gt;
&lt;li&gt;ELK 是基於全文搜索引擎的資料查詢系統&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是的，他們都能做 metrics 收集，在有限的尺度下，能達到一樣的效果。但這樣說的意思就等於是在說 mesos DC/OS 與 kubenetes 都能跑 container cluster 一樣，底下是完全不一樣的東西。&lt;/p&gt;
&lt;p&gt;兩者的差異使用上差非常多&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;metrics 結構: ELK 借助全文搜索引擎，基本上送什麼資料近來都可以查找。Prometheus metrics 拉進來是 time series 的 key-value pairs。&lt;/li&gt;
&lt;li&gt;維護同樣的 metrics，prometheus 的使用的儲存空間遠小於 elasticsearch&lt;/li&gt;
&lt;li&gt;prometheus 針對 time based 的搜尋做了很多優化，效能很高&lt;/li&gt;
&lt;li&gt;Prometheus 對於記憶體與 cpu 的消耗也少很多&lt;/li&gt;
&lt;li&gt;Elasticsearch 資源上很貴，是因為在處理大量 text log 的時候，他能夠用後段的 pipeline 處理內容，再進行交叉比對，可以從 text 裡面提取很多未事先定義的資料&lt;/li&gt;
&lt;li&gt;Elasticsearch 的維護工作也比較複雜困難&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果要收集服務運行資料，可以直接選 prometheus。如果有收集 log 進行交叉比對，可以考慮 elk。&lt;/p&gt;
&lt;h3 id=&#34;helm&#34;&gt;Helm&lt;/h3&gt;
&lt;p&gt;我們這邊用 helm 部屬，之所以用 helm ，因為這是我想到最簡單的方法，能讓輕鬆擁有一套功能完整的 prometheus。所以我們先用。&lt;/p&gt;
&lt;p&gt;沒用過 helm 的大德可以參考 &lt;a href=&#34;https://helm.sh/docs/using_helm/#quickstart&#34;&gt;Helm Quickstart&lt;/a&gt;，先把 helm cli 與 kubernetes 上的 helm tiller 都設定好&lt;/p&gt;
&lt;h1 id=&#34;deploy-prometheus&#34;&gt;Deploy Prometheus&lt;/h1&gt;
&lt;p&gt;我把我的寶藏都放在這了&lt;a href=&#34;https://github.com/chechiachang/prometheus-kubernetes&#34;&gt;https://github.com/chechiachang/prometheus-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下載下來的 .sh ，跑之前養成習慣貓一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat install.sh

#!/bin/bash
HELM_NAME=prometheus-1

helm upgrade --install ${HELM_NAME} stable/prometheus \
  --namespace default \
  --values values-staging.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;configuration&#34;&gt;Configuration&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/prometheus&#34;&gt;Prometheus Stable Chart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;values.yaml 很長，但其實各個元件設定是重複的,設定好各自的 image,
replicas, service, topology 等等&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alertmanager:
  enabled: true

kubeStateMetrics:
  enabled: true

nodeExporter:
  enabled: true

server:
  enabled: true

pushgateway:
  enabled: true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;底下有更多 runtime 的設定檔&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;定義好 global 的 scrape 間距，越短 metrics 維度就越精準&lt;/li&gt;
&lt;li&gt;PersistenVolume 強謝建議開起來，維持歷史的資料
&lt;ul&gt;
&lt;li&gt;加上 storage usage 的 self monitoring（之後會講) 才不會滿出來 server 掛掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;server 的 scrapeConfigs 是 server 去收集的 job 設定。稍後再來細講。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;server:
  global:
    ## How frequently to scrape targets by default
    ##
    scrape_interval: 10s
    ## How long until a scrape request times out
    ##
    scrape_timeout: 10s
    ## How frequently to evaluate rules
    ##
    evaluation_interval: 10s
  persistentVolume:
    ## If true, Prometheus server will create/use a Persistent Volume Claim
    ## If false, use emptyDir
    ##
    enabled: true

    ## Prometheus server data Persistent Volume access modes
    ## Must match those of existing PV or dynamic provisioner
    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    accessModes:
      - ReadWriteOnce

    ## Prometheus server data Persistent Volume annotations
    ##
    annotations: {}

    ## Prometheus server data Persistent Volume existing claim name
    ## Requires server.persistentVolume.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    existingClaim: &amp;quot;&amp;quot;

    ## Prometheus server data Persistent Volume mount root path
    ##
    mountPath: /data

    ## Prometheus server data Persistent Volume size
    ##
    size: 80Gi

alertmanagerFiles:

serverFiles:

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;部屬完看一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get pods --selector=&#39;app=prometheus&#39;

NAME                                             READY   STATUS    RESTARTS   AGE
prometheus-alertmanager-694d6694c6-dvkwd         2/2     Running   0          8d
prometheus-kube-state-metrics-85f6d75f8b-7vlkp   1/1     Running   0          8d
prometheus-node-exporter-2mpjc                   1/1     Running   0          8d
prometheus-node-exporter-kg7fj                   1/1     Running   0          51d
prometheus-node-exporter-snnn5                   1/1     Running   0          8d
prometheus-pushgateway-5cdfb4979c-dnmjn          1/1     Running   0          8d
prometheus-server-59b8b8ccb4-bplkx               2/2     Running   0          8d

kubectl get services --selector=&#39;app=prometheus&#39;

NAME                            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
prometheus-alertmanager         ClusterIP   10.15.241.66   &amp;lt;none&amp;gt;        80/TCP     197d
prometheus-kube-state-metrics   ClusterIP   None           &amp;lt;none&amp;gt;        80/TCP     197d
prometheus-node-exporter        ClusterIP   None           &amp;lt;none&amp;gt;        9100/TCP   197d
prometheus-pushgateway          ClusterIP   10.15.254.0    &amp;lt;none&amp;gt;        9091/TCP   197d
prometheus-server               ClusterIP   10.15.245.10   &amp;lt;none&amp;gt;        80/TCP     197d

kubectl get endpoints --selector=&#39;app=prometheus&#39;

NAME                            ENDPOINTS                                             AGE
prometheus-alertmanager         10.12.6.220:9093                                      197d
prometheus-kube-state-metrics   10.12.6.222:8080                                      197d
prometheus-node-exporter        10.140.0.30:9100,10.140.0.9:9100,10.140.15.212:9100   197d
prometheus-pushgateway          10.12.6.211:9091                                      197d
prometheus-server               10.12.3.14:9090                                       197d
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;簡單說明一下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;prometheus-server 是主要的 api-server 以及 time series database&lt;/li&gt;
&lt;li&gt;alertmanager 負責告警工作&lt;/li&gt;
&lt;li&gt;pushgateway 提供 client 端主動推送 metrics 給 server 的 endpoint&lt;/li&gt;
&lt;li&gt;kube-state-metrics 是開來收集 cluster wide 的 metrics, 像是 pods running counts, deployment ready count, total pods number 等等 metrics&lt;/li&gt;
&lt;li&gt;node-exporter 是 daemonsets, 把每一個 node 的 metrics, 像是 memory, cpu, disk&amp;hellip;等資料,收集出來&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要服務存取就是透過 prometheus-server&lt;/p&gt;
&lt;h1 id=&#34;access-prometheus-server&#34;&gt;Access Prometheus server&lt;/h1&gt;
&lt;p&gt;除了直接 exec -it 進去 prometheus-server 以外，由於 prometheus 本身有提供 web portal, 所以我們這邊透過 port forwarding 打到本機上&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PROMETHEUS_POD_NAME=$(kc get po -n default --selector=&#39;app=prometheus,component=server&#39; -o=jsonpath=&#39;{.items[0].metadata.name}&#39;)

kubectl --namespace default port-forward ${PROMETHEUS_POD_NAME} 9090
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;透過 browser 就可以連入操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://localhost:9090
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也可以透過 &lt;a href=&#34;https://prometheus.io/docs/prometheus/latest/querying/api/&#34;&gt;HTTP API&lt;/a&gt; 用程式接入控制&lt;/p&gt;
&lt;h1 id=&#34;prometheus-web&#34;&gt;Prometheus Web&lt;/h1&gt;
&lt;p&gt;Prometheus 本慎提供的 UI 其實功能就很強大&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以查到 (已經匯入存在) 的 metrics&lt;/li&gt;
&lt;li&gt;可以在上面執行 PromQL 查詢語法&lt;/li&gt;
&lt;li&gt;查詢運行的 status&lt;/li&gt;
&lt;li&gt;查詢目前所有收集的 targets 的狀態,有收集器掛了也可以在這邊看到&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;小結&#34;&gt;小結&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;輕鬆自架 prometheus&lt;/li&gt;
&lt;li&gt;Prometheus 頁面有精簡，但是功能完整的 graph 製圖&lt;/li&gt;
&lt;li&gt;但大家通常會使用 Grafana 搭配使用, 用過都說讚, 我們明天繼續&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Prometheus Deploy Grafana</title>
      <link>https://chechia.net/post/prometheus-deploy-grafana/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/prometheus-deploy-grafana/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus / Grafana (5)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deployment-on-kubernetes/&#34;&gt;GKE 上自架 Prometheus / Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GKE 上自架 Grafana 與設定&lt;/li&gt;
&lt;li&gt;使用 exporter 監測 GKE 上的各項服務&lt;/li&gt;
&lt;li&gt;輸出 kubernetes 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 redis-ha 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 kafka 的監測數據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Grafana Introduction&lt;/li&gt;
&lt;li&gt;Deploy Grafana&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;grafana-introduction&#34;&gt;Grafana Introduction&lt;/h1&gt;
&lt;p&gt;上偏我們簡單介紹了 Prometheus，prometheus 的 Web Portol 已經附上簡單的 Query 與 Graph 工具，但一般我們在使用時，還是會搭配 Grafana 來使用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://grafana.com/grafana/&#34;&gt;Grafana 在官網上提到&lt;/a&gt; 是一個 Analytics system，可以協助了解運行資料，建立完整的 dashboard。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支援許多圖表，直線圖，長條圖，區域分析，基本上需要的都有&lt;/li&gt;
&lt;li&gt;在圖表上定義 alter，並且主動告警，整合其他通訊軟體&lt;/li&gt;
&lt;li&gt;對後端 data source 的整合，可以同時使用 ELK, prometheus, influxdb 等 30 多種的資料來源&lt;/li&gt;
&lt;li&gt;有許多公開的 plugin 與 dashboard 可以匯入使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;總之功能強大，至於用起來的感覺，個人是非常推薦。如果有大得想要試玩看看，可以直接到 &lt;a href=&#34;https://play.grafana.org/d/000000029/prometheus-demo-dashboard?orgId=1&amp;amp;refresh=5m&#34;&gt;Grafana Live Demo&lt;/a&gt; 上面試玩&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般使用都會圍繞 dashboard 為核心，透過單一畫面，一覽目前使用者需要讀取的資料&lt;/li&gt;
&lt;li&gt;左上角的下拉選單，可以選擇不同的 dashboards&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;與-kibana-做比較&#34;&gt;與 Kibana 做比較&lt;/h1&gt;
&lt;p&gt;雖然大部分使用上，我們都會使用 ELK 一套，而 Prometheus + Grafana 另一套。但其實兩邊的 data source 都可以互接。例如 grafana 可以吃 elasticsearch 的 data source，而 kibana 有 prometheus module。&lt;/p&gt;
&lt;p&gt;我們這邊基於兩款前端分析工具，稍微做個比較，底層的 data source 差異這邊先不提。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;都是開源: 兩者的開源社群都非常強大&lt;/li&gt;
&lt;li&gt;兩者內建的 dashboard 都非常完整，而且不斷推出新功能&lt;/li&gt;
&lt;li&gt;Log vs Metrics:
&lt;ul&gt;
&lt;li&gt;Kibana 的 metrics 也是像 log 一樣的 key value pairs，能夠 explore 未定義的 log&lt;/li&gt;
&lt;li&gt;Grafana 的 UI 專注於呈現 time series 的 metrics，並沒有提供 data 的欄位搜尋，而是使用語法 Query 來取得數據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data source:
&lt;ul&gt;
&lt;li&gt;Grafana 可以收集各種不同的後端資料來源&lt;/li&gt;
&lt;li&gt;ELK 主要核心還是 ELK stack，用其他 Module 輔助其他資料源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;deploy-grafana&#34;&gt;Deploy Grafana&lt;/h1&gt;
&lt;p&gt;我把我的寶藏都放在這了&lt;a href=&#34;https://github.com/chechiachang/prometheus-kubernetes&#34;&gt;https://github.com/chechiachang/prometheus-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下載下來的 .sh ，跑之前養成習慣貓一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd grafana

cat install.sh

#!/bin/bash
HELM_NAME=grafana-1

helm upgrade --install grafana stable/grafana \
  --namespace default \
  --values values-staging.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;helm&#34;&gt;Helm&lt;/h3&gt;
&lt;p&gt;我們這邊用 helm 部屬，&lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/grafana&#34;&gt;Grafana Stable Chart&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;configuration&#34;&gt;Configuration&lt;/h3&gt;
&lt;p&gt;簡單看一下設定檔&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim values-staging.yaml

replicas: 1

deploymentStrategy: RollingUpdate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Grafana 是支援 &lt;a href=&#34;https://grafana.com/docs/tutorials/ha_setup/&#34;&gt;Grafana HA&lt;/a&gt; ，其實也非常簡單，就是把 grafana 本身的 dashboard database 從每個 grafana 一台 SQLite，變成外部統一的 MySQL，統一讀取後端資料，前端就可水平擴展。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;readinessProbe:
  httpGet:
    path: /api/health
    port: 3000

livenessProbe:
  httpGet:
    path: /api/health
    port: 3000
  initialDelaySeconds: 60
  timeoutSeconds: 30
  failureThreshold: 10

image:
  repository: grafana/grafana
  tag: 6.0.0
  pullPolicy: IfNotPresent

  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  # pullSecrets:
  #   - myRegistrKeySecretName
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一些 Pod 的基本配置， health check 使用內建的 api，有需要也可以直接打 api&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;securityContext:
  runAsUser: 472
  fsGroup: 472


extraConfigmapMounts: []
  # - name: certs-configmap
  #   mountPath: /etc/grafana/ssl/
  #   configMap: certs-configmap
  #   readOnly: true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有要開外部 ingress，需要 ssl 的話可以從這邊掛進去&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).
## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.
## ref: http://kubernetes.io/docs/user-guide/services/
##
service:
  type: LoadBalancer
  port: 80
  targetPort: 3000
    # targetPort: 4181 To be used with a proxy extraContainer
  annotations: {}
  labels: {}

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: &amp;quot;true&amp;quot;
  labels: {}
  path: /
  hosts:
    - chart-example.local
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;這邊可以開 service load balancer, 以及 ingress，看實際使用的需求&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;persistence:
  enabled: true
  initChownData: true
  # storageClassName: default
  accessModes:
    - ReadWriteOnce
  size: 10Gi
  # annotations: {}
  # subPath: &amp;quot;&amp;quot;
  # existingClaim:
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Persistent Volume 作為本地儲存建議都開起來，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Administrator credentials when not using an existing secret (see below)
adminUser: admin
# adminPassword: strongpassword

# Use an existing secret for the admin user.
admin:
  existingSecret: &amp;quot;&amp;quot;
  userKey: admin-user
  passwordKey: admin-password
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;帳號密碼建議使用 secret 掛進去&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;datasources: {}
#  datasources.yaml:
#    apiVersion: 1
#    datasources:
#    - name: Prometheus
#      type: prometheus
#      url: http://prometheus-prometheus-server
#      access: proxy
#      isDefault: true

## Configure grafana dashboard providers
## ref: http://docs.grafana.org/administration/provisioning/#dashboards
##
## `path` must be /var/lib/grafana/dashboards/&amp;lt;provider_name&amp;gt;
##
dashboardProviders: {}
#  dashboardproviders.yaml:
#    apiVersion: 1
#    providers:
#    - name: &#39;default&#39;
#      orgId: 1
#      folder: &#39;&#39;
#      type: file
#      disableDeletion: false
#      editable: true
#      options:
#        path: /var/lib/grafana/dashboards/default

## Configure grafana dashboard to import
## NOTE: To use dashboards you must also enable/configure dashboardProviders
## ref: https://grafana.com/dashboards
##
## dashboards per provider, use provider name as key.
##
dashboards: {}
  # default:
  #   some-dashboard:
  #     json: |
  #       $RAW_JSON
  #   custom-dashboard:
  #     file: dashboards/custom-dashboard.json
  #   prometheus-stats:
  #     gnetId: 2
  #     revision: 2
  #     datasource: Prometheus
  #   local-dashboard:
  #     url: https://example.com/repository/test.json
  #   local-dashboard-base64:
  #     url: https://example.com/repository/test-b64.json
  #     b64content: true
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Data source, Dashboard 想要直接載入，可以在這邊設定，或是 grafana 起來後，透過 Web UI 進去新增也可以&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Grafana&#39;s primary configuration
## NOTE: values in map will be converted to ini format
## ref: http://docs.grafana.org/installation/configuration/
##
grafana.ini:
  paths:
    data: /var/lib/grafana/data
    logs: /var/log/grafana
    plugins: /var/lib/grafana/plugins
    provisioning: /etc/grafana/provisioning
  analytics:
    check_for_updates: true
  log:
    mode: console
  grafana_net:
    url: https://grafana.net
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然後是 grafana.ini 核心 runtime 設定，更多設定可以參考&lt;a href=&#34;http://docs.grafana.org/installation/configuration/&#34;&gt;官方文件&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;deployment&#34;&gt;Deployment&lt;/h1&gt;
&lt;p&gt;部屬完看一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get po --selector=&#39;app=grafana&#39;


&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;access&#34;&gt;Access&lt;/h1&gt;
&lt;p&gt;如果沒有透過 service load balancer 打出來，一樣可以使用 kubectl 做 port forwarding，權限就是 context 的權限，沒有 cluster context 的使用者就會進步來&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GRAFANA_POD_NAME=$(kc get po -n default --selector=&#39;app=grafana&#39; -o=jsonpath=&#39;{.items[0].metadata.name}&#39;)
kubectl --namespace default port-forward ${GRAFANA_POD_NAME} 3000

http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由於我們透過 service load balancer，gcp 會在外部幫忙架一個 load balancer，
可以直接透過 load balancer ip 存取，如果想設定 dns，指向這個 ip 後記得去調整 grafana 的 server hostname。&lt;/p&gt;
&lt;p&gt;使用 secret 的密碼登入，username: grafana，這個是系統管理員&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl get secret --namespace default grafana -o jsonpath=&amp;quot;{.data.admin-password}&amp;quot; | base64 --decode ; echo
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;configuration-1&#34;&gt;Configuration&lt;/h1&gt;
&lt;p&gt;近來畫面後先到左邊的&lt;a href=&#34;https://play.grafana.org/plugins&#34;&gt;Configuration&lt;/a&gt; 調整&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;產生新的 user org 與 user，把 admin 權限控制在需要的人手上&lt;/li&gt;
&lt;li&gt;把 prometheus data source 加進來，就可以直接看到 prometheus 裡面的資料。&lt;/li&gt;
&lt;li&gt;切換到非管理員的 user 繼續操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;import-dashboard&#34;&gt;Import Dashboard&lt;/h3&gt;
&lt;p&gt;Grafana 網站上已經有&lt;a href=&#34;https://grafana.com/grafana/dashboards&#34;&gt;超多設置好的 Dashboard&lt;/a&gt; 可以直接 import，大部分的服務都已經有別人幫我們把視覺畫圖表拉好，使用社群主流的 exporter 的話，參數直接接好。我們匯入後再進行簡單的客製化調整即可。&lt;/p&gt;
&lt;p&gt;我們鐵人賽有用到的服務，都已經有 dashboard&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kubernetes Cluster: 6417
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/dashboards/6417&#34;&gt;https://grafana.com/dashboards/6417&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kafka Exporter Overview: 7589
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/dashboards/7589&#34;&gt;https://grafana.com/dashboards/7589&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prometheus Redis: 763
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/dashboards/763&#34;&gt;https://grafana.com/dashboards/763&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kubernetes Deployment Statefulset Daemonset metrics: 8588
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/dashboards/8588&#34;&gt;https://grafana.com/dashboards/8588&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Haproxy Metrics Servers: 367
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://grafana.com/dashboards/367&#34;&gt;https://grafana.com/dashboards/367&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Go to grafana lab to find more dashboards&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;export-dashboard&#34;&gt;Export Dashboard&lt;/h3&gt;
&lt;p&gt;dashboard 會依照登入使用者的需求做調整，每個腳色需要看到的圖表都不同，基本上讓各個腳色都能一眼看到所需的表格即可&lt;/p&gt;
&lt;p&gt;自己的調整過的 dashboard 也可以匯出分享&lt;/p&gt;
&lt;h1 id=&#34;小結&#34;&gt;小結&lt;/h1&gt;
&lt;p&gt;到這邊就可以正常使用 grafana了，資料來源的 exporter 我們會搭配前幾周分享過的服務，一起來講&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prometheus Deploy Grafana</title>
      <link>https://chechia.net/post/prometheus-scrape/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/prometheus-scrape/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus / Grafana (5)
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/prometheus-deployment-on-kubernetes/&#34;&gt;GKE 上自架 Prometheus / Grafana&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GKE 上自架 Grafana 與設定&lt;/li&gt;
&lt;li&gt;使用 exporter 監測 GKE 上的各項服務&lt;/li&gt;
&lt;li&gt;輸出 kubernetes 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 redis-ha 的監測數據&lt;/li&gt;
&lt;li&gt;輸出 kafka 的監測數據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus scrape&lt;/li&gt;
&lt;li&gt;scrape_configs&lt;/li&gt;
&lt;li&gt;Node exporter&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;scrape&#34;&gt;Scrape&lt;/h1&gt;
&lt;p&gt;Prometheus 收集 metrics 的方式，是從被監測的目標的 http endpoints 收集 (scrape) metrics，目標服務有提供 export metrics 的 endpoint 的話，稱作 exporter。例如 kafka-exporter 就會收集 kafka 運行的 metrics，變成 http endpoint instance，prometheus 從 instance 上面收集資料。&lt;/p&gt;
&lt;p&gt;Promethesu 自己也是也提供 metrics endpoint，並且自己透過 scrape 自己的 metrics endpoint 來取得 self-monitoring 的 metrics。把自己當作外部服務監測。下面的設定就是直接透過 http://localhost:9090/metrics 取得。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.

  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: &#39;codelab-monitor&#39;

# A scrape configuration containing exactly one endpoint to scrape:
# Here it&#39;s Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&amp;lt;job_name&amp;gt;` to any timeseries scraped from this config.
  - job_name: &#39;prometheus&#39;

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: [&#39;localhost:9090&#39;]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;透過 Grafana -&amp;gt; explore 就可以看到 Prometheus 的 metrics&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;static/img/prometheus-self-metrics.jpg&#34; alt=&#34;Prometheus Self Metrics&#34;&gt;&lt;/p&gt;
&lt;p&gt;而使用 metrics 時最好先查到說明文件，確定 metrics 的定義與計算方法，才可以有效的製圖。關於 &lt;a href=&#34;https://wiki.lnd.bz/display/LFTC/Prometheus&#34;&gt;Prometheus Exporter 的 metrics 說明&lt;/a&gt; 可以到這裡來找。&lt;/p&gt;
&lt;h1 id=&#34;dashboard&#34;&gt;Dashboard&lt;/h1&gt;
&lt;p&gt;收集到 metrics 之後就可以在 prometheus 中 query，但一般使用不會一直跑進來下 query，而是會直接搭配 dashboard 製圖呈現，讓資料一覽無遺。&lt;/p&gt;
&lt;p&gt;例如 prometheus 自身的 metrics 也已經有搭配好的 &lt;a href=&#34;https://grafana.com/grafana/dashboards/3662&#34;&gt;Prometheus overview dashboard&lt;/a&gt; 可以使用。&lt;/p&gt;
&lt;p&gt;使用方法非常簡單，直接透過 Grafana import dashboard，裡面就把重要的 prometheus metrics 都放在 dashboard 上了。不能更方便了。&lt;/p&gt;
&lt;h1 id=&#34;exporters&#34;&gt;Exporters&lt;/h1&gt;
&lt;p&gt;Prometheus 支援超級多 exporter，包含 prometheus 自身直接維護的 exporter，還有非常多外部服務友也開源的 exporter 可以使用，&lt;a href=&#34;https://prometheus.io/docs/instrumenting/exporters/#exporters-and-integrations&#34;&gt;清單可以到這裡看&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;有希望自己公司的服務，也使用 prometheus&lt;/p&gt;
&lt;h1 id=&#34;node-exporter&#34;&gt;Node Exporter&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/prometheus/node_exporter&#34;&gt;prometheus/node_exporter&lt;/a&gt; 是 Prometheus 直接維護的 project，主要用途就是將 node / vm 的運行 metrics export 出來。有點類似 ELK 的 metricbeat。&lt;/p&gt;
&lt;p&gt;我們這邊是在 kubernetes 上執行，所以直接做成 daemonsets 在 k8s 上跑，部屬方面在 deploy prometheus-server 的 helm chart 中，就已經附帶整合，部屬到每一台 node 上。&lt;/p&gt;
&lt;p&gt;如果是在 kubernetes 外的環境，例如說 on premise server，或是 gcp instance，希望自己部屬 node exporter 的話，可以參考&lt;a href=&#34;https://prometheus.io/docs/guides/node-exporter/&#34;&gt;這篇教學文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我們這邊可以看一下 config，以及 job 定義。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim values-staging.yaml

  # Enable nodeExporter
  nodeExporter:
    create: true

  prometheus.yml:
    rule_files:
      - /etc/config/rules
      - /etc/config/alerts

    scrape_configs:

    # Add kubernetes node job
    - job_name: &#39;kubernetes-nodes&#39;

        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https

        # This TLS &amp;amp; bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery &amp;amp; scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # &amp;lt;kubernetes_sd_config&amp;gt;.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          # If your node certificates are self-signed or use a different CA to the
          # master CA, then disable certificate verification below. Note that
          # certificate verification is an integral part of a secure infrastructure
          # so this should only be disabled in a controlled environment. You can
          # disable certificate verification by uncommenting the line below.
          #
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
          - role: node

        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;kubernetes_sd_config: 可以透過 kubernetes API 來取得 scrape target，以這邊的設定，是使用 node role 去集群取得 node，並且每一台 node 都當成一個 target，這樣就不用把所有 node 都手動加到 job 的 instance list 裡面。&lt;/p&gt;
&lt;p&gt;從 node role 取得的 instance 會使用 ip 標註或是 hostname 標註。node role 有提供 node 範圍的 meta labels，例如 __meta_kubernetes_node_name, _&lt;em&gt;meta_kubernetes_node_address&lt;/em&gt; 等等，方便查找整理資料。&lt;/p&gt;
&lt;p&gt;relabel_configs: 針對資料做額外標記，方便之後在 grafana 上面依據需求 query。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Redis Ha Topology</title>
      <link>https://chechia.net/post/redis-ha-topology/</link>
      <pubDate>Fri, 23 Aug 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/redis-ha-topology/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/2020ironman&#34;&gt;2020 It邦幫忙鐵人賽&lt;/a&gt; 系列文章&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 GKE 上部署 Redis HA
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://chechia.net/post/redis-ha-deployment/&#34;&gt;使用 helm 部署 redis-ha&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Redis HA with sentinel&lt;/li&gt;
&lt;li&gt;Redis sentinel topology&lt;/li&gt;
&lt;li&gt;Redis HA with HAproxy&lt;/li&gt;
&lt;li&gt;集群內部的 HA 設定，網路設定&lt;/li&gt;
&lt;li&gt;應用端的基本範例，效能調校&lt;/li&gt;
&lt;li&gt;在 GKE 上維運 redis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。&lt;/p&gt;
&lt;p&gt;寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。&lt;/p&gt;
&lt;p&gt;對我的文章有興趣，歡迎到我的網站上 &lt;a href=&#34;https://chechia.net&#34;&gt;https://chechia.net&lt;/a&gt; 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg&#34; alt=&#34;Exausted Cat Face&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Redis Sentinel Topology&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;topology&#34;&gt;Topology&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Masters: M1, M2, M3, &amp;hellip;, Mn.&lt;/li&gt;
&lt;li&gt;Slaves: R1, R2, R3, &amp;hellip;, Rn (R stands for replica).&lt;/li&gt;
&lt;li&gt;Sentinels: S1, S2, S3, &amp;hellip;, Sn.&lt;/li&gt;
&lt;li&gt;Clients: C1, C2, C3, &amp;hellip;, Cn.&lt;/li&gt;
&lt;li&gt;每個方格代表一台機器或是 VM&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-sentinels&#34;&gt;2 Sentinels&lt;/h3&gt;
&lt;p&gt;DON&amp;rsquo;T DO THIS&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+----+         +----+
| M1 |---------| R1 |
| S1 |         | S2 |
+----+         +----+

Configuration: quorum = 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;這個設定下，如果 M1 掛了需要 failover，很有可能 S1 跟著機器一起掛了，S2 會沒有辦法取得多數來執行 failover，整個系統掛掉&lt;/p&gt;
&lt;h3 id=&#34;3-vm&#34;&gt;3 VM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+

Configuration: quorum = 2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;這是最基本的蛋又兼顧安全設定的設置&lt;/p&gt;
&lt;p&gt;如果 M1 死了 S1 跟著機器故障，S2 與 S3 還可以取得多數，順利 failover 到 R2 或是 R3。&lt;/p&gt;
&lt;h3 id=&#34;寫入資料遺失&#34;&gt;寫入資料遺失&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;         +----+
         | M1 |
         | S1 | &amp;lt;- C1 (writes will be lost)
         +----+
            |
            /
            /
+------+    |    +----+
| [M2] |----+----| R3 |
| S2   |         | S3 |
+------+         +----+
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;failover 之前，M1 是 master，Client 的寫入往 M1 寫&lt;/li&gt;
&lt;li&gt;M1 網路故障，M2 failover 後成為新的 master，可是 Client 往 M1 寫入的資料並無法 sync 回 M2&lt;/li&gt;
&lt;li&gt;等網路修復後，M1 回覆後會變成 R1 變成 slave，由 M2 去 sync R1，變成 R1 在 master 時收到的寫入資料遺失&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了避免這種情形，做額外的設定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;min-slaves-to-write 1&lt;/li&gt;
&lt;li&gt;min-slaves-max-lag 10&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當 master 發現自己再也無法 sync 到足夠的 slave，表示 master 可能被孤立，這時主動拒絕客戶端的寫入請求。客戶端被拒絕後，會再向 sentinel 取得有效的 master，重新執行寫入請求，確保資料寫到有效的 master 上。&lt;/p&gt;
&lt;h3 id=&#34;sentinel-放在-client-端&#34;&gt;Sentinel 放在 Client 端&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;            +----+         +----+
            | M1 |----+----| R1 |
            |    |    |    |    |
            +----+    |    +----+
                      |
         +------------+------------+
         |            |            |
         |            |            |
      +----+        +----+      +----+
      | C1 |        | C2 |      | C3 |
      | S1 |        | S2 |      | S3 |
      +----+        +----+      +----+
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;有些情形，redis 這端只有兩台可用機器，這種情形可以考慮把 sentinel 放在客戶端的機器上&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仍然維持了獨立的 3 sentinels 的穩定&lt;/li&gt;
&lt;li&gt;sentinel 與 client 所觀察到的 redis 狀態是相同的&lt;/li&gt;
&lt;li&gt;如果 M1 死了，要 failover ，客戶端的 3 sentinel 可以正確地執行 failover，不受故障影響&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;客戶端又不足-3-個&#34;&gt;客戶端又不足 3 個&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;            +----+         +----+
            | M1 |----+----| R1 |
            | S1 |    |    | S2 |
            +----+    |    +----+
                      |
               +------+-----+
               |            |  
               |            |
            +----+        +----+
            | C1 |        | C2 |
            | S3 |        | S4 |
            +----+        +----+

      Configuration: quorum = 3

            +----+         +----+
            | M1 |----+----| R1 |
            | S1 |    |    | S2 |
            +----+    |    +----+
                      |
                      |        
                      |        
                   +----+      
                   | C1 |      
                   | S3 |      
                   +----+      

      Configuration: quorum = 2
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;跟上個例子類似，但又額外確保 3 sentinels&lt;/li&gt;
&lt;li&gt;如果 M1 死了，剩下的 sentinel 可以正確 failover&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
