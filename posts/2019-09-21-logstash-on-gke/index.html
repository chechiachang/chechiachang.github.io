<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Logstash on GKE | Che-Chia Chang</title><meta name=keywords content="鐵人賽2019,elasticsearch,devops,logstash"><meta name=description content="2020 It邦幫忙鐵人賽 系列文章

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP

作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。

摘要

簡介 logstash
將 logstash 部屬到 kubernetes 上
設定 logstash pipeline 處理 nginx access log

介紹 Logstash
Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。"><meta name=author content="chechiachang"><link rel=canonical href=https://chechia.net/posts/2019-09-21-logstash-on-gke/><meta name=google-site-verification content="G-QYR8JCDGM9"><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://chechia.net/favicon/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://chechia.net/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://chechia.net/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://chechia.net/favicon/favicon-32x32.png><link rel=mask-icon href=https://chechia.net/favicon/favicon-32x32.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://chechia.net/posts/2019-09-21-logstash-on-gke/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QYR8JCDGM9"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QYR8JCDGM9")}</script><meta property="og:url" content="https://chechia.net/posts/2019-09-21-logstash-on-gke/"><meta property="og:site_name" content="Che-Chia Chang"><meta property="og:title" content="Logstash on GKE"><meta property="og:description" content="2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
摘要 簡介 logstash 將 logstash 部屬到 kubernetes 上 設定 logstash pipeline 處理 nginx access log 介紹 Logstash Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-09-21T15:22:23+08:00"><meta property="article:modified_time" content="2019-09-21T15:22:23+08:00"><meta property="article:tag" content="鐵人賽2019"><meta property="article:tag" content="Elasticsearch"><meta property="article:tag" content="Devops"><meta property="article:tag" content="Logstash"><meta property="og:image" content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Logstash on GKE"><meta name=twitter:description content="2020 It邦幫忙鐵人賽 系列文章

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP

作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。

摘要

簡介 logstash
將 logstash 部屬到 kubernetes 上
設定 logstash pipeline 處理 nginx access log

介紹 Logstash
Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://chechia.net/posts/"},{"@type":"ListItem","position":2,"name":"Logstash on GKE","item":"https://chechia.net/posts/2019-09-21-logstash-on-gke/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Logstash on GKE","name":"Logstash on GKE","description":"2020 It邦幫忙鐵人賽 系列文章\nSelf-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。\n由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n摘要 簡介 logstash 將 logstash 部屬到 kubernetes 上 設定 logstash pipeline 處理 nginx access log 介紹 Logstash Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。\n","keywords":["鐵人賽2019","elasticsearch","devops","logstash"],"articleBody":"2020 It邦幫忙鐵人賽 系列文章\nSelf-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。\n由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n摘要 簡介 logstash 將 logstash 部屬到 kubernetes 上 設定 logstash pipeline 處理 nginx access log 介紹 Logstash Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。\nLogastash 內部的功能也大多模組化，因此可以組裝不同的 plugin，來快速處理不同來源資料。\n基本上常見的資料來源，logstash 都能夠處理，並且有寫好的 plugin 可以直接使用，細節請見logstash 官方文件\n後送資料庫與最終儲存庫 在開始架設 logstash 要先考慮 pipeline 處理過後送的資料庫，可使用的資料庫非常多，這邊會展示的有：\nELK Stack 標準配備送到 Elasticsearch 存放會時常查詢的熱資料，只存放一段時間前的資料 太舊的資料自動 Rollout 最終 archieving 的資料庫，這邊使用 GCP 的 Big Query 存放查找次數少，但非常大量的歷史紀錄。 Elasticsearch 在前幾篇已經架設好，GCP Big Query 的設定也事先開好。\n部屬 Logstash kubernetes resource 的 yaml 請參考 我的 github elk-kubernetes\nkubectl apply -f config-configmap.yaml kubectl apply -f pipelines-configmap.yam kubectl apply -f deployment.yaml kubectl apply -f service.yaml 放上去的 resource\nconfig-configmap: Logstash 服務本身啟動的設定參數 pipelines-configmap: Logstash 的 pipelines 設定檔案 Lostagh Deployment Logastash 的服務 instance 可以動態 scaling，也就是會有複數 Logstash instance 做負載均衡 Logstash service 可透過 kubernetes 內部的 kube-dns 服務 集群內的 filebeat 可以直接透過 logstash.default.svc.chechiachang-cluster.local 的 dns 連線 logstash 集群內的網路，直接使用 http（當然使用 https 也是可以，相關步驟請見前幾篇文章） 簡單講一下 kubernetes service 的負載均衡，關於 kubernetes service 細節這篇附上文件\n$ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE logstash ClusterIP 10.15.254.47 5044/TCP 182d $ kubectl get endpoints NAME ENDPOINTS AGE logstash 10.12.0.132:5044,10.12.10.162:5044,10.12.9.167:5044 + 12 more... 182d 在 Kubernetes 內部每個 Pod 都能看到 logstash, logstash.default.svc.chechiachang-cluster.local 這兩個 dns DNS 直接指向複數的 logstash endpoints， 每一個 ip 都是 kubernetes 內部配置的一個 Pod 的 IP，開啟 5044 的 logstash port Service 的 load balance 機制視 service 設定，細節可以看這邊 講到最白，就是 filebeat LOGSTASH URL 設定為 http://logstash 就會打到其中一台 logstash\n更改 filebeat configmap\n$ kubectl edit configmap filebeat-configmap # Disable output to elasticsearch output.elasticsearch: enabled: false # Output to logstash output.logstash: hosts: [\"logstash:5044\"] protocol: \"http\" username: \"elastic\" password: 設定 logstash 這邊要先說，logstash 也支援 centralized configuration，如果你的 logstash 不是跑在 Kubernetes 上，沒辦法配置一套 configmap 就應用到全部的 instance，記的一定要使用。\nLogastash 的運行設定 logstash.yml，這邊我們沒有做設定，都是預設值，有需求可以自行更改\n當然之後要調整 batch size 或是 queue, cache 等等效能調校，也是來這邊改，改完 configmap ，rolling update logstash 就可以。\n這邊主要是來講 pipeline 設定。\n$ kubectl describe configmap pipelines-configmap apiVersion: v1 kind: ConfigMap metadata: name: logstash-pipelines namespace: elk labels: k8s-app: logstash data: # Nginx Template # https://www.elastic.co/guide/en/logstash/7.3/logstash-config-for-filebeat-modules.html#parsing-nginx nginx.conf: | ... Configmap 裡面只有一個 pipeline，就是 nginx.conf，我們這邊就只有一條，這邊一段一段看\nInput input { beats { # The lisening port of logstash port =\u003e 5044 host =\u003e \"0.0.0.0\" } } 設定 Input 來源，是 beat 從 5044 進來\nFilter 接下來一大段是 filter，每個 filter 中間的 block 都是一個 plugin，logstash 支援非常多有趣的 plugin ，處理不同來源的工作，細節請看這篇\nfilter { # Ignore data from other source in case filebeat input is incorrectly configured. if [kubernetes][container][name] == \"nginx-ingress-controller\" { # Parse message with grok # Use grok debugger in kibana -\u003e dev_tools -\u003e grok_debugger grok { match =\u003e { \"message\" =\u003e \"%{IPORHOST:[nginx][access][remote_ip]} - \\[%{IPORHOST:[nginx][access][remote_ip_list]}\\] - %{DATA:[nginx][access][user_name]} \\[%{HTTPDATE:[nginx][access][time]}\\] \\\"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][request_url]} HTTP/%{NUMBER:[nginx][access][http_version]}\\\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \\\"%{DATA:[nginx][access][referrer]}\\\" \\\"%{DATA:[nginx][access][agent]}\\\" %{NUMBER:[nginx][access][request_length]} %{NUMBER:[nginx][access][request_time]} \\[%{DATA:[nginx][access][proxy_upstream_name]}\\] %{DATA:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream_response_length]} %{NUMBER:[nginx][access][upstream_response_time]} %{NUMBER:[nginx][access][upstream_status]} %{DATA:[nginx][access][req_id]}\" } } # Match url parameters if has params grok { match =\u003e { \"[nginx][access][request_url]\" =\u003e \"%{DATA:[nginx][access][url]}\\?%{DATA:[nginx][access][url_params]}\" } } # Remove and add fields mutate { remove_field =\u003e \"[nginx][access][request_url]\" add_field =\u003e { \"read_timestamp\" =\u003e \"%{@timestamp}\" } # Add fileset.module:nginx to fit nginx dashboard add_field =\u003e { \"[fileset][module]\" =\u003e \"nginx\"} add_field =\u003e { \"[fileset][name]\" =\u003e \"access\"} } # Parse date string into timestamp date { match =\u003e [ \"[nginx][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ] remove_field =\u003e \"[nginx][access][time]\" } # Split url_parameters with \u0026 # /api?uuid=123\u0026query=456 # become # nginx.access.url_params.uuid=123 nginx.access.url_params.query=456 kv { source =\u003e \"[nginx][access][url_params]\" field_split =\u003e \"\u0026\" } # Parse useragent useragent { source =\u003e \"[nginx][access][agent]\" target =\u003e \"[nginx][access][user_agent]\" remove_field =\u003e \"[nginx][access][agent]\" } # Search remote_ip with GeoIP database, output geoip information for map drawing geoip { source =\u003e \"[nginx][access][remote_ip]\" target =\u003e \"[nginx][access][geoip]\" #fields =\u003e [\"country_name\",\"city_name\",\"real_region_name\",\"latitude\",\"longitude\",\"ip\",\"location\"] } # ============== # Remove message to reduce data # ============== if [nginx][access][url] { mutate { # source:/var/lib/docker/containers/6e608bfc0a437c038a1dbdf2e3d28619648b58a1d1ac58635f8178fc5f871109/6e608bfc0a437c038a1dbdf2e3d28619648b58a1d1ac58635f8178fc5f871109-json.log remove_field =\u003e \"[source]\" # Origin message remove_field =\u003e \"[message]\" #add_field =\u003e { \"[nginx][access][message]\" =\u003e \"[message]\"} remove_field =\u003e \"[nginx][access][message]\" # url_params:client_id=1d5ffd378296c154d3e32e5890d6f4eb\u0026timestamp=1546849955\u0026nonce=9a52e3e6283f2a9263e5301b6724e2c0d723def860c4724c9121470152a42318 remove_field =\u003e \"[nginx][access][url_params]\" } } } # nginx-ingress-controller } # filter Grok Grok 本身的文件又是一大段，個人建議各路大德，如果要使用，請直接搜尋人家配置好的設定，不要自己寫\n真的要寫的話要善用工具\nKibana Grok Debugger YOUR_KIBANA_HOST/app/kibana#/dev_tools/grokdebugger 或是不知名大德貢獻線上 Debugger grok { match =\u003e { \"message\" =\u003e \"%{IPORHOST:[nginx][access][remote_ip]} - \\[%{IPORHOST:[nginx][access][remote_ip_list]}\\] - %{DATA:[nginx][access][user_name]} \\[%{HTTPDATE:[nginx][access][time]}\\] \\\"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][request_url]} HTTP/%{NUMBER:[nginx][access][http_version]}\\\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \\\"%{DATA:[nginx][access][referrer]}\\\" \\\"%{DATA:[nginx][access][agent]}\\\" %{NUMBER:[nginx][access][request_length]} %{NUMBER:[nginx][access][request_time]} \\[%{DATA:[nginx][access][proxy_upstream_name]}\\] %{DATA:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream_response_length]} %{NUMBER:[nginx][access][upstream_response_time]} %{NUMBER:[nginx][access][upstream_status]} %{DATA:[nginx][access][req_id]}\" } } 其實就是 nginx 的 access log\n1.2.3.4 - [1.2.3.4] - - [21/Sep/2019:07:21:21 +0000] \"GET /v1/core/api/list?type=queued\u0026timestamp=1569050481\u0026nonce=d1e80e00381e0ba6e42d4601912befcf03fbf291748e77b178230c19cd1fdbe2 HTTP/1.1\" 200 3 \"-\" \"python-requests/2.18.4\" 425 0.031 [default-chechiachang-server-80] 10.12.10.124:8003 3 0.031 200 f43db228afe66da67b2c7417d0ad2c04 預設的 log 送件來，格式是 text，經過 pattern matching 後變成 json-like format，也就是可以從資料結構取得 .nginx.access.remote_ip 這樣的欄位，讓原本的 access log 從 text 變成可以查找的內容。\n原本的 text 送進 elasticsearch 當然也可以查找，但就會在 text 裡面做全文檢索，功能很侷限，效率很差。\nOutput logstash 支援的 output 以及設定在這邊\noutput { elasticsearch { hosts =\u003e [\"https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}\"] user =\u003e \"${ELASTICSEARCH_USERNAME}\" password =\u003e \"${ELASTICSEARCH_PASSWORD}\" index =\u003e \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\" manage_template =\u003e false } } Elasticsearch 的配置很單純\noutput { google_bigquery { project_id =\u003e ${GCP_PROJECT_ID} dataset =\u003e ${GCP_BIG_QUERY_DATASET_NAME} csv_schema =\u003e \"path:STRING,status:INTEGER,score:FLOAT\" json_key_file =\u003e ${GCP_JSON_KEY_FILE_PATH} error_directory =\u003e \"/tmp/bigquery-errors\" date_pattern =\u003e \"%Y-%m-%dT%H:00\" flush_interval_secs =\u003e 30 } } 其中的變數，我們全都用環境變數，在 deployment.yaml 配置，啟動 logstash pods 時代入\nGCP_JSON_KEY_FILE_PATH 這邊要配置一隻 GCP 的服務帳號金鑰，一個有 Big Query 寫入權限的 service account，把 json 使用 kubernetes secret 放到集群上，然後在 pod 上使用 volume from secret 掛載進來。 csv_schema =\u003e \"path:STRING,status:INTEGER,score:FLOAT\" 這邊要配置之後會存入 Big Query 的 csv 結構\n小結 部屬 Logstash deployment 到 kubernetes 上 設定 pipeline，超多 plugin，族繁不及備載 Grok 配置 Big Query output 配置 ","wordCount":"817","inLanguage":"en","image":"https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2019-09-21T15:22:23+08:00","dateModified":"2019-09-21T15:22:23+08:00","author":{"@type":"Person","name":"chechiachang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://chechia.net/posts/2019-09-21-logstash-on-gke/"},"publisher":{"@type":"Organization","name":"Che-Chia Chang","logo":{"@type":"ImageObject","url":"https://chechia.net/favicon/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://chechia.net/ accesskey=h title="Home (Alt + H)"><img src=https://chechia.net/favicon/favicon-32x32.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://chechia.net/#posts title=Posts><span>Posts</span></a></li><li><a href=https://mvp.microsoft.com/zh-TW/mvp/profile/e407d0b9-5c01-eb11-a815-000d3a8ccaf5 title=MVP><span>MVP</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://chechia.net/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://chechia.net/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://chechia.net/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://chechia.net/>Home</a>&nbsp;»&nbsp;<a href=https://chechia.net/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Logstash on GKE</h1><div class=post-meta><span title='2019-09-21 15:22:23 +0800 CST'>September 21, 2019</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;817 words&nbsp;·&nbsp;chechiachang&nbsp;|&nbsp;<a href=https://github.com/chechiachang.github.io-src/content/posts/2019-09-21-logstash-on-gke.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#input>Input</a></li><li><a href=#filter>Filter</a></li><li><a href=#grok>Grok</a></li><li><a href=#output>Output</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p><a href=https://ithelp.ithome.com.tw/2020ironman>2020 It邦幫忙鐵人賽</a> 系列文章</p><ul><li><a href=https://chechia.net/posts/2019-09-15-self-host-elk-stack-on-gcp/>Self-host ELK stack on GCP</a></li><li><a href=https://chechia.net/posts/2019-09-15-secure-elk-stack/>Secure ELK Stask</a></li><li><a href=https://chechia.net/posts/2019-09-18-monitoring-gce-with-elk/>監測 Google Compute Engine 上服務的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/>監測 Google Kubernetes Engine 的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-18-elastic-or-not-elastic/>是否選擇 ELK 作為解決方案</a></li><li><a href=https://chechia.net/posts/2019-09-21-logstash-on-gke/>使用 logstash pipeline 做數據前處理</a></li><li>Elasticsearch 日常維護：數據清理，效能調校，永久儲存</li><li>Debug ELK stack on GCP</li></ul><p>作為範例的 ELK 的版本是當前的 stable release 7.3.1。</p><p>由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。</p><hr><h1 id=摘要>摘要<a hidden class=anchor aria-hidden=true href=#摘要>#</a></h1><ul><li>簡介 logstash</li><li>將 logstash 部屬到 kubernetes 上</li><li>設定 logstash pipeline 處理 nginx access log</li></ul><h1 id=介紹-logstash>介紹 Logstash<a hidden class=anchor aria-hidden=true href=#介紹-logstash>#</a></h1><p>Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。</p><p>Logastash 內部的功能也大多模組化，因此可以組裝不同的 plugin，來快速處理不同來源資料。</p><p>基本上常見的資料來源，logstash 都能夠處理，並且有寫好的 plugin 可以直接使用，細節請見<a href=https://www.elastic.co/guide/en/logstash/current/introduction.html>logstash 官方文件</a></p><p><img alt=官方架構圖 loading=lazy src=https://www.elastic.co/guide/en/logstash/current/static/images/logstash.png></p><h1 id=後送資料庫與最終儲存庫>後送資料庫與最終儲存庫<a hidden class=anchor aria-hidden=true href=#後送資料庫與最終儲存庫>#</a></h1><p>在開始架設 logstash 要先考慮 pipeline 處理過後送的資料庫，<a href=https://www.elastic.co/guide/en/logstash/current/introduction.html#_choose_your_stash>可使用的資料庫非常多</a>，這邊會展示的有：</p><ul><li>ELK Stack 標準配備送到 Elasticsearch<ul><li>存放會時常查詢的熱資料，只存放一段時間前的資料</li><li>太舊的資料自動 Rollout</li></ul></li><li>最終 archieving 的資料庫，這邊使用 GCP 的 Big Query<ul><li>存放查找次數少，但非常大量的歷史紀錄。</li></ul></li></ul><p>Elasticsearch 在前幾篇已經架設好，<a href="https://cloud.google.com/bigquery/docs/?hl=zh-tw">GCP Big Query</a> 的設定也事先開好。</p><h1 id=部屬-logstash>部屬 Logstash<a hidden class=anchor aria-hidden=true href=#部屬-logstash>#</a></h1><p>kubernetes resource 的 yaml 請參考 <a href=https://github.com/chechiachang/elk-kubernetes/tree/master/logstash>我的 github elk-kubernetes</a></p><pre><code>kubectl apply -f config-configmap.yaml
kubectl apply -f pipelines-configmap.yam

kubectl apply -f deployment.yaml

kubectl apply -f service.yaml
</code></pre><p>放上去的 resource</p><ul><li>config-configmap:<ul><li>Logstash 服務本身啟動的設定參數</li></ul></li><li>pipelines-configmap:<ul><li>Logstash 的 pipelines 設定檔案</li></ul></li><li>Lostagh Deployment<ul><li>Logastash 的服務 instance</li><li>可以動態 scaling，也就是會有複數 Logstash instance 做負載均衡</li></ul></li><li>Logstash service<ul><li>可透過 kubernetes 內部的 kube-dns 服務</li><li>集群內的 filebeat 可以直接透過 logstash.default.svc.chechiachang-cluster.local 的 dns 連線 logstash</li><li>集群內的網路，直接使用 http（當然使用 https 也是可以，相關步驟請見前幾篇文章）</li></ul></li></ul><p>簡單講一下 kubernetes service 的負載均衡，關於 <a href=https://kubernetes.io/docs/concepts/services-networking/service/>kubernetes service 細節這篇附上文件</a></p><pre><code>$ kubectl get services

NAME              TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)    AGE
logstash          ClusterIP      10.15.254.47    &lt;none&gt;          5044/TCP   182d

$ kubectl get endpoints

NAME              ENDPOINTS                                                          AGE
logstash          10.12.0.132:5044,10.12.10.162:5044,10.12.9.167:5044 + 12 more...   182d
</code></pre><ul><li>在 Kubernetes 內部每個 Pod 都能看到 logstash, logstash.default.svc.chechiachang-cluster.local 這兩個 dns</li><li>DNS 直接指向複數的 logstash endpoints， 每一個 ip 都是 kubernetes 內部配置的一個 Pod 的 IP，開啟 5044 的 logstash port</li><li>Service 的 load balance 機制視 service 設定，細節可以看<a href=https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies>這邊</a></li></ul><p>講到最白，就是 filebeat LOGSTASH URL 設定為 http://logstash 就會打到其中一台 logstash</p><p>更改 filebeat configmap</p><pre><code>$ kubectl edit configmap filebeat-configmap

# Disable output to elasticsearch
output.elasticsearch:
  enabled: false

# Output to logstash
output.logstash:
  hosts: [&quot;logstash:5044&quot;]
  protocol: &quot;http&quot;
  username: &quot;elastic&quot;
  password: 

</code></pre><h1 id=設定-logstash>設定 logstash<a hidden class=anchor aria-hidden=true href=#設定-logstash>#</a></h1><p>這邊要先說，logstash 也支援 <a href=https://www.elastic.co/guide/en/logstash/7.3/configuring-centralized-pipelines.html>centralized configuration</a>，如果你的 logstash 不是跑在 Kubernetes 上，沒辦法配置一套 configmap 就應用到全部的 instance，記的一定要使用。</p><p>Logastash 的運行設定 logstash.yml，這邊我們沒有做設定，都是預設值，有需求可以自行更改</p><p>當然之後要調整 batch size 或是 queue, cache 等等效能調校，也是來這邊改，改完 configmap ，rolling update logstash 就可以。</p><p>這邊主要是來講 pipeline 設定。</p><pre><code>$ kubectl describe configmap pipelines-configmap

apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-pipelines
  namespace: elk
  labels:
    k8s-app: logstash
data:
  # Nginx Template
  # https://www.elastic.co/guide/en/logstash/7.3/logstash-config-for-filebeat-modules.html#parsing-nginx
  nginx.conf: |
  ...
</code></pre><p>Configmap 裡面只有一個 pipeline，就是 <code>nginx.conf</code>，我們這邊就只有一條，這邊一段一段看</p><h3 id=input>Input<a hidden class=anchor aria-hidden=true href=#input>#</a></h3><pre><code>input {
  beats {
    # The lisening port of logstash
    port =&gt; 5044
    host =&gt; &quot;0.0.0.0&quot;
  }
}
</code></pre><p>設定 Input 來源，是 beat 從 5044 進來</p><h3 id=filter>Filter<a hidden class=anchor aria-hidden=true href=#filter>#</a></h3><p>接下來一大段是 filter，每個 filter 中間的 block 都是一個 plugin，logstash 支援非常多有趣的 plugin ，處理不同來源的工作，<a href=https://www.elastic.co/guide/en/logstash/7.3/filter-plugins.html>細節請看這篇</a></p><pre><code>filter {

  # Ignore data from other source in case filebeat input is incorrectly configured.
  if [kubernetes][container][name] == &quot;nginx-ingress-controller&quot; {

    # Parse message with grok
    # Use grok debugger in kibana -&gt; dev_tools -&gt; grok_debugger
    grok {
      match =&gt; { &quot;message&quot; =&gt; &quot;%{IPORHOST:[nginx][access][remote_ip]} - \[%{IPORHOST:[nginx][access][remote_ip_list]}\] - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \&quot;%{WORD:[nginx][access][method]} %{DATA:[nginx][access][request_url]} HTTP/%{NUMBER:[nginx][access][http_version]}\&quot; %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \&quot;%{DATA:[nginx][access][referrer]}\&quot; \&quot;%{DATA:[nginx][access][agent]}\&quot; %{NUMBER:[nginx][access][request_length]} %{NUMBER:[nginx][access][request_time]} \[%{DATA:[nginx][access][proxy_upstream_name]}\] %{DATA:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream_response_length]} %{NUMBER:[nginx][access][upstream_response_time]} %{NUMBER:[nginx][access][upstream_status]} %{DATA:[nginx][access][req_id]}&quot; }
    }

    # Match url parameters if has params
    grok {
      match =&gt; { &quot;[nginx][access][request_url]&quot; =&gt; &quot;%{DATA:[nginx][access][url]}\?%{DATA:[nginx][access][url_params]}&quot; }
    }

    # Remove and add fields
    mutate {
      remove_field =&gt; &quot;[nginx][access][request_url]&quot;
      add_field =&gt; { &quot;read_timestamp&quot; =&gt; &quot;%{@timestamp}&quot; }
      # Add fileset.module:nginx to fit nginx dashboard
      add_field =&gt; { &quot;[fileset][module]&quot; =&gt; &quot;nginx&quot;}
      add_field =&gt; { &quot;[fileset][name]&quot; =&gt; &quot;access&quot;}
    }

    # Parse date string into timestamp
    date {
      match =&gt; [ &quot;[nginx][access][time]&quot;, &quot;dd/MMM/YYYY:H:m:s Z&quot; ]
      remove_field =&gt; &quot;[nginx][access][time]&quot;
    }

    # Split url_parameters with &amp;
    # /api?uuid=123&amp;query=456 
    # become 
    # nginx.access.url_params.uuid=123 nginx.access.url_params.query=456
    kv {
      source =&gt; &quot;[nginx][access][url_params]&quot;
      field_split =&gt; &quot;&amp;&quot;
    }

    # Parse useragent
    useragent {
      source =&gt; &quot;[nginx][access][agent]&quot;
      target =&gt; &quot;[nginx][access][user_agent]&quot;
      remove_field =&gt; &quot;[nginx][access][agent]&quot;
    }

    # Search remote_ip with GeoIP database, output geoip information for map drawing
    geoip {
      source =&gt; &quot;[nginx][access][remote_ip]&quot;
      target =&gt; &quot;[nginx][access][geoip]&quot;
      #fields =&gt; [&quot;country_name&quot;,&quot;city_name&quot;,&quot;real_region_name&quot;,&quot;latitude&quot;,&quot;longitude&quot;,&quot;ip&quot;,&quot;location&quot;]
    }

    # ==============
    # Remove message to reduce data
    # ==============
    if [nginx][access][url] {
      mutate {
        # source:/var/lib/docker/containers/6e608bfc0a437c038a1dbdf2e3d28619648b58a1d1ac58635f8178fc5f871109/6e608bfc0a437c038a1dbdf2e3d28619648b58a1d1ac58635f8178fc5f871109-json.log
        remove_field =&gt; &quot;[source]&quot;
        # Origin message
        remove_field =&gt; &quot;[message]&quot;
        #add_field =&gt; { &quot;[nginx][access][message]&quot; =&gt; &quot;[message]&quot;}
        remove_field =&gt; &quot;[nginx][access][message]&quot;
        # url_params:client_id=1d5ffd378296c154d3e32e5890d6f4eb&amp;timestamp=1546849955&amp;nonce=9a52e3e6283f2a9263e5301b6724e2c0d723def860c4724c9121470152a42318
        remove_field =&gt; &quot;[nginx][access][url_params]&quot;
      }
    }

  } # nginx-ingress-controller

} # filter
</code></pre><h3 id=grok>Grok<a hidden class=anchor aria-hidden=true href=#grok>#</a></h3><p><a href=https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-grok.html>Grok 本身的文件</a>又是一大段，個人建議各路大德，如果要使用，請直接搜尋人家配置好的設定，不要自己寫</p><p>真的要寫的話要善用工具</p><ul><li>Kibana Grok Debugger <code>YOUR_KIBANA_HOST/app/kibana#/dev_tools/grokdebugger</code></li><li>或是不知名大德貢獻<a href=https://grokdebug.herokuapp.com/>線上 Debugger</a></li></ul><pre><code>grok {
  match =&gt; { &quot;message&quot; =&gt; &quot;%{IPORHOST:[nginx][access][remote_ip]} - \[%{IPORHOST:[nginx][access][remote_ip_list]}\] - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \&quot;%{WORD:[nginx][access][method]} %{DATA:[nginx][access][request_url]} HTTP/%{NUMBER:[nginx][access][http_version]}\&quot; %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \&quot;%{DATA:[nginx][access][referrer]}\&quot; \&quot;%{DATA:[nginx][access][agent]}\&quot; %{NUMBER:[nginx][access][request_length]} %{NUMBER:[nginx][access][request_time]} \[%{DATA:[nginx][access][proxy_upstream_name]}\] %{DATA:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream_response_length]} %{NUMBER:[nginx][access][upstream_response_time]} %{NUMBER:[nginx][access][upstream_status]} %{DATA:[nginx][access][req_id]}&quot; }
}
</code></pre><p>其實就是 nginx 的 access log</p><pre><code>1.2.3.4 - [1.2.3.4] - - [21/Sep/2019:07:21:21 +0000] &quot;GET /v1/core/api/list?type=queued&amp;timestamp=1569050481&amp;nonce=d1e80e00381e0ba6e42d4601912befcf03fbf291748e77b178230c19cd1fdbe2 HTTP/1.1&quot; 200 3 &quot;-&quot; &quot;python-requests/2.18.4&quot; 425 0.031 [default-chechiachang-server-80] 10.12.10.124:8003 3 0.031 200 f43db228afe66da67b2c7417d0ad2c04
</code></pre><p>預設的 log 送件來，格式是 text，經過 pattern matching 後變成 json-like format，也就是可以從資料結構取得 <code>.nginx.access.remote_ip</code> 這樣的欄位，讓原本的 access log 從 text 變成可以查找的內容。</p><p>原本的 text 送進 elasticsearch 當然也可以查找，但就會在 text 裡面做全文檢索，功能很侷限，效率很差。</p><h3 id=output>Output<a hidden class=anchor aria-hidden=true href=#output>#</a></h3><p>logstash 支援的 output 以及設定<a href=https://www.elastic.co/guide/en/logstash/7.3/output-plugins.html>在這邊</a></p><pre><code>output {
  elasticsearch {
    hosts =&gt; [&quot;https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}&quot;]
    user =&gt; &quot;${ELASTICSEARCH_USERNAME}&quot;
    password =&gt; &quot;${ELASTICSEARCH_PASSWORD}&quot;
    index =&gt; &quot;%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}&quot;
    manage_template =&gt; false
  }
}
</code></pre><p>Elasticsearch 的配置很單純</p><pre><code>output {
  google_bigquery {
    project_id =&gt; ${GCP_PROJECT_ID}
    dataset =&gt; ${GCP_BIG_QUERY_DATASET_NAME}
    csv_schema =&gt; &quot;path:STRING,status:INTEGER,score:FLOAT&quot;
    json_key_file =&gt; ${GCP_JSON_KEY_FILE_PATH}
    error_directory =&gt; &quot;/tmp/bigquery-errors&quot;
    date_pattern =&gt; &quot;%Y-%m-%dT%H:00&quot;
    flush_interval_secs =&gt; 30
  }
}
</code></pre><p>其中的變數，我們全都用環境變數，在 deployment.yaml 配置，啟動 logstash pods 時代入</p><p><code>GCP_JSON_KEY_FILE_PATH</code> 這邊要配置一隻 GCP 的服務帳號金鑰，一個有 Big Query 寫入權限的 service account，把 json 使用 kubernetes secret 放到集群上，然後在 pod 上使用 volume from secret 掛載進來。
<code>csv_schema => "path:STRING,status:INTEGER,score:FLOAT"</code> 這邊要配置之後會存入 Big Query 的 csv 結構</p><h1 id=小結>小結<a hidden class=anchor aria-hidden=true href=#小結>#</a></h1><ul><li>部屬 Logstash deployment 到 kubernetes 上</li><li>設定 pipeline，超多 plugin，族繁不及備載</li><li>Grok 配置</li><li>Big Query output 配置</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://chechia.net/tags/%E9%90%B5%E4%BA%BA%E8%B3%BD2019/>鐵人賽2019</a></li><li><a href=https://chechia.net/tags/elasticsearch/>Elasticsearch</a></li><li><a href=https://chechia.net/tags/devops/>Devops</a></li><li><a href=https://chechia.net/tags/logstash/>Logstash</a></li></ul><nav class=paginav><a class=prev href=https://chechia.net/posts/2019-09-22-kafka-deployment-on-kubernetes/><span class=title>« Prev</span><br><span>Kafka Deployment on Kubernetes</span>
</a><a class=next href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/><span class=title>Next »</span><br><span>Monitoring GKE With Elk</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on x" href="https://x.com/intent/tweet/?text=Logstash%20on%20GKE&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f&amp;hashtags=%e9%90%b5%e4%ba%ba%e8%b3%bd2019%2celasticsearch%2cdevops%2clogstash"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f&amp;title=Logstash%20on%20GKE&amp;summary=Logstash%20on%20GKE&amp;source=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f&title=Logstash%20on%20GKE"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on whatsapp" href="https://api.whatsapp.com/send?text=Logstash%20on%20GKE%20-%20https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on telegram" href="https://telegram.me/share/url?text=Logstash%20on%20GKE&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Logstash on GKE on ycombinator" href="https://news.ycombinator.com/submitlink?t=Logstash%20on%20GKE&u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-21-logstash-on-gke%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://chechia.net/>Che-Chia Chang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>