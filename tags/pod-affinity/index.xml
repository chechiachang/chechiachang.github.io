<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pod-affinity on Che-Chia Chang</title>
    <link>https://chechia.net/tags/pod-affinity/</link>
    <description>Recent content in pod-affinity on Che-Chia Chang</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016–2020, Che-Chia Chang; all rights reserved.</copyright>
    <lastBuildDate>Thu, 19 Sep 2019 17:06:29 +0800</lastBuildDate>
    
	<atom:link href="https://chechia.net/tags/pod-affinity/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Monitoring GKE With Elk</title>
      <link>https://chechia.net/post/monitoring-gke-with-elk/</link>
      <pubDate>Thu, 19 Sep 2019 17:06:29 +0800</pubDate>
      
      <guid>https://chechia.net/post/monitoring-gke-with-elk/</guid>
      <description>2020 It邦幫忙鐵人賽 系列文章
 Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP  作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
 這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：
 node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar  上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。</description>
    </item>
    
  </channel>
</rss>