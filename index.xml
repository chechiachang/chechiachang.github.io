<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Che-Chia Chang</title>
    <link>https://chechia.net/</link>
    <description>Recent content on Che-Chia Chang</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016–2020, Che-Chia Chang; all rights reserved.</copyright>
    <lastBuildDate>Mon, 12 Sep 2022 14:31:48 +0800</lastBuildDate><atom:link href="https://chechia.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2022 09 12 14th iThome ironman-01 IaC best practice workshop on aws</title>
      <link>https://chechia.net/post/2022-09-12-14th-ithome-ironman-iac-aws-workshop-01-introduction/</link>
      <pubDate>Mon, 12 Sep 2022 14:31:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2022-09-12-14th-ithome-ironman-iac-aws-workshop-01-introduction/</guid>
      <description>
        
          
            iThome 鐵人賽好讀版
賽後文章會整理放到個人的部落格上 http://chechia.net/
追蹤粉專可以收到文章的主動推播
&amp;ndash;
AWS 為例，實現 production framework 的最佳實踐的 30 天 workshop
準備 Production environmtn Devops 面臨的問題 DevOps 的工作內容繁雜
今天想要 Deploy 一個 backend API deployment 到 k8s 上 一轉眼發現自己在修 port / servie / ingress / alb 一轉眼發現自己在修 tls certificate 一轉眼發現自己在修 node linux 上的一個 bug 一轉眼發現自己在修 monitoring / metrics + alert / log collection &amp;hellip; 我只是想 deploy 一個 backend deployment 修infra 花了好幾天，而寫 deployment 只要 2 hr Devops 的工作，是處理 developer 與 operator 中間的繁雜的細節 換個角度思考：上面這些元件全都是存在許久的功能，應該有一套統一介面隨叫即用這些服務，ex.
          
          
        
      </description>
    </item>
    
    <item>
      <title>2022 06 09 IThome 2022 DevOpsDay Introducing policy as code for terraform</title>
      <link>https://chechia.net/post/2022-06-09-ithome-devopsday-2022-proposal-introduce-policy-as-code-for-terraform-/</link>
      <pubDate>Thu, 09 Jun 2022 01:04:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2022-06-09-ithome-devopsday-2022-proposal-introduce-policy-as-code-for-terraform-/</guid>
      <description>
        
          
            Titleq 從零導入 Policy as Code 到 terraform 甘苦談 - Introducing policy as code for terraform
Presentation Google Slides
Description Terraform 是一個很棒的 Infrastructure as Code 的工具，能夠以現代的軟體工程流程來穩定的建構 infrastructure，並隨著需求變更自動化迭代，將新的 feature 安全地更新到既有的 infrastructure 上。只要是 Infrastructure 有關的問題，我一律推薦 Terraform。
這也意味 Terraform 的品質就等於 infrastructure 的品質，好的 terraform 帶你上天堂，不好的 terraform 全 team 火葬場。
Infrastructure 有太多資安的考量，新的風險不斷被檢查出來，連帶要不斷的 patch terraform code 來避免潛在的資安風險 Infrastructure 會不斷地更新，例如公有雲的 api 不斷更新，去年的 code 已經跟不上今年的最佳實踐了 好的工程師寫出的 terraform code 屌打菜鳥工程師，要如何讓團隊依循更好的實踐，避免寫出爛 code 維護 code 有 clean code / best practice，Terraform 也有 clean code 與 best practice，工程師要如何工具來輔助，是 Policy as Code 的一大課題。 本演講聚焦於實際經驗，從一大堆 terraform modules 開始，沒有 Policy as Code，到一步步評估、導入、實作、改進與迭代，逐漸的提升團隊 Terraform code 品質，提升 infrastructure 交付品質，並避免到未來潛在的風險。
          
          
        
      </description>
    </item>
    
    <item>
      <title>2022 05 21 COSCUP Operating Time Series Database in K8s</title>
      <link>https://chechia.net/post/2022-05-21-coscup-proposal-operating-time-series-database-in-k8s/</link>
      <pubDate>Sat, 21 May 2022 01:04:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2022-05-21-coscup-proposal-operating-time-series-database-in-k8s/</guid>
      <description>
        
          
            Titleq 在 k8s 上跑 time series database 甘苦談 - Operating Time Series Database in K8s
Google Slides Youtube live record: https://youtu.be/YexUnVOZC8M?t=9421
Description Influxdb 為市占最高的 time series DBMS 之一，使用上與 RDBMS 有不同優劣勢。
在維運方面，database 有許多相似需求：穩定性、高可用性、備份、還原、資源管理、調度、災難復原&amp;hellip;等。社群常聽到有人問：可不可以在 K8s 上跑 database。
本演講會分享在 k8s 中維運，實務上所遇到的問題，提供一些思考方向。
本次演講的 influxdb 版本為 Influxdb OSS / enterprise 1.9+
InfluxDB is one the the most popular time series database management system (DBMS) and is a powerful platform when dealing with time series data.
          
          
        
      </description>
    </item>
    
    <item>
      <title>2021 11 16 Ithome Cloud Summit Vault</title>
      <link>https://chechia.net/post/2021-11-16-ithome-cloud-summit-vault/</link>
      <pubDate>Tue, 16 Nov 2021 01:04:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2021-11-16-ithome-cloud-summit-vault/</guid>
      <description>
        
          
            各位好
關於這個 QRcode
每次上台前，我都會想要帶什麼樣的內容給觀眾，讓觀眾值得花 30 分鐘在底下聽。後來就習慣先發表一篇文章，把對觀眾有幫助的資源包成一包：
首先是完整投影片：https://slides.com/chechiac&amp;hellip;/terraform-introduction-a56697 逐字講稿：(最後校稿中） 然而只有本次演講內容，回去可能還是不太容易操作。所以這次附上使用 Terraform 一鍵部署 vault 的 Github Repository：https://github.com/&amp;hellip;/southe&amp;hellip;/chechia_net/vault/singleton 如果不熟 Terraform，再附上 30 天手把手 Terraform 教學文章，只要願意花時間，全篇中文一個月帶你上手 Terraform。 IThome 鐵人賽好讀版：https://ithelp.ithome.com.tw/users/20120327/ironman/4057 Github Repository 完整版：https://github.com/&amp;hellip;/terraform-30&amp;hellip;/tree/main/lecture/zh 如果遇到問題還是需要找人發問，所以再推薦兩個社群，可以來這邊發問，要找我本人也找得到。甚至只是加入潛水不講話，都可以被動吸收許多新知。 Cloud Native Taiwan User Group https://t.me/cntug https://fb.cloudnative.tw DevOps Taiwan Meetup Group https://t.me/devopstw 大家可以手機拍完這個就出去吃午餐了。 或是拍回家，然後傳給一個同事叫他花 30 天把 Terraform 跟 Vault 這些都學會。
總之希望對各位有幫助，讓國內技術力能持續進步成長。
回到本次演講。
本次演講有三個關鍵字
Kubernetes Vault Terraform 這個是隱藏的 請問平時工作會用到這三個技術之一的朋友，請舉個手，好讓我知道一下觀眾的分布，等等分享的內容會照比例做一些調整。
我們今天不會講太多 Kubernetes 的內容，重點放在 Vault，以及如何設定 Vault，所以 Terraform Infrastructure as Code 或是 configuration as Code 會在這邊跑出來。
          
          
        
      </description>
    </item>
    
    <item>
      <title>2021 09 01 Ithome Ironman Go</title>
      <link>https://chechia.net/post/2021-09-01-ithome-ironman-go/</link>
      <pubDate>Wed, 01 Sep 2021 12:25:06 +0800</pubDate>
      
      <guid>https://chechia.net/post/2021-09-01-ithome-ironman-go/</guid>
      <description>
        
          
            2021 ithome 鐵人賽開跑了～
今年的題目是「Terraform Workshop - Infrastructure as Code for Public Cloud 疫情警戒陪你度過 30 天」，是一個長達 30 天的 terraform workshop，對 terraform 有興趣的朋友歡迎追縱
Day 01 - 引言：Terraform 是個好東西。
課程內容與代碼會放在 Github 上: https://github.com/chechiachang/terraform-30-days
賽後文章會整理放到個人的部落格上 http://chechia.net/
追蹤粉專可以收到文章的主動推播
          
          
        
      </description>
    </item>
    
    <item>
      <title>DevOps Taiwan Meetup #33: Hashicorp Vault for Kubernetes</title>
      <link>https://chechia.net/post/2021-05-13-devops-taiwan-33-hashicorp-vault-for-kubernetes-apps/</link>
      <pubDate>Thu, 13 May 2021 16:29:26 +0800</pubDate>
      
      <guid>https://chechia.net/post/2021-05-13-devops-taiwan-33-hashicorp-vault-for-kubernetes-apps/</guid>
      <description>
        
          
            Event https://devops.kktix.cc/events/meetup33-maicoin-devops-taiwan https://youtu.be/8hEifTAWnY0?t=3269 audience: 90/90 resources this presentation
https://slides.com/chechiachang/terraform-introduction-a56697 github
https://github.com/chechiachang/terraform-azure https://github.com/chechiachang/vault-playground/tree/master/deploy/v0.8.0 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: Atlantis</title>
      <link>https://chechia.net/post/2020-10-07-terraform-infrastructure-as-code-atlantis/</link>
      <pubDate>Wed, 07 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-07-terraform-infrastructure-as-code-atlantis/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
需求與問題 隨著 terraform 在團隊內的規模持續成長，團隊需要讓工作流程更加順暢，來面對大量的 tf 變更查核與變更請求。想像幾十個工程師同時在修改幾十個不同的 terraform projects / modules，這時可能會有幾個問題
需要一個穩定乾淨的環境執行 terraform 工程師的開發本機不是個好選擇 需要 24/7 的 terraform 執行中心 執行中心會有各個環境 (dev / stage / prod) 的存取權限，希望設置在內部 下列兩個工作會切換工作平台，例如 Github review，檢視 difference，與討論 PR review 完有時會忘記 merge，merge 完有時會忘記 apply repository 越多，忘得越多&amp;hellip; 團隊已經導入 Git-flow，希望把工作流程做得更完整自動化更加便利
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: Terragrunt</title>
      <link>https://chechia.net/post/2020-10-06-terraform-infrastructure-as-code-terragrunt/</link>
      <pubDate>Tue, 06 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-06-terraform-infrastructure-as-code-terragrunt/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
上面講解 Terraform 的基本操作流程，提供範本原始碼，以及一步一步導入的詳細步驟。各位應該都可以依照上面幾篇的說明，開始快樂的使用 Terraform 了。
而當使用 Terraform 的規模越來越大，管理的資料越來越多時，開始會出現一些問題，例如重複的 terraform code 越來越多，協同工作 review 不太容易，state 的內容管理與鎖管理，等等。這些問題可以透過一些工作流程的改進，或是導入新的小工具，來改善工作效率。
接下來筆者推薦幾個心得與工具，希望能提升使用 Terraform 的效率與產值
以下幾篇文章，適合已經使用過 terraform 一點時間，有經驗的團隊，並打算更大規模導入 terraform，正在尋求改善的方向。
心得 CI/CD 全自動化 State backend 選擇 最佳實踐 https://www.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: Recommended Practices</title>
      <link>https://chechia.net/post/2020-10-05-terraform-infrastructure-as-code-recommended-practices/</link>
      <pubDate>Mon, 05 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-05-terraform-infrastructure-as-code-recommended-practices/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
上面講解 Terraform 的基本操作流程，提供範本原始碼，以及一步一步導入的詳細步驟。各位應該都可以依照上面幾篇的說明，開始快樂的使用 Terraform 了。
以下幾篇文章，適合已經使用過 terraform 一點時間，有經驗的團隊，並打算更大規模導入 terraform，正在尋求改善的方向。
心得 CI/CD 全自動化 State backend 選擇 最佳實踐 工具 Terraform Atlantis Terragrunt 工具與文化 新工具提供解決方案，然而單純導入工具後不是就一勞永逸，許多實務上的問題，還是要依賴改善工作流程，並且避免整體運作的錯誤。
其次，不同團隊已有既有的團隊文化，整合新的工具後還是需要磨合，不一定要照單全收。換句話說，工作流程的不斷改進也是解決方案的一環。
建議實踐 Recommended Practices Terraform 官網有許多建議的實作與導入流程，其中大部分的建議我們都已經在前面的幾篇文章中提到，這邊要來說明一下，並補充其他官方推薦的實踐。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: Backends</title>
      <link>https://chechia.net/post/2020-10-04-terraform-infrastructure-as-code-backend/</link>
      <pubDate>Sun, 04 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-04-terraform-infrastructure-as-code-backend/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
上面講解 Terraform 的基本操作流程，提供範本原始碼，以及一步一步導入的詳細步驟。各位應該都可以依照上面幾篇的說明，開始快樂的使用 Terraform 了。
而當使用 Terraform 的規模越來越大，管理的資料越來越多時，開始會出現一些問題，例如重複的 terraform code 越來越多，協同工作 review 不太容易，state 的內容管理與鎖管理，等等。這些問題可以透過一些工作流程的改進，或是導入新的小工具，來改善工作效率。
接下來筆者推薦幾個心得與工具，希望能提升使用 Terraform 的效率與產值
以下幾篇文章，適合已經使用過 terraform 一點時間，有經驗的團隊，並打算更大規模導入 terraform，正在尋求改善的方向。
心得 CI/CD 全自動化 State backend 選擇 最佳實踐 https://www.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: CI/CD automation</title>
      <link>https://chechia.net/post/2020-10-03-terraform-infrastructure-as-code-automation/</link>
      <pubDate>Sat, 03 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-03-terraform-infrastructure-as-code-automation/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
上面講解 Terraform 的基本操作流程，提供範本原始碼，以及一步一步導入的詳細步驟。各位應該都可以依照上面幾篇的說明，開始快樂的使用 Terraform 了。
而當使用 Terraform 的規模越來越大，管理的資料越來越多時，開始會出現一些問題，例如重複的 terraform code 越來越多，協同工作 review 不太容易，state 的內容管理與鎖管理，等等。這些問題可以透過一些工作流程的改進，或是導入新的小工具，來改善工作效率。
接下來筆者推薦幾個心得與工具，希望能提升使用 Terraform 的效率與產值
以下幾篇文章，適合已經使用過 terraform 一點時間，有經驗的團隊，並打算更大規模導入 terraform，正在尋求改善的方向。
心得 CI/CD 全自動化 State backend 選擇 最佳實踐 https://www.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code: Example repository</title>
      <link>https://chechia.net/post/2020-10-02-terraform-infrastructure-as-code-repository-example/</link>
      <pubDate>Fri, 02 Oct 2020 11:15:48 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-10-02-terraform-infrastructure-as-code-repository-example/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
上面講了很多 terraform 的操作範例，應該看到這裡，對於 terraform 基本上是什麼東西，應該有些概念了。然而這樣還不能算是學會 terraform，這種工具的東西一定要有實際操作過的經驗才算是學會。
可以直接參考 Terraform 官方的 Get-started 文件來操作學習，我這邊也提供一個 Git repository 讓大家上手，當作初次操作的框架。
提供做為範例的原始碼 這個 Github Repository 是我給社群演講所使用的範例，第一次使用的可以參考
https://github.com/chechiachang/terraform-playground
1tree 2├── README.md 3├── SOP.md 4├── aws/ 5├── azure/ 6└── gcp/ TL;DR 選擇使用的雲平台，這邊提供三家範例，例如我這邊使用 gcp，當然你就要準備 GCP 的帳號，並且下載有執行權限的用戶 credential json key 等等。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Kubernetes</title>
      <link>https://chechia.net/post/2020-09-26-gcp-preemptible-instance-kubernetes/</link>
      <pubDate>Sat, 26 Sep 2020 17:24:20 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-26-gcp-preemptible-instance-kubernetes/</guid>
      <description>
        
          
            先占虛擬機與 Kubernetes 在 GCP 使用先占虛擬機，會需要面對先占虛擬機的額外限制
資料中心會 (可預期或不可預期地) 終止先占虛擬機 先占虛擬機不能自動重啟，而是會被資料中心終止後回收 GCP 不保證有足夠的先占虛擬機 節點的終止會造成額外的維運成本，例如
管理多個節點，容忍先占虛擬機的移除，自動補充新的先占虛擬機 管理多個應用複本，節點終止時，維護整體應用的可用性 將移除節點上的應用，重新排程到其他可用節點 動態維護應用複本的服務發現 (Service Discovery) 與服務端點 (Endpoints) 意思是應用關閉重啟後，換了一個新 IP，還要能持續存取應用。舊的 IP 要主動失效 配合應用的健康檢查 (Health Check) 與可用檢查 (Readiness Check)，再分配網路流量 這些需求，必須要有自動化的管理工具，是不可能人工管理的，想像你手上使用 100 個先占節點，平均每天會有 10% - 15% 的先占節點被資料中心回收，維運需要
補足被移除的 15 個節點 計算被移除的應用，補足移除的應用數量 移除失效的應用端點，補上新的應用端點 持續監控應用狀態 &amp;hellip; 沒有自動化管理工具，看了心已累 (貓爪掩面)
我們使用 Kubernetes 協助維運自動化，在 GCP 上我們使用 GKE，除了上述提到的容器應用管理自動化外，GKE 還額外整合先占虛擬機的使用
啟用先占虛擬機的節點池 (node-pool)，設定節點池的自動拓展，自動補足先占節點的數量 GKE 自動維護先占虛擬機的 labels 關於 GKE 的先占虛擬機的完整細節，請見GCP 官方文件。這份文件底下也提供了 GCP 官方建議的先占虛擬機最佳實踐
架構設計需要假設，部分或是全部的先占虛擬機都不可用的情形 Pod 不一定有時間能優雅終止 (graceful shutdown) 同時使用隨選虛擬機與先占虛擬機，以維持先占虛擬機不可用時，服務依然可用 注意節點替換時的 IP 變更 避免使用有狀態的 Pod 在先占虛擬機上 (這點稍後的文章，我們會試圖超越) 使用 node taint 來協助排程到先占虛擬機，與非先占虛擬機 總之，由於有容器自動化管理，我們才能輕易的使用先占虛擬機。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Introduction</title>
      <link>https://chechia.net/post/2020-09-26-gcp-preemptible-instance-introduction/</link>
      <pubDate>Sat, 26 Sep 2020 11:03:40 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-26-gcp-preemptible-instance-introduction/</guid>
      <description>
        
          
            先占虛擬機，技術文件二三事 第一篇的內容大部份還是翻譯跟講解官方文件。後面幾篇才會有實際的需求與解決方案分析。
Google 先占虛擬機官方文件
使用不熟悉的產品前一定要好好看文件，才不會踩到雷的時候，發現人家就是這樣設計的，而且文件上寫得清清楚楚。以為是 bug 結果真的是 feature，雷到自己。先占虛擬機是用起來跟普通虛擬機沒什麼兩樣，但實際上超級多細節要注意，毛很多的產品，請務必要小心使用。
以下文章是筆者工作經驗，覺得好用、確實有幫助公司，來跟大家分享。礙於篇幅，這裡只能非常粗略地描述我們團隊思考過的問題，實際上的問題會複雜非常多。文章只是作個發想，並不足以支撐實際的業務，所以如果要考慮導入，還是要
多作功課，仔細查閱官方文件，理解服務的規格 深入分析自身的需求 基於上面兩者，量化分析 什麼是先占虛擬機器(Preemptible Instance) 先占虛擬機器，是資料中心的多餘算力，讀者可以想像是目前賣剩的機器，會依據資料中心的需求動態調整，例如
目前資料中心的算力需求低，可使用的先占虛擬機釋出量多，可能可以用更便宜的價格使用 目前資料中心算力需求高，資料中心會收回部分先占虛擬機的額度，轉化成隨選付費的虛擬機 (pay-as-you-go) 由於先占虛擬機會不定時（但可預期）地被資料中心收回，因此上頭執行的應用，需要可以承受機器的終止，適合有容錯機制 (fault-tolerant) 的應用，或是批次執行的工作也很適合。
先占機器的優缺點 除了有一般隨選虛擬機的特性，先占虛擬機還有以下特點
比一般的虛擬機器便宜非常多，這也是我們選用先占虛擬機優於一般虛擬機的唯一理由 先占虛擬機有以下限制，以維運的角度，這些都是需要考量的點。
GCP 不保證會有足夠的先占虛擬機 先占虛擬機不能直接轉換成普通虛擬機 資料中心觸發維護事件時(ex. 回收先占虛擬機)，先占虛擬機不能設定自動重啟，而是會直接關閉 先占機器排除在 GCP 的服務等級協議 (SLA)之外 先占虛擬機不適用GCP 免費額度 費用粗估試算 至於便宜是多便宜呢？這邊先開幾個例子給各位一些概念。
以常用的 N1 standard 虛擬機：https://cloud.google.com/compute/vm-instance-pricing#n1_standard_machine_types
Hourly Machine type	CPUs	Memory	Price (USD)	Preemptible price (USD) n1-standard-1	1	3.75GB	$0.0550	$0.0110 n1-standard-2	2	7.5GB	$0.1100	$0.0220 n1-standard-4	4	15GB	$0.2200	$0.0440 n1-standard-8	8	30GB	$0.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Resource Calculation</title>
      <link>https://chechia.net/post/2020-09-25-gcp-preemptible-instance-resource-calculation/</link>
      <pubDate>Fri, 25 Sep 2020 12:22:02 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-25-gcp-preemptible-instance-resource-calculation/</guid>
      <description>
        
          
            關於資源評估 架構團隊提供虛擬機給應用，有個問題時常出現：應該分配多少資源給應用？例如：後端準備一個 API server，SRE 這邊要準備多少什麼規格的機器？
以往使用虛擬機直接部署應用時，會需要明確規劃各群虛擬機，各自需要執行的應用，如果沒有做資源的事前評估，有可能放上機器運行後就發生資源不足。
導入 Kubernetes 後，透過節點池 (Node Pool) 形成一個大型資源池，設定部署的政策後，讓 Kubernetes 自動調度應用：
每一個節點的資源夠大，使得應用虛擬機器上所佔的比例相對較小，也就是單一應用的調度不會影響節點的整體負載 如果節點太小，調度應用就會有些侷促，例如：一個 API server 均載時消耗 1 cpu 滿載時消耗 2 cpu。準備 3 cpu 的虛擬機，調度應用時幾乎是遷移整台虛擬機的負載 此外還有機會因為上篇提到的資源保留，造成調度失敗。如果準備 24 cpu 的機器，調度起來彈性就很大，對節點的性能衝擊也比較低 只需要估計整體的資源消耗率計算需求，配合自動擴展，動態器補足不足的資源 例如：估計總共需要 32 cpu ，準備 36 cpu 的虛擬機，當滿載時依據 cpu 壓力自動擴容到 48 cpu 希望整體資源的使用率夠高，當然預留太多的資源會造成浪費 要控管 Kubernetes 的資源使用量也可設定資源需求與資源限制，延伸閱讀。
估計得越準確，當然實際部署的資源掌握度就越高，然而筆者過去的經驗，團隊在交付源碼時未必就能夠做出有效的資源消耗評估，那有沒有什麼辦法可以幫助我們？
資源需求估估看 如果應用開發團隊，有先作應用的 profiling，然後 release candidate 版本有在 staging 上作壓力測試的話，維運團隊這邊應該就取得的數據，做部署前的資源評估。
應用在不同狀態或是工作階段，會消耗不同的資源
例如：運算密集的 batch job 可能會有
控制節點 (master node) 啟動後會佔有一定的資源，一般來說不會消耗太多，只是需要為控制節點優先保留資源 工作節點 (worker node) 啟動時會需要預留足夠的資源，接收工作後會逐漸增加資源使用，拉到滿載 例如：面向用戶的服務，可能會有
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Requirement</title>
      <link>https://chechia.net/post/2020-09-24-gcp-preemptible-instance-requirement/</link>
      <pubDate>Thu, 24 Sep 2020 13:39:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-24-gcp-preemptible-instance-requirement/</guid>
      <description>
        
          
            需求規劃 使用先占節點比起使用一般隨選虛擬機，會多出許多技術困難需要克服，只有節省下的成本大於整體技術成本時，我們才會選用先占節點。因此這邊要進行成本精算，重新調整的架構下，實際到底能省多少錢。務必使用 Google Cloud Pricing Calculator 精算成本。
另外，雖然先占虛擬機會有很多額外的限制與技術困難，但實務上還是要對比實際的需求，有些限制與需求是衝突的，有些限制則完全不會影響我們的需求。前者當然會帶給我們較高的導入難度，後者可能會非常輕鬆。
這邊想給大家的概念是，務必先明確需求，再討論技術。這點很重要，技術的適用與否，不是由個人的喜好決定，唯一的判斷標準，是能不能有效率的滿足需求。
所以這邊先定義我們以下幾個需求：
執行短期的 batch job 執行長期的 user-facing API server 執行長期的 stateful 資料庫、儲存庫 Batch Job 常見的範例，例如
使用網路爬蟲 (crawler) 去抓取許多網站的所有內容 使用 GPU 進行機器學習的 Model Training 大數據計算 MapReduce 這些任務的核心需求，很簡單直接
盡快完成整體工作 盡可能節省大量算力成本 例如：我手上的機器學習 Model 粗略估計 10000 小時*GPU 的算力需求，才能產出一個有效的Model。由於大量的算力需求，一般來說都會選擇分散式的運算框架 (ex. MapReduce) ，將真正消耗算力的工作，使用分而化之 (divide and conquer) 的架構設計，將分配任務的控制節點 (master)，與實際進行運算的工作節點(worker) 拆分。基於原本的分散式架構，幾乎可以無痛地將工作節點轉移到先占虛擬機上。
根據上述的需求，這類的工作特性可能有
CPU / GPU 算力需求高的運算節點 (Worker) Worker 本身是無狀態的 Stateless 可控的即時負載 將整體工作切分成任務單元 (task)，分配給工作節點 任務單元的狀態外部保留，工作節點可容錯 (fault-tolerent)，任務單元可復原 由於先占虛擬機可能是浮動價格，這類工作可以根據優先程度，調整合適的工作時間，例如在資料中心算力需求低，先占虛擬機的費用低廉時，啟用較多的工作節點加快運算，如果費用高時，可以降低先占虛擬機的使用，延後工作，甚至是調用不同區域，費用低的工作節點，來降低整體的成本。
執得注意的是，這類任務的控制節點 (master)，也許是集中式的，也許是分散式的，需要根據性質考量，是否適合放在先占虛擬機上。有些架構控制節點可以容錯，然而錯誤發生後會需要復原狀態，這時會消耗額外的算力，可能會拖緩整體進度，造成算力的消耗。也許就可以考量使用隨選虛擬機配合使用。
User-facing services 常見的範例，例如
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Speficication</title>
      <link>https://chechia.net/post/2020-09-23-gcp-preemptible-instance-speficication/</link>
      <pubDate>Wed, 23 Sep 2020 16:23:14 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-23-gcp-preemptible-instance-speficication/</guid>
      <description>
        
          
            先占虛擬機終止流程 (Preemption process) 子曰：未知生焉知死。但做工程師要反過來，考量最差情形，也就是要知道應用可能如何死去。不知道應用可能怎麼死，別說你知道應用活得好好的，大概想表達這麼意思。
這對先占虛擬機來說特別重要，一般應用面對的機器故障或是機器終止，在使用先占西你幾的狀況下，變成每日的必然，因此，需要對應用的終止情境，與終止流程有更精細的掌控。如同前幾篇所說的，先占虛擬機會被公有雲收回，但收回的時候不會突然機器就 ben 不見，會有一個固定的流程。
如果你的應用已經帶有可容錯的機制，能夠承受機器突然變不見，服務還好好的，仍然要花時間理解這邊的流程，藉此精算每天虛擬機的終止與替換：應用會有什麼反應，會產生多少衝擊，稍後可以量化服務的影響。例如
應用重啟初始化時 cpu memory 突然拉高 承受節點錯誤後的復原流程，需要消耗額外算力。例如需要從上個 checkpoint 接續做，需要去讀取資料造成 IO，或是資料需要做 rebalance &amp;hellip;等等 如果你的應用需要有 graceful shutdown 的機制，那你務必要細心理解這邊的步驟。並仔細安排安全下樁的步驟。又或是無法保證在先占虛擬機回收的作業時限內，完成優雅終止，需要考慮其他可能的實作解法。
這邊有幾個面向要注意
GCP 如何終止先占節點 GCP 移除節點對 GKE 、以及執行中應用的影響 GKE 集群如何應對的節點失效 GCP 自動調度補足新的先占節點 GKE 集群如何應對節點補足 三個重點
先占虛擬機終止對集群的影響 Pod 隨之終止對應用的影響，是否能夠優雅終止 有沒有方法可以避免上面兩者的影響 劇透一下：有的，有一些招式可以處理。讓我們繼續看下去。
GCP 如何終止虛擬機 先占虛擬機的硬體終止步驟與一般隨選虛擬機相同，所以我們要先理解虛擬機的停止流程
這裡指的終止 (Stop) 是虛擬機生命週期 的 RUNNING -&amp;gt; instances.stop() -&amp;gt; STOPPING -&amp;gt; TERMINATED 的步驟。
instances.stop() ACPI shutdown OS 會進行 shutdown 流程，並嘗試執行各個服務的終止流程，以安全的終止服務。如果虛擬機有設定Shtudown Script 會在這步驟處理 等待至少 90 秒，讓 OS 完成終止的流程 逾時的終止流程，GCP 會直接強制終止，就算 shutdown script 還沒跑完 GCP 不保證終止時限的時間，官方建議不要寫重要的依賴腳本在終止時限內 虛擬機變成 TERMINATED 狀態 GCP 如何終止先占虛擬機 與隨選虛擬機不同
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance Requirement Distributed</title>
      <link>https://chechia.net/post/2020-09-22-gcp-preemptible-instance-requirement-distributed/</link>
      <pubDate>Tue, 22 Sep 2020 14:39:00 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-22-gcp-preemptible-instance-requirement-distributed/</guid>
      <description>
        
          
            我們以下幾個需求：
執行短期的 batch job 執行長期的 user-facing API server 執行長期的 stateful 資料庫、儲存庫 該不該在 Kubernetes 上面跑 database？
TL;DR ，如果你剛開始考慮這件事，通常的答案都是否定的
等等，我們這邊不是討論該不該上 Kuberentes ，而是該不該使用先占虛擬機吧。然而由於先占虛擬機節點的諸多限制，光憑先占虛擬機並不適合跑任何持久性的儲存庫。我們這邊仰賴 Kubernetes 的網路功能 (e.g. 服務發現)，與自動管理 (e.g. health check，HPA，auto-scaler)，基於先占虛擬機，建構高可用性的服務架構，來支撐高可用，且有狀態的的儲存庫。
應用是否適合部署到 Kubernetes 上，可以看這篇 Google Blog: To run or not to run a database on Kubernetes: What to consider，如果大家有興趣，再留言告訴我，我再進行中文翻譯。
文中針對三個可能的方案做分析，以 MySQL 為例：
Sass，GCP 的 Cloud SQL 最低的管理維運成本 自架 MySQL 在 GCP 的 VM 上，自行管理 自負完全的管理責任，包含可用性，備份 (backup)，以及容錯移轉 (failover) 自架 MySQL 在 Kubernetes 上 自負完全的管理責任 Kubernetes 的複雜抽象層，會加重維運工作的複雜程度 然而 RDBMS 的提供商，自家也提供 Operator
          
          
        
      </description>
    </item>
    
    <item>
      <title>Gcp Preemptible Instance</title>
      <link>https://chechia.net/post/2020-09-21-gcp-preemptible-instance/</link>
      <pubDate>Mon, 21 Sep 2020 09:22:17 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-21-gcp-preemptible-instance/</guid>
      <description>
        
          
            前言 鐵人賽的第二部分，要帶來公有雲省錢系列文章。
架構的成本，很多時候會影響架構的設計與需求。公司的營運都需要在成本與需求之前平衡，成本其實是影響公司決策的重要因素。身為架構管理員，應該要試著量化並且進行成本管理，提出解決方案時，也需要思考如何幫公司開源節流。
一昧消減架構的成本也未必是最佳方案，帳面上消減的成本有時也會反映在其他地方，例如：使用比較便宜的解決方案，或是較低的算力，但卻造成維運需要花更多時間維護，造成隱性的人力成本消耗。用什麼替代方案 (trade-off) 省了這些錢。
Kubernetes 是一個很好的例子：例如：有人說「Kubernetes 可以省錢」，但也有人說「Kubernetes 產生的 Overhead 太重會虧錢」。
「要不要導入 Kubernetes 是一個好問題」。應該回歸基本的需求，了解需求是什麼。例如：Google 當初開發容器管理平台，是面對什麼樣的使用需求，最終開發出 Kubernetes，各位可以回顧前篇文章「Borg Omega and Kubernete，Kubernetes 的前日今生，與 Google 十餘年的容器化技術」，從 Google 的角度理解容器管理平台，反思自身團隊的實際需求。
這套解決方案是否真的適合團隊，解決方案帶來的效果到底是怎樣呢？希望看完這系列文章後，能幫助各位，從成本面思考這些重要的問題。
這篇使用 GCP 的原因，除了是我最熟悉的公有雲外，也是因為 GCP 提供的免費額度，讓我可以很輕鬆地作為社群文章的 Demo，如果有別家雲平台有提供相同方案，請留言告訴我，我可能就會多開幾家不同的範例。
先占虛擬機 TL;DR 先占虛擬機為隨選虛擬機定價的 2-3 折，使用先占虛擬機可能可以節省 7 成的雲平台支出 先占虛擬機比起隨選虛擬機，外加有諸多限制，e.g. 最長壽命 24 hr、雲平台會主動終止先占虛擬機&amp;hellip;等 配合使用自動水平擴展 (auto-scaler)，讓舊的先占虛擬機回收的同時，去購買新的先占虛擬機 配合可容錯 (fault-tolerent) 的分散式應用，讓應用可以無痛在虛擬機切換轉移，不影響服務 要讓應用可以容錯，需要做非常多事情 搭配 kubernetes ，自動化管理來簡化工作 配合正確的設定，可以穩定的執行有狀態的分散式資料庫或儲存庫 或是看 Google 官方 Blog：Cutting costs with Google Kubernetes Engine: using the cluster autoscaler and Preemptible VMs
預計內容
          
          
        
      </description>
    </item>
    
    <item>
      <title>Borg Omega and Kubernetes Translation 全文翻譯</title>
      <link>https://chechia.net/post/2020-09-12-borg-omega-and-kubernetes/</link>
      <pubDate>Sat, 12 Sep 2020 13:50:52 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-12-borg-omega-and-kubernetes/</guid>
      <description>
        
          
            前言 這是原文完整版本。太長不讀 (TL;DR) 請見Borg Omega and Kubernetes 前世今生摘要
原文：https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44843.pdf
摘要 在 container 技術夯起來前，Google 已經做了 container 十幾年，過程中發展出需三套容器管理系統。雖然每一代系統的開發需求不同，但每一代都深受上一代影響。這篇文章描述 Google 開發這些系統時，學到的經驗。
第一套 container management 系統是 Borg，為了管理 1. 長期執行的服務 2. 批次的短期工作 (batch job)，原本分別是由 Babysitter 與 Global Work Queue 兩套系統分開管理。後者的架構深刻影響 Borg，但 Global Work Queue 專注於 batch job。兩套系統都在 Linux control groups 之前。Borg 將上述兩種應用放在共享的機器上，來增加資源的使用率，以節省成本。這種共享基於支援 container 的 Linux Kernel (Google 也貢獻許多 Linux kernel container 程式碼)，提供更好的隔離 (isolation) 給延遲敏感的使用者服務 (latency-sentitive user-facing services)，以及消耗大量 cpu 的 batch 程式。
越來越多應用都在 Borg 上開發執行， Google 的應用與 infratructure 團隊開發許多工具與服務，形成 Borg 生態系。這些系統提供設定 (configure) 與更新 (update) 工作、預測資源需求、動態推送設定到執行中的工作、服務發現 (service discovery) 與負載均衡 (Load balancing)，等等功能。這些生態系的開發基於 Google 不同團隊的需求，產生一個不同起源 (heterogeneous)、只針對各別需求的 (ad-hoc) 一個堆不同系統，Borg 的使用者需要使用不同的程式語言與程序，來與這些系統互動。Borg 仍然是 Google 主要的容器管理系統，因為他規模 (scale) 巨大，功能多樣，而且極度堅固 (robustness)。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Borg Omega and Kubernetes TLDR 摘要翻譯</title>
      <link>https://chechia.net/post/2020-08-26-borg-omega-and-kubernetes-tldr/</link>
      <pubDate>Wed, 26 Aug 2020 13:50:52 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-08-26-borg-omega-and-kubernetes-tldr/</guid>
      <description>
        
          
            這是原文翻譯的太長不讀 (TL;DR) 版本。完整翻譯請見Borg Omega and Kubernetes 前世今生浩文完整翻譯
原文：https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44843.pdf
前言 Borg 以前就有應用管理系統，那時還沒有 Linux control group Borg 是第一套統一的 container-management system Borg 仍被大規模的使用，有許多功能而且非常堅固 Omega 繼承 Borg 上成功的設計，並希望改進 Borg 的生態系 Kubernetes 開源 透過 REST API 溝通 client 應用開發導向，著重於開發者的需求，希望能簡單的部署複雜的系統 Container Google 使用 Container 來提昇 utilization 把 batch jobs 跟預留資源的服務 (user-facing app) 放在一起，使用閒置時的資源跑 batch job 現代 container 的定義是 runtime-isolation 與 image Application-oriented infrastructure container 使用久了，不只滿足 utilization 的需求 資料中心從機器導向變成應用導向 Container 封裝環境，把機器與 OS 的依賴抽象化 應用不依賴 部署流程 runtime infrastrcture Container scope 在應用上，專注在應用管理而不是機器管理 Application environment cgroup, chroot, namespace 原本的目的是為了保護應用，不被其他應用影響 混合使用可以在應用與 OS 間產生抽象層，解耦 app 與 OS 提供完全相同的部署環境，避免切換環境(ex.
          
          
        
      </description>
    </item>
    
    <item>
      <title>2020 08 Season Review</title>
      <link>https://chechia.net/post/2020-08-19-season-review/</link>
      <pubDate>Wed, 19 Aug 2020 10:01:31 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-08-19-season-review/</guid>
      <description>
        
          
            季中回顧
這一季開了很多新坑，卻來不及寫文章填上
完成的有 Terraform 的基礎與實務導入經驗
正在趕工的有 hashicorp vault，Gitops，與 tls。
其中 GitOps 已經有強者我朋友 Hwchiu 巨巨填坑了，我這邊就會偷懶跳過。友情連結
剩下的希望本季結束前能填完(掩面)
已填坑 從零開始導入 Terraform DevOps Taiwan Meetup iThome Cloud Summit 新坑，碼農正在耕田，挖坑自己跳 hashicorp vault install basic operation Sign &amp;amp; manage x509 certificate with pki secret engine 填坑中，文章尚未完成 aws
post/play-aws-eks-with-low-cost: 精算小神童，如何用最少的 credits 玩 aws eks 服務 tls
post/openssl-self-sign-tls-with-own-ca post/k8s-manage-tls-certificate gitOps
post/gitops-with-argo-cd terraform
post/terraform-infrastructure-as-code-module kubernetes
borg, omega, and kubernetes 作者外出取材中&amp;hellip; MIT 6.824 Distributed System Learning Note 
          
          
        
      </description>
    </item>
    
    <item>
      <title>Terraform Infrastructure as Code Transcript</title>
      <link>https://chechia.net/post/2020-06-15-terraform-infrastructure-as-code-transcript/</link>
      <pubDate>Mon, 15 Jun 2020 10:58:56 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-06-15-terraform-infrastructure-as-code-transcript/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
各位好
About this presentation 開始之前，先分享一些資源
投影片 講稿 程式碼 SOP 範本 Facebook 粉專 都放在這裡，因為有附逐字稿，所以如果很忙的朋友，掃了 QR code 就可以回家自己看了，不用客氣。
然後有興趣在追這系列文章的，可以幫我 facebook 粉專按個讚跟追蹤，每周新文章出來，會推播通知。
文章在 chechia.net 上，新文章通知靠 facebook 粉專這樣。也可以只追蹤不按讚。我自己看別人技術 blog 也很常這樣(XD
          
          
        
      </description>
    </item>
    
    <item>
      <title>從零開始的 Infrastructure as Code: Terraform - 01</title>
      <link>https://chechia.net/post/2020-06-14-terraform-infrastructure-as-code/</link>
      <pubDate>Sun, 14 Jun 2020 16:46:09 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-06-14-terraform-infrastructure-as-code/</guid>
      <description>
        
          
            This article is part of 從零開始的 Infrastructu as Code: Terraform
Get-started examples / SOP on Github Introducation to Terraform Iac: Speaker transcript Presentation Check my website chechia.net for other blog. Follow my page to get notification. Like my page if you really like it :)
Outlline our story: issues, steps, &amp;amp; results basics IaC, terraform benefits risks and 坑 to be or not to be experience oriented
Our stories 100+ devs, many teams 25+ projects 50+ GKEs 80+ SQLs IAMs, redis, VPCs, load-balancers, &amp;hellip; Issues Ops manually create resources through GUI by SOP.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Say Goodbye 2019</title>
      <link>https://chechia.net/post/2019-12-31-say-goodbye-2019/</link>
      <pubDate>Tue, 31 Dec 2019 18:38:51 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-12-31-say-goodbye-2019/</guid>
      <description>
        
          
            2019 年度回顧
          
          
        
      </description>
    </item>
    
    <item>
      <title>MIT 6.824 Distributed System Learning Note</title>
      <link>https://chechia.net/post/2019-12-16-mit-6.824-distributed-system/</link>
      <pubDate>Mon, 16 Dec 2019 23:46:46 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-12-16-mit-6.824-distributed-system/</guid>
      <description>
        
          
            跟著 MIT 6.824 深入淺出分散式系統
          
          
        
      </description>
    </item>
    
    <item>
      <title>Ablockchain Atomic Swap</title>
      <link>https://chechia.net/post/2019-11-08-blockchain-atomic-swap/</link>
      <pubDate>Fri, 08 Nov 2019 08:03:30 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-11-08-blockchain-atomic-swap/</guid>
      <description>
        
          
            https://en.bitcoin.it/wiki/Atomic_swap
Algorithm 2 pay txs and 2 claim tx claim txs are singed at first, locked with time 2 pay txs are encrypted by x, affects only when x is reveal on the network Initialization A: random number x
tx1: A pay B A Pay BTC to B&amp;rsquo;s public key if x known &amp;amp; singed by B or Signed by A &amp;amp; B
tx2: A claim tx1 pay BTC to A&amp;rsquo;s public key locked 48 hours signed by A
          
          
        
      </description>
    </item>
    
    <item>
      <title>Blockchain Bep3 Atomic Swap</title>
      <link>https://chechia.net/post/2019-10-22-blockchain-bep3-atomic-swap/</link>
      <pubDate>Tue, 22 Oct 2019 10:35:20 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-22-blockchain-bep3-atomic-swap/</guid>
      <description>
        
          
            BEP3 Atomic Swap Binance 在 BEP3: HTLC and Atomic Peg 提到，BEP 即將在 binance chain 上支援原生的 Hash Timer Locked Transfer (HTLT) ，這使跨鏈的原子性交換 (atomic swap) 變得可行，透過 HTLC 在兩邊的鏈上鎖住 (peg) tokens，然後只有在執行交換的時候，透過 hash 交換，一次執行雙邊的交易。
關於 Atomic Swap 網路有非常多的訊息，有興趣的話可以看這篇
交易只有在雙邊完成後才完成，完成之前不能動用交換的資產 在任何階段失效都可以完全 fallback，並進行 refund 交易的認證是去中心化的 這邊有個但書，Ethereum 上是透過 smart contract 實現，但 Binance chain 上還是靠 Binance 認證 XD Binance 在 BEP3 中支援 HTLC，我們這邊主要的資訊來源是 binance.org 的官方說明文件，這邊針對文章進行驗證，並且補足文件缺漏的部分，提醒過程中可能會踩到的雷。
跨鍊(Cross Chain) 交易 在部署 asset / token 的時候，我們會選擇合適的鏈作為發布資產並運行 block chain app。常用的應用鏈如 ethereum 與 binance chain 等等。不同的主鏈上有各自的優缺點，例如使用 ethereum ，可以與許多 token 與應用互動，也是最多人使用的應用主鏈。而在 binance 鏈上執行，則能夠快速的發生 transactions，並且可以與 binance 上的資產與交易所互動。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Custom Resources with Operator SDK</title>
      <link>https://chechia.net/post/2019-10-15-kubernetes-custom-resource-with-operator-sdk/</link>
      <pubDate>Tue, 15 Oct 2019 17:28:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-15-kubernetes-custom-resource-with-operator-sdk/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 超簡短推坑 oeprator-sdk 鐵人賽心得 承上 上篇介紹了 crd 與 controller，然而沒有說明 controller 的編寫與操作，因為 controller 的部分比較複雜，我們鐵人挑戰賽尾聲，篇幅說實在是不太夠。
有興趣詳細了解的大德，請參考相同鐵人挑戰團隊的隊友文章，裏頭對 controller 有詳細介紹，這邊就不贅述。直接提供個人使用覺得最簡單上手的 operator sdk
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Custom Resource Deployment</title>
      <link>https://chechia.net/post/2019-10-13-kubernetes-custom-resource-deployment/</link>
      <pubDate>Sun, 13 Oct 2019 22:03:08 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-13-kubernetes-custom-resource-deployment/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 CRD 內容 Deploy CRD Use custom resource Recap 在上次的 cert-manager 內容中我們走過 cert-manager 的安裝步驟，其中有一個步驟是 apply cert-manager 的 manigests 檔案 *.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Custom Resources Basic</title>
      <link>https://chechia.net/post/2019-10-13-kubernetes-custom-resources-basic/</link>
      <pubDate>Sun, 13 Oct 2019 17:28:12 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-13-kubernetes-custom-resources-basic/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 custom resources custom controllers 簡介 custom resources Kubernetes 預先定義許多 resource ，這些 resource 是 kubernetes API 預先設置的 API objects，例如 kubernetes pods resource 包含許多 pods 物件。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cert Manager Complete Workflow</title>
      <link>https://chechia.net/post/2019-10-12-cert-manager-complete-workflow/</link>
      <pubDate>Sat, 12 Oct 2019 17:41:25 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-12-cert-manager-complete-workflow/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
Recap 昨天我們實際使用 cert-manager，為 nginx ingress controller 產生 certificates，過程中我們做了幾件事
設置 Let&amp;rsquo;s Encript prod site 的 Issuer 設置 certificates.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cert Manager How It Work</title>
      <link>https://chechia.net/post/2019-10-11-cert-manager-how-it-work/</link>
      <pubDate>Fri, 11 Oct 2019 11:24:34 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-11-cert-manager-how-it-work/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
今天我們來實際使用 cert-manager，為 nginx ingress controller 產生 certificates with ACME Issuer
CA Terminology 先把實際執行 CA 簽發的名詞定義一下，以免跟 cert-manager 的資源搞混
          
          
        
      </description>
    </item>
    
    <item>
      <title>Cert Manager Deployment on Kubernetes</title>
      <link>https://chechia.net/post/2019-10-10-cert-manager-deployment/</link>
      <pubDate>Thu, 10 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-10-cert-manager-deployment/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Cert-manager Introduction Deploy cert-manager 簡介 cert-manager TLS certificate 管理很重要，但在 kubernetes 上管理 TLS certificates 很麻煩。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Nginx Ingress Controller</title>
      <link>https://chechia.net/post/2019-10-08-kubernetes-nginx-ingress-controller/</link>
      <pubDate>Tue, 08 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-08-kubernetes-nginx-ingress-controller/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊該了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
Nginx Ingress Controller 簡介 nginx &amp;amp; Ingress Controller 部屬並設定 nginx ingress controller Nginx Introduction Nginx 是一款高效能、耐用、且功能強大的 load balancer 以及 web server，也是市占率最高的 web server 之一。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Nginx Ingress Controller Config</title>
      <link>https://chechia.net/post/2019-10-08-kubernetes-nginx-ingress-config/</link>
      <pubDate>Tue, 08 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-08-kubernetes-nginx-ingress-config/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
這邊改了一些大綱，原本的內容還有一些 kubernetes 的設定，以及 GCP 相關服務的介紹。但既然我們的主題是把東西搬上 k8s 的踩雷旅程，那我們就繼續搬，繼續踩。剩下的時間大概會有四個題目。
Nginx Ingress (3) Deploy Nginx Ingress Controller Configure Nginx Ingress Cert-manager (3) Deploy cert-manager How cert-manager work Cert-manager complete workflow Kubernetes CRD &amp;amp; Operator-sdk (3) Introduction about custom resource Deployment &amp;amp; Usage Deployment &amp;amp; Usage 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Nginx Ingress Controller 運作原理 設定 Nginx Ingress Controller 運作原理 昨天講完 nginx ingress controller 部屬，今天來談談 controller 是如何運作的。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus &amp; Kubernetes State Metrics Exporter</title>
      <link>https://chechia.net/post/2019-10-07-prometheus-kube-state-metrics-exporter/</link>
      <pubDate>Mon, 07 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-07-prometheus-kube-state-metrics-exporter/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
如果要透過 prometheus 來監控集群的運行狀況，有兩個 exporter 是必裝的，一個是把 node 狀態 export 出來的 node exporter，一個是把 kubernetes 集群狀態 export 出來的 kube state metrics exporter。
Node Exporter 簡介 kube metrics exporter 安裝與設定 Node Exporter Node Exporter 是 prometheus 官方維護的一個子項目，主要在把類 unix 硬體 kernel 的 metrics 送出來。官方也支援 windows node 與 nvidia gpu metrics，可以說是功能強大。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Exporter Library &amp; Redis Exporter</title>
      <link>https://chechia.net/post/2019-10-06-prometheus-exporter-library-redis-exporter/</link>
      <pubDate>Sun, 06 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-06-prometheus-exporter-library-redis-exporter/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Exporter 工作原理簡介 Prometheus exporter library Exporter workflow 上次講到 exporter 可以從服務端把運行資料抽出來，並開成 http endpoint，讓 prometheus 來 scrape metrics。那 exporter 本身是如何取得服務內部的 metrics 呢? 我們今天就稍微看一下。
Redis Exporter 我們今天以 Redis Exporter 為例，研究一下外部的 exporter 是如何取得 redis 內部的 metrcs。
Redis exporter 是用 golang 寫的一個小程式，總共算算才 1000 行，而且很多都是對 redis 內部 metrics 的清單，以及轉化成 prometheus metrics 的 tool functions，主要的邏輯非常簡單。我們簡單看一下源碼。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Deployment on Kubernetes</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-deployment-on-kubernetes/</link>
      <pubDate>Fri, 04 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-deployment-on-kubernetes/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Prometheus Introduction Deploy Prometheus Prometheus Introduction 生產環境與非生產環境，其中的一指標就是有沒有足夠完整的服務監測系統，這句話可以看出服務監測對於產品化是多麼重要。而監控資料 (metrics) 的收集與可視化工具其實非常多，例如上周介紹的 ELK Stack，這次我們要來介紹另外一個很多人使用的 prometheus。
Promethues 在官網上提到 是一個 Monitoring system and time series database
可以收集高維度的資料 使用自己的 PromQL 做有效且精簡的資料查詢 內建資料瀏覽器，並且與 Grafana 高度整合 支援 sharding 與 federation，來達到水平擴展 有許多隨插即用的整合 exporter，例如 redis-exporter, kafka-exporter，kubernetes-exporter ，都可以直接取得資料 支援 alert，使用 PromQL 以及多功能的告警，可以設定精準的告警條件 與 ELK 做比較 基本上 Prometheus 跟 ELK 比，其實是很奇怪的一件事，但這也是最常被問的一個問題。兩者在本質上是完全不同的系統。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Deploy Grafana</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-deploy-grafana/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-deploy-grafana/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Grafana Introduction Deploy Grafana Grafana Introduction 上偏我們簡單介紹了 Prometheus，prometheus 的 Web Portol 已經附上簡單的 Query 與 Graph 工具，但一般我們在使用時，還是會搭配 Grafana 來使用。
Grafana 在官網上提到 是一個 Analytics system，可以協助了解運行資料，建立完整的 dashboard。
支援許多圖表，直線圖，長條圖，區域分析，基本上需要的都有 在圖表上定義 alter，並且主動告警，整合其他通訊軟體 對後端 data source 的整合，可以同時使用 ELK, prometheus, influxdb 等 30 多種的資料來源 有許多公開的 plugin 與 dashboard 可以匯入使用 總之功能強大，至於用起來的感覺，個人是非常推薦。如果有大得想要試玩看看，可以直接到 Grafana Live Demo 上面試玩
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Scrape</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-scrape/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-scrape/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Prometheus scrape scrape_configs Node exporter Scrape Prometheus 收集 metrics 的方式，是從被監測的目標的 http endpoints 收集 (scrape) metrics，目標服務有提供 export metrics 的 endpoint 的話，稱作 exporter。例如 kafka-exporter 就會收集 kafka 運行的 metrics，變成 http endpoint instance，prometheus 從 instance 上面收集資料。
Promethesu 自己也是也提供 metrics endpoint，並且自己透過 scrape 自己的 metrics endpoint 來取得 self-monitoring 的 metrics。把自己當作外部服務監測。下面的設定就是直接透過 http://localhost:9090/metrics 取得。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Failure Recovery</title>
      <link>https://chechia.net/post/2019-10-03-redis-ha-failure-recovery/</link>
      <pubDate>Thu, 03 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-03-redis-ha-failure-recovery/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Failure Case Recovery Topology 上篇的例子完成應該是這樣
1 2 +-------+ +--------+ +------------+ +---------+ 3 |Clients|---|HAProxys|----|redis master|----|sentinels| 4 +-------+ +--------+ +------------+ +---------+ HAproxy 作為後端 redis 的 gateway Client 透過 HAproxy 連入 redis master sentinel 負責監測 redis 狀態與 failover，只是 client 不再透過 sentinel 去取得 master，而是透過 HAProxy。 那現在就來聊聊這些服務可能怎麼死的，回復的機制又是如何
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha HAProxy</title>
      <link>https://chechia.net/post/2019-10-02-redis-ha-on-haproxy/</link>
      <pubDate>Wed, 02 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-02-redis-ha-on-haproxy/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 HAProxy Introduction Redis Sentinel with HAProxy HAProxy Intro HAproxy 全名是 High Availability Proxy，是一款開源 TCP/HTTP load balancer，他可以
聽 tcp socket，連 server，然後把 socket 接在一起讓雙向流通 可做 Http reverse-proxy (Http gateway)，自己作為代理 server，把接受到的 connection 傳到後端的 server。 SSL 終端，可支援 client-side 與 server-side 的 ssl/tls 當 tcp/http normalizer 更改 http 的 request 與 response 當 switch，決定 request 後送的目標 做 load balancer，為後端 server 做負載均衡 調節流量，設定 rate limit，或是根據內容調整流量 HAProxy 還有其他非常多的功能，想了解細節可以來看原理解說文件
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Topology</title>
      <link>https://chechia.net/post/2019-09-30-redis-ha-topology/</link>
      <pubDate>Mon, 30 Sep 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-30-redis-ha-topology/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Redis Sentinel Topology Topology Masters: M1, M2, M3, &amp;hellip;, Mn. Slaves: R1, R2, R3, &amp;hellip;, Rn (R stands for replica). Sentinels: S1, S2, S3, &amp;hellip;, Sn. Clients: C1, C2, C3, &amp;hellip;, Cn.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Sentinel</title>
      <link>https://chechia.net/post/2019-09-29-redis-ha-sentinel/</link>
      <pubDate>Sun, 29 Sep 2019 17:14:38 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-29-redis-ha-sentinel/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 redis-sentinel redis sentinel 與 redis 使用相容的 api，直接使用 redis-cli 透過 26479 port 連入，可以連到 sentinel，透過 sentinel 可以取得 redis master 的狀態與連線設定。
1redis-cli -h redis-redis-ha -p 26479 上篇我們的 redis-ha 安裝完變這樣
1$ kubectl get po | grep redis 2 3NAME READY STATUS RESTARTS AGE 4redis-1-redis-ha-server-0 3/3 Running 0 3d4h 5redis-1-redis-ha-server-1 3/3 Running 0 3d5h 6redis-1-redis-ha-server-2 3/3 Running 0 3d4h 有三個 Pod，裡面都是一個 redis, sentinel, 跟 exporter，這篇文章會專注講 sentinel 的功能與機制
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Deployment</title>
      <link>https://chechia.net/post/2019-09-28-redis-ha-deployment/</link>
      <pubDate>Sat, 28 Sep 2019 15:14:23 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-28-redis-ha-deployment/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
今天的文會比較短，因為我早上在綠島已經水肺潛水潛了三趟，有點累哈哈
Redis introduction Redis 是常用的 in-memory 的資料儲存庫，可作為資料庫，快取，message broker 使用，都非常好用。Redis 官方支援 high availability，使用的是 redis-sentinel ，今天我們就來部署一個有完整 sentinel 的 redis-ha。
Redis 另外提供了一個 solution Redis cluster (multiple writer solution)，作為增加資料輸出帶寬，與增加資料耐用度的分散式解決方案，與 redis sentinel 所處理的 ha 問題是不相同的。有機會我們也來談。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka HA Continued</title>
      <link>https://chechia.net/post/2019-09-26-kafka-ha-continued/</link>
      <pubDate>Thu, 26 Sep 2019 22:50:32 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-26-kafka-ha-continued/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka HA Topology</title>
      <link>https://chechia.net/post/2019-09-25-kafka-ha-topology/</link>
      <pubDate>Wed, 25 Sep 2019 22:50:32 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-25-kafka-ha-topology/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Operation Scripts</title>
      <link>https://chechia.net/post/2019-09-25-kafka-operation-scripts/</link>
      <pubDate>Wed, 25 Sep 2019 22:50:32 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-25-kafka-operation-scripts/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka-basic-usage</title>
      <link>https://chechia.net/post/2019-09-24-kafka-basic-usage/</link>
      <pubDate>Tue, 24 Sep 2019 21:59:49 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-24-kafka-basic-usage/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka-introduction</title>
      <link>https://chechia.net/post/2019-09-23-kafka-introduction/</link>
      <pubDate>Mon, 23 Sep 2019 21:59:49 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-23-kafka-introduction/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Helm Configuration</title>
      <link>https://chechia.net/post/2019-09-23-kafka-helm-configuration/</link>
      <pubDate>Mon, 23 Sep 2019 21:55:29 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-23-kafka-helm-configuration/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Deployment on Kubernetes</title>
      <link>https://chechia.net/post/2019-09-22-kafka-deployment-on-kubernetes/</link>
      <pubDate>Sun, 22 Sep 2019 09:58:41 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-22-kafka-deployment-on-kubernetes/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
碎念 30 天每天一文真的蠻逼人的，每一篇都是新寫，還要盡可能顧及文章品質，下班趕文章，各位大德寫看看就知道
          
          
        
      </description>
    </item>
    
    <item>
      <title>Logstash on GKE</title>
      <link>https://chechia.net/post/2019-09-21-logstash-on-gke/</link>
      <pubDate>Sat, 21 Sep 2019 15:22:23 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-21-logstash-on-gke/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
摘要 簡介 logstash 將 logstash 部屬到 kubernetes 上 設定 logstash pipeline 處理 nginx access log 介紹 Logstash Logstash 是開元的資料處理引擎，可以動態的將輸入的資料做大量的處裡。原先的目的是處理 log ，但目前以不限於處理 log ，各種 ELK beat 或是其他來源的不同監測數據，都能處理。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitoring GKE With Elk</title>
      <link>https://chechia.net/post/2019-09-19-monitoring-gke-with-elk/</link>
      <pubDate>Thu, 19 Sep 2019 17:06:29 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-19-monitoring-gke-with-elk/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：
node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar 上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitoring GCE With ELK</title>
      <link>https://chechia.net/post/2019-09-18-monitoring-gce-with-elk/</link>
      <pubDate>Wed, 18 Sep 2019 19:10:50 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-18-monitoring-gce-with-elk/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
ELK 的 beats 是輕量級的系統監測收集器，beats 收集到的 data 經過 mapping 可以送到 Elasticsearch 後，進行彈性的搜尋比對。
beat 有許多種類，依據收集的 data 區別：
Auditbeat: Audit data Filebeat: Log files Functionbeat: Cloud data Heartbeat: Availability Journalbeat: Systemd journals Metricbeat: Metrics Packetbeat: Network traffic Winlogbeat: Windows event logs 這邊先以 filebeat 為例，在 GCE 上收集圓端服務節點上的服務日誌與系統日誌，並在 ELK 中呈現。
          
          
        
      </description>
    </item>
    
    <item>
      <title>ELK or Not ELK</title>
      <link>https://chechia.net/post/2019-09-18-elastic-or-not-elastic/</link>
      <pubDate>Wed, 18 Sep 2019 18:51:40 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-18-elastic-or-not-elastic/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
有板友問到，要如何選擇要不要用 ELK，其實也這是整篇 ELK 的初衷。這邊分享一下 ELK 與其他選擇，以及選擇解決方案應該考慮的事情。
其他常用的服務 Prometheus: 開源的 time series metrics 收集系統
Stackdriver: GCP 的 log 與 metrics 平台
Elastic Cloud: ELK 的 Sass
Self-hosted ELK
或是依照需求混搭，各個服務使用的各層套件是可以相容，例如
在 GKE 上不用 beat 可以用 fluentd
          
          
        
      </description>
    </item>
    
    <item>
      <title>X.509 certificate</title>
      <link>https://chechia.net/post/2020-09-17-x.509-certificate/</link>
      <pubDate>Tue, 17 Sep 2019 10:15:36 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-17-x.509-certificate/</guid>
      <description>
        
          
            簡單講一下 certificate X.509 是公鑰憑證(public key certificate) 的一套標準，用在很多網路通訊協定 (包含 TLS/SSL)
certificate 包含公鑰及識別資訊(hostname, organization, &amp;hellip;等資訊)
certificate 是由 certificate authority(CA) 簽署，或是自簽(Self-signed)
使用 browser 連入 https server時，會檢查 server 的 certificate 是否有效，確定這個 server 真的是合法的 site
在 elastic stack 上，如果有多個 elasticsearch server node 彼此連線，由於 node 彼此是 client 也是 server
使用 self-signed CA 產出來的 certificate，連入時會檢查使用的 certificate 是否由同一組 CA 簽署 server 使用 certificate，確定連入 server 的 client 都帶有正確的私鑰與 public certificate，是 authenticated user 附帶說明，X.509 有多種檔案格式
.pem .cer, .crt, .der .p12 .
          
          
        
      </description>
    </item>
    
    <item>
      <title>Secure Elk Stack</title>
      <link>https://chechia.net/post/2019-09-15-secure-elk-stack/</link>
      <pubDate>Sun, 15 Sep 2019 23:00:33 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-15-secure-elk-stack/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
&amp;ndash;
上篇Self-host ELK stack on GCP 介紹了，elk stack 基本的安裝，安裝完獲得一個只支援 http (裸奔)的 elk stack，沒有 https 在公開網路上使用是非常危險的。這篇要來介紹如何做安全性設定。
官方的文件在這裡，碎念一下，除非對 ELK 的功能有一定了解，不然這份真的不是很友善。建議從官方文件底下的Tutorial: Getting started with security 開始，過程比較不會這麼血尿。
總之為了啟用 authentication &amp;amp; https，這篇要做的事情：
enable x-pack &amp;amp; activate basic license Generate self-signed ca, server certificate, client certificate Configure Elasticsearch, Kibana, &amp;amp; other components to use server certificate when act as server use client certificate when connect to an ELK server 啟用 X-pack Elasticsearch 的安全性模組由 x-pack extension 提供，在 6.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Self-host ELK stack - Installation</title>
      <link>https://chechia.net/post/2019-09-15-self-host-elk-stack-on-gcp/</link>
      <pubDate>Sun, 15 Sep 2019 11:43:03 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-15-self-host-elk-stack-on-gcp/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
&amp;ndash;
簡介 ELK stack 官方說明文件
ELK 的元件 Elasticsearch: 基於 Lucene 的分散式全文搜索引擎 Logstash: 數據處理 pipeline Kibana: ELK stack 的管理後台與數據視覺化工具 Beats: 輕量級的應用端數據收集器，會從被監控端收集 log 與監控數據(metrics) ELK 的工作流程 beats -&amp;gt; (logstash) -&amp;gt; elasticsearch -&amp;gt; kibana
          
          
        
      </description>
    </item>
    
    <item>
      <title>2019 IT邦幫忙鐵人賽</title>
      <link>https://chechia.net/post/2019-09-09-ithome-ironman-challenge/</link>
      <pubDate>Mon, 09 Sep 2019 16:56:03 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-09-ithome-ironman-challenge/</guid>
      <description>
        
          
            2019 IT邦幫忙鐵人賽
          
          
        
      </description>
    </item>
    
    <item>
      <title>2020 IT邦幫忙鐵人賽</title>
      <link>https://chechia.net/post/2020-09-09-ithome-ironman-challenge/</link>
      <pubDate>Mon, 09 Sep 2019 16:56:03 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-09-ithome-ironman-challenge/</guid>
      <description>
        
          
            2020 IT邦幫忙鐵人賽
          
          
        
      </description>
    </item>
    
    <item>
      <title>Journey to Quantum Computing</title>
      <link>https://chechia.net/post/2019-06-02-journey-to-quantum-computing/</link>
      <pubDate>Sun, 02 Jun 2019 10:21:37 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-06-02-journey-to-quantum-computing/</guid>
      <description>
        
          
            This post is about my learning steps for quantum-computing.
For a quick-start tutorial, check my workshop project throught the project link above.
Resources Courses
Coursera
on MIT x pro
Quantum Information Processing from UW Madison
Quantum Computation by John Preskill
IBM Q Experience
https://github.com/Qiskit/openqasm
https://github.com/Qiskit/qiskit-tutorials
IBM Q Experience Day 1 Getting Started with Circuit Composer
Hello Quantum World circuit transformed two qubits, from $ \vert0\rangle $ to $ \frac{\vert00\rangle + \vert11\rangle}{\sqrt{2}} $
          
          
        
      </description>
    </item>
    
    <item>
      <title>Istio 三分鐘就入坑 佈署篇</title>
      <link>https://chechia.net/post/2019-05-06-service-mesh-for-microservice-on-kubernetes/</link>
      <pubDate>Mon, 06 May 2019 18:12:15 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-05-06-service-mesh-for-microservice-on-kubernetes/</guid>
      <description>
        
          
            基於 Kubernetes 平台上的 Istio ，實際部署，並一步一步操作Istio 的功能。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Jenkins X on Kubernetes</title>
      <link>https://chechia.net/post/2019-04-19-jenkins-x-on-kubernetes/</link>
      <pubDate>Fri, 19 Apr 2019 12:15:41 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-04-19-jenkins-x-on-kubernetes/</guid>
      <description>
        
          
            Jenkins is one of the earliest open source antomation server and remains the most common option in use today. Over the years, Jenkins has evolved into a powerful and flexible framework with hundreds of plugins to support automation for any project.
Jenkins X, on the other hand, is a CI/CD platform (Jenkins Platform) for modern cloud applications on Kubernetes.
Here we talk about some basic concepts about Jenkins X and provide a hand-to-hand guide to deploy jenkins-x on Kubernetes.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kubernetes Container Runtime Interface</title>
      <link>https://chechia.net/post/2018-10-06-kubernetes-container-runtime-interface/</link>
      <pubDate>Sat, 06 Oct 2018 12:07:00 +0800</pubDate>
      
      <guid>https://chechia.net/post/2018-10-06-kubernetes-container-runtime-interface/</guid>
      <description>
        
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
