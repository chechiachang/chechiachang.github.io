<!doctype html><html lang=en><head><meta charset=utf-8><title>Cloud Summit: Cloud Infrastructure Saving Engineering 雲端省錢工程</title><meta name=description content="分享幾個節省雲端開銷的方法，包含：導入 spot instance，成本計算與預測工具，動態資源調整HPA與VPA，saving plan"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="black-translucent"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><link rel=stylesheet href=/reveal-js/dist/reset.css><link rel=stylesheet href=/reveal-js/dist/reveal.css><link rel=stylesheet href=/reveal-hugo/themes/robot-lung.css id=theme><link rel=stylesheet href=/highlight-js/color-brewer.min.css></head><body><div class=reveal><div class=slides><section data-noprocess data-shortcode-slide data-background-image=onepiece.png><aside class=notes><p>投影片跟講稿我都放在我的網站上，如果有興趣可以參考</p></aside></section><section><h3 id=雲端k8s省錢工程>雲端K8s省錢工程</h3><p><a href=https://chechia.net/>Che Chia Chang</a></p><aside class=notes><p>兩個關鍵字：雲端 / k8s
如果你有在使用公有雲，而且有在跑 k8s，你是這篇演講的最主要對象
如果你是私有雲 k8s，或是其他的雲端服務，有一些相通的概念，會有一些參考價值
如果你是地端的機器，雖然概念相同，但成本控制的做法完全是另外一個故事，你可以當午休時間的故事聽聽看</p></aside></section><section><h3 id=關於我>關於我</h3><ul><li>Che Chia Chang</li><li>SRE @ <a href=https://www.linkedin.com/company/maicoin/jobs/>Maicoin</a></li><li><a href=https://mvp.microsoft.com/zh-TW/MVP/profile/e407d0b9-5c01-eb11-a815-000d3a8ccaf5>Microsoft MVP</a></li><li>個人部落格<a href=https://chechia.net/>chechia.net</a></li><li>presentation and speaker notes</li><li>鐵人賽 (Terraform / Vault 手把手入門)</li></ul></section><section><h3 id=大綱>大綱</h3><ul><li>公有雲的費用</li><li>節省算力成本</li><li>監控是成本控管的基礎</li><li>導入成本分析與預測工具</li><li>自動化資源使用建議</li><li>Saving Plan/Committed Usage</li><li>Spot Instance 與微服務</li><li>Autoscaling: HPA / VPA</li><li>Q&amp;A</li></ul><aside class=notes><p>這是我們今天的大綱</p><p>我們會先講一下在公有雲上的成本
然後講一下 k8s 的運算資源管理
接著講一下監控，為何成本控管的基礎是監控
如何使用工具成本分析，未來成本預測
然後使用工具建議合適的資源
最後講實務上要如何降低成本，例如 saving plan / spot instance / HPA / VPA，依照執行的難度排序，有時間的話也會講如何從無到有開始進行</p></aside></section><section><h3 id=動機>動機</h3><ul><li>公司希望賺錢，節省成本</li><li>團隊希望控制成本</li><li>個人產生 Credit 與團隊 Impact</li></ul><aside class=notes><p>團隊而言，成本控制是一個很重要的議題，因為成本控制是一個很直接的影響公司獲利的方式
個人，如果為公司節省超過個人的薪水，那公司聘用你就是淨賺
節省公司雲端成本 50% 職涯上履歷很好看</p></aside></section><section><h3 id=公有雲的費用>公有雲的費用</h3><p>打開公有雲的 billing</p><ul><li>算力成本 Compute Resource (cpu, memory)</li><li>儲存成本 Storage (Disk, EBS, S3&mldr;)</li><li>網路 Networking</li></ul><aside class=notes><p>有在使用公有雲的人，把公有雲的 billing 帳單打開來看，可能看到的大概是這幾個項目
當然因為不同團隊的服務不同，可能會有一些出入，但如果你的公司的產品是 web service，應該會有這幾個項目</p></aside></section><section><h3 id=今天只會講這個算力成本>今天只會講這個算力成本</h3><ul><li>算力成本 Compute Resource (cpu, memory)</li><li>今天只會講這個</li></ul><aside class=notes><p>Storage 不太好說省就省，因為你的資料量就在那邊，放不下就是要再買，所以 storage 的成本控制，可能是在資料的使用上，例如資料的壓縮，或是資料的備份，或是資料的存取方式，這些是另外一個故事
使用公有雲的服務，基本上 storage 都是依據使用的大小計價，而且需多服務都可以動態增長，例如動態增加 disk</p><p>Storage / Database / Networking 這幾個項目，我們下集再來談</p></aside></section><section><h3 id=算力成本>算力成本</h3><p>網頁服務的微服務系統，都需要算力</p><ul><li>api server</li><li>cronjob</li><li>business logic job</li><li>database
如需節省，也可以從這裡下手</li></ul><aside class=notes><p>如果你跟敝社一樣是 web service，那麼 cpu / memory 可能是你最大的一筆成本</p><p>你需要足夠運算能力 serve 客戶，不管是支持用戶的request，進行商業邏輯的運算，然後把運算完成的狀態回傳給客戶，或是存在資料庫中，每一個動作都需要算力</p><p>足夠的 cpu 跟 memory，不是越多越好，而是足夠，不會浪費，也不會因為不足而影響服務品質
我們要省錢，就要從這裡下手</p></aside></section><section><h3 id=尋找多餘的算力>尋找多餘的算力</h3><ul><li>已有足夠的 cpu / memory，多給也不會增加服務品質的多餘算力</li><li>多少才是夠？</li><li>減去多少 cpu / memory，依然不改變服務品質</li></ul><aside class=notes><p>多少才是夠？這是一個複雜的問題，實務上通常使用 SLA / SLO 來衡量服務品質，然後根據服務品質的要求，來設定 cpu / memory 的配額</p><p>我們今天要做的是成本優化，白話的說是降低 cpu / memory 的設定配額，但是我們不能降低到影響服務品質
甚至退一百步，防守性的來說，我們不希望因為降低 cpu / memory 的設定配額，為了省錢而導致負面的結果，甚至為服務的穩定度背鍋。</p></aside></section><section><h3 id=維持slo>維持SLO</h3><p>以維持各個服務元件的 SLO為前提，降低 cpu / memory 使用量</p><aside class=notes><p>維持個個服務元件的 SLO
是一個很好的指標，如果你的服務是 99.9% 的 SLA，那麼你的服務就要保證 99.9% 的時間都是正常運作的，那麼你的 cpu / memory 就要足夠支持這個 SLA</p><p>談 SLO 之前，你要先知道你的服務的 SLA 是多少，你要先知道當前的狀態是多少
這個在稍後的 monitoring 會提到，為什麼監控是成本管理的基礎</p></aside></section><section><h3 id=基於-slo-的成本調降>基於 SLO 的成本調降</h3><ul><li>負載穩定的元件，可以抓過去 30d 的 p99 cpu time 或 p99 memory usage + buffer</li><li>負載不穩定的元件，例如 cpu usage 與受活躍用戶數量正比，需要搭配 HPA 水平拓展</li><li>負載不穩定的元件，但又不能水平拓展，例如 stateful service，可以考慮 VPA</li></ul><aside class=notes><p>負載穩定的元件，固定吃多少 cpu / memory，他的附載不太容易隨外部因素波動的服務，可以抓過去 30d 的 p99 cpu time 或 p99 memory usage + buffer，然後降低 cpu / memory 的設定配額</p></aside></section><section><h3 id=小結成本控管的基本概念>小結：成本控管的基本概念</h3><ul><li>尋找服務中多餘算力</li><li>以維持 SLO 為前提</li><li>降低 cpu / memory 使用量</li><li>依據元件負載特性，選擇適當的調降方式</li></ul><aside class=notes></aside></section><section><h3 id=k8s-cpu--memory-management><a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers>k8s cpu / memory management</a></h3><p><a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers>https://kubernetes.io/docs/concepts/configuration/manage-resources-containers</a></p><ul><li>k8s 如何管理 workload 的 cpu 與 memory</li><li>調降多少會影響服務品質</li></ul><aside class=notes><p>這裡面再講一下 k8s 如何管理 cpu / memory</p><p>這邊的重點是，怎麼樣的調整會影響到服務品質，那我們做成本控制的時候，就不要去踩到這個底線</p></aside></section><section><h3 id=how-k8s-manage-cpu--memory><a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-limits-are-run>How k8s manage cpu / memory</a></h3><ul><li>scheduler 依據 cpu / memory request 調度 pod</li><li>container runtime 設定 cgroup<ul><li>cpu 使用量依據 request 佔 node 比例分配</li><li>控制 cpu 用量不超過 limit</li><li>memory 使用 limit，超過 limit 會被 oomkill，並依據設定重啟</li><li>當前 node memory 不足時，會依據 pod request Evict pod</li></ul></li></ul><aside class=notes><p>文件講得很清楚</p></aside></section><section><h3 id=上面都是概念底下進實作>上面都是概念，底下進實作</h3></section><section><h3 id=monitoring-監控是成本控管的基礎>Monitoring 監控是成本控管的基礎</h3><ul><li>監測是成本控管的基礎</li><li>沒有監測就沒有 p99 cpu time / memory usage，也沒有 SLI/SLO</li><li>沒有檢測下做成本精簡，會碰壞服務</li><li>如果沒有監測先補檢測</li></ul><aside class=notes><p>如果沒有 monitoring，上面的兩大前提都不存在
目前的 cpu / memory usage，runtime utilization 的資料
目前SLO，調降之後新的SLO</p><p>沒有檢測下，還是可以做成本精簡
然而要馬兒好又要而不吃草，今天如果把 cpu / memory 降下來，有可能會餓到服務
cpu throttling / memory oomkill，這些都是可能發生的事情
會碰壞服務</p></aside></section><section data-noprocess data-shortcode-slide data-background-image=grafana-dashboard.png></section><section><h3 id=監測調整前設定目標基準線>監測：調整前設定目標基準線</h3><ul><li>設定節省目標：ex. 過去 3 個月的 p99 資源用量<ul><li>99% 的時間，memory 使用量都在這條線以下</li><li>99% 的時間，cpu throttling 在這條線以下</li></ul></li><li>多餘的算力 = (分配的 resource - p99)</li><li>那如果我們把 cpu / memory 降低到 p99 / p99.9 服務品質會受到影響嗎？</li></ul><aside class=notes><p>做之前要能評估做完大概能省多少
例如評估完後</p><p>如果評估完發現省不了什麼錢，那當然團隊就不一定要做這件事</p></aside></section><section data-noprocess data-shortcode-slide data-background-image=grafana-cpu-dashboard.png></section><section><h3 id=監測-調整後>監測: 調整後</h3><ul><li>資源用量是否有變化</li><li>確定沒有改壞東西，有壞要有及時的 alert</li><li>效能表現：有可能沒壞，但是變很慢</li></ul><aside class=notes><p>如果你改壞了，及時的 alert 會救你一命</p><p>performance 監測很重要</p></aside></section><section><h3 id=推薦監測工具>推薦監測工具</h3><ul><li><a href=https://prometheus.io/>prometheus.io</a></li><li><a href=https://docs.kubecost.com/using-kubecost>Kubecost / Opencost</a></li></ul></section><section data-noprocess data-shortcode-slide data-background-image=prometheus.png><aside class=notes><p>大家都知道 prometheus 是什麼嗎？</p><p>知道的人請舉個手
不知道的我很簡單說一下</p><p>我們想要知道一個 pod 會需要花多少 cpu / memory，你就把它跑起來，然後去紀錄跑起來的 pod 用了多少 cpu / memory，然後根據時間統計，你就可以拉出一張圖，看到這個 pod 用了多少 cpu / memory
你的 kubelet / cadvisor / container runtime 會知道你的 container 的 cpu / memory 使用量，包含 request & limit 然後是否有 throttling 或是 oomkill，這些資訊都會被 prometheus 收集起來，然後你可以透過其他工具，例如 kubecost 看到這些資訊</p></aside></section><section data-noprocess data-shortcode-slide data-background-image=grafana-cpu-usage.png><p><a href=https://grafana.com/grafana/dashboards/17375-k8s-resource-monitoring/>https://grafana.com/grafana/dashboards/17375-k8s-resource-monitoring/</a></p><aside class=notes><p>這是 prometheus 收集的資料，vm 的 resource 使用量的 grafana dashboard</p></aside></section><section><h3 id=導入成本分析與預測工具>導入成本分析與預測工具</h3><ul><li>有了 prometheus 後，我們知道短期/長期的資源使用狀況</li><li>要把資源使用轉成成本，需要一個成本計算工具</li><li>評估是否要做成本精簡，能夠減少多少錢</li><li>管理上的考量：投資人力成本，與預期回報</li></ul><aside class=notes><p>政治上的考量，做成本節省需要時間跟人力資源
有一個精準的成本分析，節省空間估算的工具十分有說服力</p><p>有這些資料，才可以科學化決策要不要做，該怎麼做
做之前就能評估做完大概能省多少</p><p>如果評估完發現省不了什麼錢，那當然團隊就不一定要做這件事</p></aside></section><section><h3 id=成本分析>成本分析</h3><ul><li>VM 可以用各家公有雲的費用計算工具</li><li><a href=https://azure.microsoft.com/en-us/products/cost-management>Azure Cost Management</a></li><li><a href=https://aws.amazon.com/aws-cost-management/aws-cost-explorer/>AWS Cost Explorer</a></li><li><a href=https://cloud.google.com/billing/docs/how-to/cost-breakdown>GCP Cost Breakdown</a></li></ul></section><section data-noprocess data-shortcode-slide data-background-image=azure-cost-management.jpeg></section><section><h3 id=成本分析公有雲-billing>成本分析：公有雲 billing</h3><ul><li>計算長時間的費用趨勢</li><li>適合當作成本精簡後的成果回報</li><li>不適合當做調整的依據</li><li>時間計算較長，反饋時間長，不及時，項目不夠精細</li><li>有無更即時的成本分析工具？</li></ul></section><section><h3 id=成本分析-kubecost--opencost>成本分析: <a href=https://docs.kubecost.com/using-kubecost/>Kubecost / Opencost</a></h3><ul><li>有提供 UI</li><li>基於 prometheus</li><li>可以針對 allocation 做成本分析 <a href=https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/cost-allocation>Cost Allocation</a></li><li>可以透過 cloud provider 去撈雲端的使用資料</li></ul></section><section data-noprocess data-shortcode-slide data-background-image=kubecost.jpeg></section><section data-noprocess data-shortcode-slide data-background-image=kubecost-allocation.jpeg><p><a href=https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/cost-allocation>https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/cost-allocation</a></p></section><section data-noprocess data-shortcode-slide data-background-image=kubecost-efficiency.png><p><a href=https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/cost-allocation/efficiency-idle>https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/cost-allocation/efficiency-idle</a></p></section><section><h3 id=推薦工具>推薦工具</h3><ul><li><a href=https://github.com/robusta-dev/krr>https://github.com/robusta-dev/krr</a></li><li><a href=https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/savings>Kubecost / Opencost Savings</a></li><li><a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/pkg/recommender/README.md>VPA recommendator</a></li></ul></section><section><h3 id=推薦工具-kubecost--opencost-savings>推薦工具: <a href=https://docs.kubecost.com/using-kubecost/navigating-the-kubecost-ui/savings>Kubecost / Opencost Savings</a></h3><ul><li>設定 target utilization<ul><li>request / allocatable</li><li>dev 80%+</li><li>prod 60%</li></ul></li></ul><aside class=notes><p>根據服務品質的要求，以及公司政策去做設定
SLA/SLO
開發與測試環境，在不影響工作的前提，都可以拉到 overcommit</p></aside></section><section><h3 id=推薦工具-krr>推薦工具: KRR</h3><ul><li><a href=https://github.com/robusta-dev/krr>https://github.com/robusta-dev/krr</a></li><li>免安裝，不影響 k8s 本身</li><li>使用外部工具讀取 prometheus 資料</li></ul></section><section><h3 id=推薦工具-krr-1>推薦工具: KRR</h3><pre><code>kubectl port-forward svc/prometheus 9090

git clone https://github.com/robusta-dev/krr.git
source .venv/bin/activate

python krr.py simple \
  -p http://127.0.0.1:9090 \
  --mem-min 10 \
  --cpu-min 10 \
  --history_duration 720 -q
</code></pre><aside class=notes></aside></section><section data-noprocess data-shortcode-slide data-background-image=krr.jpeg></section><section><h3 id=推薦工具-krr-2>推薦工具: KRR</h3><ul><li>根據 krr 計算的結果，手動調整</li><li>有一些工具有提供自動調整 ex VPA</li></ul><aside class=notes><p>自動工具比手動需要考量更多因素，這個我們稍候 VPA 再提</p><p>請詳閱工具說明再服用</p></aside></section><section><h3 id=推薦工具-vpa-recommendator>推薦工具: <a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/pkg/recommender/README.md>VPA recommendator</a></h3><ul><li>需要先知道 VPA 是什麼</li><li>直接安裝在 k8s cluster 內</li><li>透過 Prometheus 資料，推薦適當的資源</li><li>可以自動化推薦資源，調整運行中的 pod，依照設定重啟 pod <a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md#quick-start>VPA mode</a></li><li>需要可以參考 <a href=https://github.com/cowboysysop/charts/tree/master/charts/vertical-pod-autoscaler>helm chart</a></li></ul><aside class=notes><p>krr 是可以無腦用的工具，但是 VPA 就不是了
請設定 VPA mode Off
請務必需要研究一下在使用</p></aside></section><section><h3 id=推薦工具-比較>推薦工具: 比較</h3><ul><li><p>kubecost 需要 helm install，krr 不需要</p></li><li><p>kubecost 產生一個漂亮的 UI，krr 產生 command line 報表</p></li><li><p>VPA 需要 helm install，並且會需要 cluster 權限</p></li><li><p>VPA 可以做到自動化調整，邏輯更複雜，有侵入性，設定有問題會出事</p></li></ul></section><section><h3 id=剛上手的做法>剛上手的做法</h3><p>沒時間細部研究研究元件的行為，直接調整 request 與 limit</p><ul><li>先調降 request，不動 limit，對服務衝擊較小</li><li>用抓比例的方式動態調整，例如目前 request 距離 p99 request 差距 1000Mi，你先收 500Mi 回來試個水溫</li><li>p99 直接使用 tool 計算，細節在後面</li><li>測試環境先行，有信心在上 production</li></ul><aside class=notes><p>如果你第一次做，但對服務元件沒有熟到這種程度，這是比較安全的做法
公司規模大服務元件複雜，身為 SRE 你只能仰賴 metrics 來判斷服務品質是否受影響，但很多複雜的服務，以及不熟悉的服務，會很難評估</p><p>先調降 request，提升單一 node 上的 pod 數量，然後觀察服務品質，如果服務品質沒有受到影響，那麼你可以進一步調降 limit
市場喊價，先喊個一半，在看能繼續壓到什麼程度</p></aside></section><section><h3 id=小結>小結</h3><ul><li>收集目前資源使用資料</li><li>轉化成公有雲的成本</li><li>透過 tool 建議適當的資源</li><li>根據服務品質的要求，調降 cpu / memory</li><li>回頭檢查 SLO 是否有受到影響</li></ul><aside class=notes></aside></section><section><h3 id=自動拓展hpa>自動拓展：HPA</h3><ul><li><a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>k8s/horizontal-pod-autoscale</a></li><li>使用 HPA 在成本精簡的意義：因為外部因素改變負載的元件</li><li>低負載時不要開太多，高負載時自動加開 pod</li></ul></section><section><h3 id=自動拓展hpa-的考量>自動拓展：HPA 的考量</h3><p>元件是否能夠水平拓展</p><ul><li>啟動的 liveness check / readiness check</li><li>laod balancer</li><li>需要持續調整 scale up / down 的條件與 time windows</li><li>scale up 對依賴服務的 loading 會有影響 ex. 後面的 db</li><li>退場機制，要如何安全的中斷連線，紀錄 state</li></ul><aside class=notes><p>要能安全地進出場</p><p>進場，pod readiness / liveness
loading 增加時 scale up time windows
scale out 對後方服務的影響，是否會出現新的瓶頸</p><p>loading 降低時 scale down 是否會影響服務</p></aside></section><section><h3 id=自動拓展vpa>自動拓展：VPA</h3><ul><li><a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md#quick-start>k8s/autoscaler/vertical-pod-autoscaler</a></li><li>不能水平拓展，只好先垂直拓展</li><li>調整資源，有可能會重啟 pod / container</li><li><a href=https://kubernetes.io/blog/2023/05/12/in-place-pod-resize-alpha/>Kubernetes 1.27: In-place Resource Resize for Kubernetes Pods (alpha)</a></li><li><a href=https://github.com/kubernetes/kubernetes/issues/122760>In-Place Pod Resource Resizing always restarts pod</a></li><li>如果你的 workload 然後不適合做 HPA，但可以接受 resize 後重啟，那可以試試VPA</li></ul><aside class=notes><p>1.27 你可以把 InPlacePodVerticalScaling feature gate 開起來
他不保證 resize 後不會重啟 pod，還是要看你的 container runtime 支援程度
請先在測試環境中玩一玩</p></aside></section><section><h3 id=saving-plan--ri>Saving Plan / RI</h3><ul><li>AWS Saving Plan / RI</li><li>GCP Committed Use Discount</li><li>Azure Saving Plan / Reservation</li></ul><aside class=notes><p>Saving Plan / RI 是一種長期的合約，你可以跟雲端服務商簽約，保證你會用多少資源，然後雲端服務商會給你一個折扣
七折上下，很適合長期使用的客戶</p><p>有 monitoring + prediction，基本上可以確定你會用多少資源，這時候就可以考慮 saving plan / RI</p></aside></section><section><h3 id=spot-instance>Spot Instance</h3><ul><li><a href=https://azure.microsoft.com/en-us/products/virtual-machines/spot>azure spot vm</a></li><li><a href=https://aws.amazon.com/ec2/spot/>aws spot intance</a></li><li><a href=https://cloud.google.com/spot-vms>gcp spot vm</a></li><li>帳面上最高可省 90%</li></ul></section><section><h3 id=spot-instance-1>Spot Instance</h3><ul><li>超便宜，打一折</li><li>多餘的算力</li><li>interruption，不保證使用</li><li><a href=https://aws.amazon.com/ec2/spot/instance-advisor/>https://aws.amazon.com/ec2/spot/instance-advisor/</a></li></ul><aside class=notes><p>因為一折真的很香，一折是有點拼，但打個 3 折還是很有機會</p></aside></section><section><h3 id=spot-instance-如何開始>Spot Instance: 如何開始</h3><p>重啟不影響服務品質的</p><ul><li>stateless</li><li>batch job</li><li>將 worklaod 從 monolithic 拆分成小的 batch job</li><li>測試環境 dev / stag</li><li>CI/CD</li></ul><aside class=notes><p>乍看之下幾個小時~24hr 內會被重啟，好像是犧牲了服務品質，但如果你的服務是可以容忍 interruption 的，例如 batch job，那麼 spot instance 就是一個很好的選擇</p><p>將 worklaod 從 monolithic 拆分成小的 batch job，例如你是 api server 處理一個 request 會有很多步驟，你可以把這些步驟拆分成小的 batch job，然後用 queue 串接，這樣你的 api server 就可以用 spot instance 來跑，然後你的 batch job 用 spot instance 跑，這樣你的服務就可以省很多錢</p></aside></section><section><h3 id=小結-1>小結</h3><ul><li>krr 工具調整資源</li><li>HPA 做水平擴展</li><li>VPA 自動化調整資源</li><li>saving plan / RI 長期合約打七折</li><li>spot instance 打一折</li></ul></section><section><h3 id=展望>展望</h3><ul><li>運行成本轉達給開發團隊 cost awareness development</li><li>根據各團隊制定精簡計畫 find-grade optimization</li><li>成本管理自動化 automation</li></ul><aside class=notes><p>有了資源預測系統，可以在開發階段就將資源使用回饋給開發團隊
根據不同服務元件的品質要求，做更細緻的資源管控
自動化調整，讓人力可以專注在更重要的事情上</p></aside></section><section><h3 id=小結-2>小結</h3><ul><li>cpu / memory</li><li>監測是基礎</li><li>依據監測做預測</li><li>開始調整</li><li>長期合約打七折</li><li>spot instance 打一折</li><li>HPA / VPA</li></ul></section><section><h3 id=感謝>感謝</h3><ul><li><p>presentation and speaker notes <a href=https://chechia.net/>chechia.net</a></p></li><li><p><a href=https://www.linkedin.com/company/maicoin/jobs/>Maicoin 職缺</a></p></li><li><p>公司福利不錯，業務成長中，想一起共事，歡迎找我聊</p></li></ul></section><section></section></div></div><script type=text/javascript src=/reveal-hugo/object-assign.js></script><script src=/reveal-js/dist/reveal.js></script><script type=text/javascript src=/reveal-js/plugin/markdown/markdown.js></script><script type=text/javascript src=/reveal-js/plugin/highlight/highlight.js></script><script type=text/javascript src=/reveal-js/plugin/zoom/zoom.js></script><script type=text/javascript src=/reveal-js/plugin/notes/notes.js></script><script type=text/javascript>function camelize(e){return e&&Object.keys(e).forEach(function(t){newK=t.replace(/(_\w)/g,function(e){return e[1].toUpperCase()}),newK!=t&&(e[newK]=e[t],delete e[t])}),e}var revealHugoDefaults={center:!0,controls:!0,history:!0,progress:!0,transition:"slide"},revealHugoSiteParams={},revealHugoPageParams={custom_theme:"reveal-hugo/themes/robot-lung.css",highlight_theme:"color-brewer",margin:.2,templates:{hotpink:{background:"#FF4081",class:"hotpink"}},transition:"slide",transition_speed:"fast"},revealHugoPlugins={plugins:[RevealMarkdown,RevealHighlight,RevealZoom,RevealNotes]},options=Object.assign({},camelize(revealHugoDefaults),camelize(revealHugoSiteParams),camelize(revealHugoPageParams),camelize(revealHugoPlugins));Reveal.initialize(options)</script><script type=text/javascript src=/mermaid.min_16862243754454536095.js></script><script type=text/javascript>mermaid.initialize({startOnLoad:!1});let render=e=>{let t=e.currentSlide.querySelectorAll(".mermaid");if(!t.length)return;t.forEach(e=>{let t=e.getAttribute("data-processed");t||mermaid.init(0[0],e)})};render({currentSlide:Reveal.getCurrentSlide()}),Reveal.on("slidechanged",render),Reveal.on("ready",render)</script></body></html>