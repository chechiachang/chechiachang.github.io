<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kafka Operation Scripts | Che-Chia Chang</title><meta name=keywords content="鐵人賽2019,kafka,kubernetes,ithome"><meta name=description content="2020 It邦幫忙鐵人賽 系列文章

ELK Stack

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP


Kafka HA on Kubernetes(6)

Deploy kafka-ha
Kafka Introduction
kafka 基本使用
kafka operation scripts
集群內部的 HA topology
集群內部的 HA 細節
Prometheus Metrics Exporter 很重要
效能調校



由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。"><meta name=author content="chechiachang"><link rel=canonical href=https://chechia.net/posts/2019-09-25-kafka-operation-scripts/><meta name=google-site-verification content="G-QYR8JCDGM9"><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://chechia.net/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://chechia.net/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://chechia.net/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://chechia.net/favicon/favicon-32x32.png><link rel=mask-icon href=https://chechia.net/favicon/favicon-32x32.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://chechia.net/posts/2019-09-25-kafka-operation-scripts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://chechia.net/posts/2019-09-25-kafka-operation-scripts/"><meta property="og:site_name" content="Che-Chia Chang"><meta property="og:title" content="Kafka Operation Scripts"><meta property="og:description" content="2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-09-25T22:50:32+08:00"><meta property="article:modified_time" content="2019-09-25T22:50:32+08:00"><meta property="article:tag" content="鐵人賽2019"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Ithome"><meta property="og:image" content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Kafka Operation Scripts"><meta name=twitter:description content="2020 It邦幫忙鐵人賽 系列文章

ELK Stack

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP


Kafka HA on Kubernetes(6)

Deploy kafka-ha
Kafka Introduction
kafka 基本使用
kafka operation scripts
集群內部的 HA topology
集群內部的 HA 細節
Prometheus Metrics Exporter 很重要
效能調校



由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://chechia.net/posts/"},{"@type":"ListItem","position":2,"name":"Kafka Operation Scripts","item":"https://chechia.net/posts/2019-09-25-kafka-operation-scripts/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kafka Operation Scripts","name":"Kafka Operation Scripts","description":"2020 It邦幫忙鐵人賽 系列文章\nELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。\n對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。\n","keywords":["鐵人賽2019","kafka","kubernetes","ithome"],"articleBody":"2020 It邦幫忙鐵人賽 系列文章\nELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。\n對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。\n摘要 從 Zookeeper 獲取資訊 取得並處理 topic benchmark kafka zookeeper zookeeper 是 kafka 的分散式協調系統，在 kafka 上多個節點間需要協調的內容，例如：彼此節點的ID，位置與當前狀態，或是跨節點 topic 的設定與狀態。取名叫做 zookeeper 就是在協調混亂的分散式系統，,裡面各種不同種類的服務都要協調，象個動物園管理員。Zookeeper 的官方文件 有更詳細的說明。\nKafka 的節點資訊，與當前狀態，是放在 zookeeper 上，我們可以透過以下指令取得\n# 首先先取得 zkCli 的 cli，這個只有連進任何一台 zookeeper 內部都有 kubectl exec -it kafka-0-zookeeper-0 --container kafka-broker bash # 由於是在 Pod 內部，直接 localhost 詢問本地 /usr/bin/zkCli.sh -server localhost:2181 Connecting to localhost:2181 2019-09-25 15:02:36,089 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT 2019-09-25 15:02:36,096 [myid:] - INFO [main:Environment@100] - Client environment:host.name=kafka-0-zookeeper-0.kafka-0-zookeeper-headless.default.svc.cluster.local 2019-09-25 15:02:36,096 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_131 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=/usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.10.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper: 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.io.tmpdir=/tmp 2019-09-25 15:02:36,100 [myid:] - INFO [main:Environment@100] - Client environment:java.compiler= 2019-09-25 15:02:36,101 [myid:] - INFO [main:Environment@100] - Client environment:os.name=Linux 2019-09-25 15:02:36,101 [myid:] - INFO [main:Environment@100] - Client environment:os.arch=amd64 2019-09-25 15:02:36,101 [myid:] - INFO [main:Environment@100] - Client environment:os.version=4.14.127+ 2019-09-25 15:02:36,101 [myid:] - INFO [main:Environment@100] - Client environment:user.name=zookeeper 2019-09-25 15:02:36,102 [myid:] - INFO [main:Environment@100] - Client environment:user.home=/home/zookeeper 2019-09-25 15:02:36,102 [myid:] - INFO [main:Environment@100] - Client environment:user.dir=/ 2019-09-25 15:02:36,105 [myid:] - INFO [main:ZooKeeper@438] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@42110406 Welcome to ZooKeeper! 2019-09-25 15:02:36,160 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) JLine support is enabled 2019-09-25 15:02:36,374 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@876] - Socket connection established to localhost/127.0.0.1:2181, initiating session 2019-09-25 15:02:36,393 [myid:] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16d67baf1310001, negotiated timeout = 30000 WATCHER:: WatchedEvent state:SyncConnected type:None path:null [zk: localhost:2181(CONNECTED) 0] 取得 kafka broker 資料\n# List root Nodes $ ls / [cluster, controller, controller_epoch, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config] # Brokers 的資料節點 $ ls /brokers [ids, topics, seqid] # List /brokers/ids 得到三個 kafka broker $ ls /brokers/ids [0, 1, 2] # 列出所有 topic 名稱 ls /brokers/topics [ticker] ticker 是上篇範利用到的 topic\n簡單來說，zookeeper 存放這些狀態與 topic 的 metadata\n儲存核心的狀態與資料，特別是 broker 萬一掛掉，也還需要維持的資料 協調工作，例如協助 broker 處理 quorum，紀錄 partition master 等 # 離開 zkCli quit Kafka 這邊一樣先連線進去一台 broker，取得 kafka binary\nkubectl exec -it kafka-0-0 --container kafka-broker bash ls /usr/bin/ | grep kafka kafka-acls kafka-broker-api-versions kafka-configs kafka-console-consumer kafka-console-producer kafka-consumer-groups kafka-consumer-perf-test kafka-delegation-tokens kafka-delete-records kafka-dump-log kafka-log-dirs kafka-mirror-maker kafka-preferred-replica-election kafka-producer-perf-test kafka-reassign-partitions kafka-replica-verification kafka-run-class kafka-server-start kafka-server-stop kafka-streams-application-reset kafka-topics kafka-verifiable-consumer kafka-verifiable-producer 很多工具，我們這邊只會看其中幾個\ntopic 資訊 Topic 的資訊，跟 zookeeper 要\n# List topics /usr/bin/kafka-topics --list --zookeeper kafka-0-zookeeper ticker 操作 message 從 topic 取得 message\n# This will create a new console-consumer and start consuming message to stdout /usr/bin/kafka-console-consumer \\ --bootstrap-server localhost:9092 \\ --topic engine_topic_soundwave_USD \\ --timeout 0 \\ --from-beginning 如果 ticker 那個 example pod 還在執行，這邊就會收到 ticker 的每秒 message\n如果沒有，也可以開啟另一個 broker 的連線\nkubectl exec -it kafka-0-1 --container kafka-broker bash # 使用 producer 的 console 連入，topic 把 message 塞進去 /usr/bin/kafka-console-producer \\ --broker-list localhost:9092\\ --topic ticker tick [enter] tick [enter] kafka-console-consumer 那個 terminal 就會收到 message\ntick tick 當然也可以使用 consumer group\n# Use consumer to check ticker topics /usr/bin/kafka-console-consumer \\ --bootstrap-server localhost:9092 \\ --topic ticker \\ --group test 有做過上面的操作產生 consumer group，就可以透過 consumer API，取得 consumer group 狀態\n# Check consumer group /usr/bin/kafka-consumer-groups \\ --bootstrap-server localhost:9092 \\ --group ticker \\ --describe Consumer group 'test' has no active members. TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-ID ticker 0 23 23 0 - - - Topic 設定操作 Topic 設定文件 在此\n這邊透過 kafka-configs 從 zookeeper 取得 topic 設定，這邊的 max.message.bytes，是這個 topic 每個 message 的最大上限。\n/usr/bin/kafka-configs --zookeeper kafka-0-zookeeper:2181 --describe max.message.bytes --entity-type topics Configs for topic '__consumer_offsets' are segment.bytes=104857600,cleanup.policy=compact,compression.type=producer Configs for topic 'ticker' are __consumer__offsets 是系統的 topic ，紀錄目前 consumer 讀取的位置。\nticker 沒有設定，就是 producer 當初產生 topic 時沒有指定，使用 default 值\n由於我們公司的使用情境常常會超過，所以可以檢查 producer app 那端送出的 message 大小，在比較這邊的設定。當然現在 ticker 的範例，只有一個 0-60 的數值，並不會超過。這個可以在 helm install 的時候，使用 value.yaml 傳入時更改。\n不喜歡這個值，可以更改，這邊增加到 16MB\nTOPIC=ticker /usr/bin/kafka-configs \\ --zookeeper kafka-3-zookeeper:2181 \\ --entity-type topics \\ --alter \\ --entity-name ${TOPIC} \\ --add-config max.message.bytes=16000000 Benchmark 使用內建工具跑 benchmark\nProducer\n/usr/bin/kafka-producer-perf-test \\ --num-records 100 \\ --record-size 100 \\ --topic performance-test \\ --throughput 100 \\ --producer-props bootstrap.servers=kafka:9092 max.in.flight.requests.per.connection=5 batch.size=100 compression.type=none 100 records sent, 99.108028 records/sec (0.01 MB/sec), 26.09 ms avg latency, 334.00 ms max latency, 5 ms 50th, 70 ms 95th, 334 ms 99th, 334 ms 99.9th. Consumer\n/usr/bin/kafka-consumer-perf-test \\ --messages 100 \\ --broker-list=kafka:9092 \\ --topic performance-test \\ --group performance-test \\ --num-fetch-threads 1 ","wordCount":"763","inLanguage":"en","image":"https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2019-09-25T22:50:32+08:00","dateModified":"2019-09-25T22:50:32+08:00","author":{"@type":"Person","name":"chechiachang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://chechia.net/posts/2019-09-25-kafka-operation-scripts/"},"publisher":{"@type":"Organization","name":"Che-Chia Chang","logo":{"@type":"ImageObject","url":"https://chechia.net/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://chechia.net/ accesskey=h title="Home (Alt + H)"><img src=https://chechia.net/favicon/favicon-32x32.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://chechia.net/#posts title=Posts><span>Posts</span></a></li><li><a href=https://mvp.microsoft.com/zh-TW/mvp/profile/e407d0b9-5c01-eb11-a815-000d3a8ccaf5 title=MVP><span>MVP</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://chechia.net/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://chechia.net/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://chechia.net/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://chechia.net/>Home</a>&nbsp;»&nbsp;<a href=https://chechia.net/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Kafka Operation Scripts</h1><div class=post-meta><span title='2019-09-25 22:50:32 +0800 CST'>September 25, 2019</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;763 words&nbsp;·&nbsp;chechiachang&nbsp;|&nbsp;<a href=https://github.com/chechiachang.github.io-src/content/posts/2019-09-25-kafka-operation-scripts.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#topic-資訊>topic 資訊</a></li><li><a href=#操作-message>操作 message</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p><a href=https://ithelp.ithome.com.tw/2020ironman>2020 It邦幫忙鐵人賽</a> 系列文章</p><ul><li>ELK Stack<ul><li><a href=https://chechia.net/posts/2019-09-15-self-host-elk-stack-on-gcp/>Self-host ELK stack on GCP</a></li><li><a href=https://chechia.net/posts/2019-09-15-secure-elk-stack/>Secure ELK Stask</a></li><li><a href=https://chechia.net/posts/2019-09-18-monitoring-gce-with-elk/>監測 Google Compute Engine 上服務的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/>監測 Google Kubernetes Engine 的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-18-elastic-or-not-elastic/>是否選擇 ELK 作為解決方案</a></li><li><a href=https://chechia.net/posts/2019-09-21-logstash-on-gke/>使用 logstash pipeline 做數據前處理</a></li><li>Elasticsearch 日常維護：數據清理，效能調校，永久儲存</li><li>Debug ELK stack on GCP</li></ul></li><li>Kafka HA on Kubernetes(6)<ul><li><a href=https://chechia.net/posts/2019-09-22-kafka-deployment-on-kubernetes/>Deploy kafka-ha</a></li><li><a href=https://chechia.net/posts/2019-09-23-kafka-introduction/>Kafka Introduction</a></li><li><a href=https://chechia.net/posts/2019-09-24-kafka-basic-usage/>kafka 基本使用</a></li><li><a href=https://chechia.net/posts/2019-09-25-kafka-operation-scripts/>kafka operation scripts</a></li><li><a href=https://chechia.net/posts/2019-09-25-kafka-ha-topology/>集群內部的 HA topology</a></li><li><a href=https://chechia.net/posts/2019-09-26-kafka-ha-continued/>集群內部的 HA 細節</a></li><li>Prometheus Metrics Exporter 很重要</li><li>效能調校</li></ul></li></ul><p>由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。</p><p>寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。</p><p>對我的文章有興趣，歡迎到我的網站上 <a href=https://chechia.net>https://chechia.net</a> 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。</p><p><img alt="Exausted Cat Face" loading=lazy src=https://d32l83enj9u8rg.cloudfront.net/wp-content/uploads/iStock-966846550-cat-overheating-simonkr-1-940x470.jpg></p><hr><h1 id=摘要>摘要<a hidden class=anchor aria-hidden=true href=#摘要>#</a></h1><ul><li>從 Zookeeper 獲取資訊</li><li>取得並處理 topic</li><li>benchmark kafka</li></ul><h1 id=zookeeper>zookeeper<a hidden class=anchor aria-hidden=true href=#zookeeper>#</a></h1><p>zookeeper 是 kafka 的分散式協調系統，在 kafka 上多個節點間需要協調的內容，例如：彼此節點的ID，位置與當前狀態，或是跨節點 topic 的設定與狀態。取名叫做 zookeeper 就是在協調混亂的分散式系統，,裡面各種不同種類的服務都要協調，象個動物園管理員。<a href=https://zookeeper.apache.org/doc/r3.3.3/zookeeperAdmin.html>Zookeeper 的官方文件</a> 有更詳細的說明。</p><p>Kafka 的節點資訊，與當前狀態，是放在 zookeeper 上，我們可以透過以下指令取得</p><pre><code># 首先先取得 zkCli 的 cli，這個只有連進任何一台 zookeeper 內部都有
kubectl exec -it kafka-0-zookeeper-0 --container kafka-broker bash

# 由於是在 Pod 內部，直接 localhost 詢問本地
/usr/bin/zkCli.sh -server localhost:2181

Connecting to localhost:2181
2019-09-25 15:02:36,089 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2019-09-25 15:02:36,096 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=kafka-0-zookeeper-0.kafka-0-zookeeper-headless.default.svc.cluster.local
2019-09-25 15:02:36,096 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_131
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/usr/bin/../build/classes:/usr/bin/../build/lib/*.jar:/usr/bin/../share/zookeeper/zookeeper-3.4.10.jar:/usr/bin/../share/zookeeper/slf4j-log4j12-1.6.1.jar:/usr/bin/../share/zookeeper/slf4j-api-1.6.1.jar:/usr/bin/../share/zookeeper/netty-3.10.5.Final.jar:/usr/bin/../share/zookeeper/log4j-1.2.16.jar:/usr/bin/../share/zookeeper/jline-0.9.94.jar:/usr/bin/../src/java/lib/*.jar:/usr/bin/../etc/zookeeper:
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.io.tmpdir=/tmp
2019-09-25 15:02:36,100 [myid:] - INFO  [main:Environment@100] - Client environment:java.compiler=&lt;NA&gt;
2019-09-25 15:02:36,101 [myid:] - INFO  [main:Environment@100] - Client environment:os.name=Linux
2019-09-25 15:02:36,101 [myid:] - INFO  [main:Environment@100] - Client environment:os.arch=amd64
2019-09-25 15:02:36,101 [myid:] - INFO  [main:Environment@100] - Client environment:os.version=4.14.127+
2019-09-25 15:02:36,101 [myid:] - INFO  [main:Environment@100] - Client environment:user.name=zookeeper
2019-09-25 15:02:36,102 [myid:] - INFO  [main:Environment@100] - Client environment:user.home=/home/zookeeper
2019-09-25 15:02:36,102 [myid:] - INFO  [main:Environment@100] - Client environment:user.dir=/
2019-09-25 15:02:36,105 [myid:] - INFO  [main:ZooKeeper@438] - Initiating client connection, connectString=localhost:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@42110406
Welcome to ZooKeeper!
2019-09-25 15:02:36,160 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1032] - Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
JLine support is enabled
2019-09-25 15:02:36,374 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@876] - Socket connection established to localhost/127.0.0.1:2181, initiating session
2019-09-25 15:02:36,393 [myid:] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1299] - Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x16d67baf1310001, negotiated timeout = 30000

WATCHER::

WatchedEvent state:SyncConnected type:None path:null
[zk: localhost:2181(CONNECTED) 0]
</code></pre><p>取得 kafka broker 資料</p><pre><code># List root Nodes
$ ls /

[cluster, controller, controller_epoch, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]

# Brokers 的資料節點
$ ls /brokers
[ids, topics, seqid]

# List /brokers/ids 得到三個 kafka broker
$ ls /brokers/ids
[0, 1, 2]

# 列出所有 topic 名稱
ls /brokers/topics
[ticker]
</code></pre><p>ticker 是上篇範利用到的 topic</p><p>簡單來說，zookeeper 存放這些狀態與 topic 的 metadata</p><ul><li>儲存核心的狀態與資料，特別是 broker 萬一掛掉，也還需要維持的資料</li><li>協調工作，例如協助 broker 處理 quorum，紀錄 partition master 等</li></ul><pre><code># 離開 zkCli
quit
</code></pre><h1 id=kafka>Kafka<a hidden class=anchor aria-hidden=true href=#kafka>#</a></h1><p>這邊一樣先連線進去一台 broker，取得 kafka binary</p><pre><code>kubectl exec -it kafka-0-0 --container kafka-broker bash

 ls /usr/bin/ | grep kafka
kafka-acls
kafka-broker-api-versions
kafka-configs
kafka-console-consumer
kafka-console-producer
kafka-consumer-groups
kafka-consumer-perf-test
kafka-delegation-tokens
kafka-delete-records
kafka-dump-log
kafka-log-dirs
kafka-mirror-maker
kafka-preferred-replica-election
kafka-producer-perf-test
kafka-reassign-partitions
kafka-replica-verification
kafka-run-class
kafka-server-start
kafka-server-stop
kafka-streams-application-reset
kafka-topics
kafka-verifiable-consumer
kafka-verifiable-producer
</code></pre><p>很多工具，我們這邊只會看其中幾個</p><h3 id=topic-資訊>topic 資訊<a hidden class=anchor aria-hidden=true href=#topic-資訊>#</a></h3><p>Topic 的資訊，跟 zookeeper 要</p><pre><code># List topics
/usr/bin/kafka-topics --list --zookeeper kafka-0-zookeeper

ticker
</code></pre><h3 id=操作-message>操作 message<a hidden class=anchor aria-hidden=true href=#操作-message>#</a></h3><p>從 topic 取得 message</p><pre><code># This will create a new console-consumer and start consuming message to stdout
/usr/bin/kafka-console-consumer \
--bootstrap-server localhost:9092 \
--topic engine_topic_soundwave_USD \
--timeout 0 \
--from-beginning
</code></pre><p>如果 ticker 那個 example pod 還在執行，這邊就會收到 ticker 的每秒 message</p><p>如果沒有，也可以開啟另一個 broker 的連線</p><pre><code>kubectl exec -it kafka-0-1 --container kafka-broker bash

# 使用 producer 的 console 連入，topic 把 message 塞進去
/usr/bin/kafka-console-producer \
--broker-list localhost:9092\
 --topic ticker

tick [enter]
tick [enter]
</code></pre><p>kafka-console-consumer 那個 terminal 就會收到 message</p><pre><code>tick
tick
</code></pre><p>當然也可以使用 consumer group</p><pre><code># Use consumer to check ticker topics
/usr/bin/kafka-console-consumer \
--bootstrap-server localhost:9092 \
--topic ticker \
--group test
</code></pre><p>有做過上面的操作產生 consumer group，就可以透過 consumer API，取得 consumer group 狀態</p><pre><code># Check consumer group
/usr/bin/kafka-consumer-groups \
--bootstrap-server localhost:9092 \
--group ticker \
--describe

Consumer group 'test' has no active members.

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
ticker          0          23              23              0               -               -               -
</code></pre><h1 id=topic-設定操作>Topic 設定操作<a hidden class=anchor aria-hidden=true href=#topic-設定操作>#</a></h1><p><a href=https://kafka.apache.org/documentation/#topicconfigs>Topic 設定文件</a> 在此</p><p>這邊透過 kafka-configs 從 zookeeper 取得 topic 設定，這邊的 max.message.bytes，是這個 topic 每個 message 的最大上限。</p><pre><code>/usr/bin/kafka-configs --zookeeper kafka-0-zookeeper:2181 --describe max.message.bytes --entity-type topics

Configs for topic '__consumer_offsets' are segment.bytes=104857600,cleanup.policy=compact,compression.type=producer
Configs for topic 'ticker' are
</code></pre><p><code>__consumer__offsets</code> 是系統的 topic ，紀錄目前 consumer 讀取的位置。</p><p>ticker 沒有設定，就是 producer 當初產生 topic 時沒有指定，使用 default 值</p><p>由於我們公司的使用情境常常會超過，所以可以檢查 producer app 那端送出的 message 大小，在比較這邊的設定。當然現在 ticker 的範例，只有一個 0-60 的數值，並不會超過。這個可以在 helm install 的時候，使用 value.yaml 傳入時更改。</p><p>不喜歡這個值，可以更改，這邊增加到 16MB</p><pre><code>TOPIC=ticker

/usr/bin/kafka-configs \
  --zookeeper kafka-3-zookeeper:2181 \
  --entity-type topics \
  --alter \
  --entity-name ${TOPIC} \
  --add-config max.message.bytes=16000000

</code></pre><h1 id=benchmark>Benchmark<a hidden class=anchor aria-hidden=true href=#benchmark>#</a></h1><p>使用內建工具跑 benchmark</p><p>Producer</p><pre><code>/usr/bin/kafka-producer-perf-test \
  --num-records 100 \
  --record-size 100 \
  --topic performance-test \
  --throughput 100 \
  --producer-props bootstrap.servers=kafka:9092 max.in.flight.requests.per.connection=5 batch.size=100 compression.type=none

100 records sent, 99.108028 records/sec (0.01 MB/sec), 26.09 ms avg latency, 334.00 ms max latency, 5 ms 50th, 70 ms 95th, 334 ms 99th, 334 ms 99.9th.
</code></pre><p>Consumer</p><pre><code>/usr/bin/kafka-consumer-perf-test \
  --messages 100 \
  --broker-list=kafka:9092 \
  --topic performance-test \
  --group performance-test \
  --num-fetch-threads 1
</code></pre></div><footer class=post-footer><ul class=post-tags><li><a href=https://chechia.net/tags/%E9%90%B5%E4%BA%BA%E8%B3%BD2019/>鐵人賽2019</a></li><li><a href=https://chechia.net/tags/kafka/>Kafka</a></li><li><a href=https://chechia.net/tags/kubernetes/>Kubernetes</a></li><li><a href=https://chechia.net/tags/ithome/>Ithome</a></li></ul><nav class=paginav><a class=prev href=https://chechia.net/posts/2019-09-25-kafka-ha-topology/><span class=title>« Prev</span><br><span>Kafka HA Topology</span>
</a><a class=next href=https://chechia.net/posts/2019-09-24-kafka-basic-usage/><span class=title>Next »</span><br><span>Kafka-basic-usage</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on x" href="https://x.com/intent/tweet/?text=Kafka%20Operation%20Scripts&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f&amp;hashtags=%e9%90%b5%e4%ba%ba%e8%b3%bd2019%2ckafka%2ckubernetes%2cithome"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f&amp;title=Kafka%20Operation%20Scripts&amp;summary=Kafka%20Operation%20Scripts&amp;source=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f&title=Kafka%20Operation%20Scripts"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on whatsapp" href="https://api.whatsapp.com/send?text=Kafka%20Operation%20Scripts%20-%20https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on telegram" href="https://telegram.me/share/url?text=Kafka%20Operation%20Scripts&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kafka Operation Scripts on ycombinator" href="https://news.ycombinator.com/submitlink?t=Kafka%20Operation%20Scripts&u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-25-kafka-operation-scripts%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://chechia.net/>Che-Chia Chang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>