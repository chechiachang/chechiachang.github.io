<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ithome on Che-Chia Chang</title>
    <link>https://chechia.net/tags/ithome/</link>
    <description>Recent content in ithome on Che-Chia Chang</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2016–2020, Che-Chia Chang; all rights reserved.</copyright>
    <lastBuildDate>Mon, 07 Oct 2019 08:12:10 +0800</lastBuildDate><atom:link href="https://chechia.net/tags/ithome/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prometheus &amp; Kubernetes State Metrics Exporter</title>
      <link>https://chechia.net/post/2019-10-07-prometheus-kube-state-metrics-exporter/</link>
      <pubDate>Mon, 07 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-07-prometheus-kube-state-metrics-exporter/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
如果要透過 prometheus 來監控集群的運行狀況，有兩個 exporter 是必裝的，一個是把 node 狀態 export 出來的 node exporter，一個是把 kubernetes 集群狀態 export 出來的 kube state metrics exporter。
Node Exporter 簡介 kube metrics exporter 安裝與設定 Node Exporter Node Exporter 是 prometheus 官方維護的一個子項目，主要在把類 unix 硬體 kernel 的 metrics 送出來。官方也支援 windows node 與 nvidia gpu metrics，可以說是功能強大。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Exporter Library &amp; Redis Exporter</title>
      <link>https://chechia.net/post/2019-10-06-prometheus-exporter-library-redis-exporter/</link>
      <pubDate>Sun, 06 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-06-prometheus-exporter-library-redis-exporter/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Exporter 工作原理簡介 Prometheus exporter library Exporter workflow 上次講到 exporter 可以從服務端把運行資料抽出來，並開成 http endpoint，讓 prometheus 來 scrape metrics。那 exporter 本身是如何取得服務內部的 metrics 呢? 我們今天就稍微看一下。
Redis Exporter 我們今天以 Redis Exporter 為例，研究一下外部的 exporter 是如何取得 redis 內部的 metrcs。
Redis exporter 是用 golang 寫的一個小程式，總共算算才 1000 行，而且很多都是對 redis 內部 metrics 的清單，以及轉化成 prometheus metrics 的 tool functions，主要的邏輯非常簡單。我們簡單看一下源碼。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Deployment on Kubernetes</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-deployment-on-kubernetes/</link>
      <pubDate>Fri, 04 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-deployment-on-kubernetes/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Prometheus Introduction Deploy Prometheus Prometheus Introduction 生產環境與非生產環境，其中的一指標就是有沒有足夠完整的服務監測系統，這句話可以看出服務監測對於產品化是多麼重要。而監控資料 (metrics) 的收集與可視化工具其實非常多，例如上周介紹的 ELK Stack，這次我們要來介紹另外一個很多人使用的 prometheus。
Promethues 在官網上提到 是一個 Monitoring system and time series database
可以收集高維度的資料 使用自己的 PromQL 做有效且精簡的資料查詢 內建資料瀏覽器，並且與 Grafana 高度整合 支援 sharding 與 federation，來達到水平擴展 有許多隨插即用的整合 exporter，例如 redis-exporter, kafka-exporter，kubernetes-exporter ，都可以直接取得資料 支援 alert，使用 PromQL 以及多功能的告警，可以設定精準的告警條件 與 ELK 做比較 基本上 Prometheus 跟 ELK 比，其實是很奇怪的一件事，但這也是最常被問的一個問題。兩者在本質上是完全不同的系統。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Deploy Grafana</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-deploy-grafana/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-deploy-grafana/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Grafana Introduction Deploy Grafana Grafana Introduction 上偏我們簡單介紹了 Prometheus，prometheus 的 Web Portol 已經附上簡單的 Query 與 Graph 工具，但一般我們在使用時，還是會搭配 Grafana 來使用。
Grafana 在官網上提到 是一個 Analytics system，可以協助了解運行資料，建立完整的 dashboard。
支援許多圖表，直線圖，長條圖，區域分析，基本上需要的都有 在圖表上定義 alter，並且主動告警，整合其他通訊軟體 對後端 data source 的整合，可以同時使用 ELK, prometheus, influxdb 等 30 多種的資料來源 有許多公開的 plugin 與 dashboard 可以匯入使用 總之功能強大，至於用起來的感覺，個人是非常推薦。如果有大得想要試玩看看，可以直接到 Grafana Live Demo 上面試玩
          
          
        
      </description>
    </item>
    
    <item>
      <title>Prometheus Scrape</title>
      <link>https://chechia.net/post/2019-10-04-prometheus-scrape/</link>
      <pubDate>Fri, 04 Oct 2019 08:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-04-prometheus-scrape/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Prometheus / Grafana (5) GKE 上自架 Prometheus GKE 上自架 Grafana scrape config &amp;amp; exporter Dive into Redis Exporter 輸出 kube-state 的監測數據 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Prometheus scrape scrape_configs Node exporter Scrape Prometheus 收集 metrics 的方式，是從被監測的目標的 http endpoints 收集 (scrape) metrics，目標服務有提供 export metrics 的 endpoint 的話，稱作 exporter。例如 kafka-exporter 就會收集 kafka 運行的 metrics，變成 http endpoint instance，prometheus 從 instance 上面收集資料。
Promethesu 自己也是也提供 metrics endpoint，並且自己透過 scrape 自己的 metrics endpoint 來取得 self-monitoring 的 metrics。把自己當作外部服務監測。下面的設定就是直接透過 http://localhost:9090/metrics 取得。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Failure Recovery</title>
      <link>https://chechia.net/post/2019-10-03-redis-ha-failure-recovery/</link>
      <pubDate>Thu, 03 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-03-redis-ha-failure-recovery/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Failure Case Recovery Topology 上篇的例子完成應該是這樣
1 2 +-------+ +--------+ +------------+ +---------+ 3 |Clients|---|HAProxys|----|redis master|----|sentinels| 4 +-------+ +--------+ +------------+ +---------+ HAproxy 作為後端 redis 的 gateway Client 透過 HAproxy 連入 redis master sentinel 負責監測 redis 狀態與 failover，只是 client 不再透過 sentinel 去取得 master，而是透過 HAProxy。 那現在就來聊聊這些服務可能怎麼死的，回復的機制又是如何
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha HAProxy</title>
      <link>https://chechia.net/post/2019-10-02-redis-ha-on-haproxy/</link>
      <pubDate>Wed, 02 Oct 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-10-02-redis-ha-on-haproxy/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 HAProxy Introduction Redis Sentinel with HAProxy HAProxy Intro HAproxy 全名是 High Availability Proxy，是一款開源 TCP/HTTP load balancer，他可以
聽 tcp socket，連 server，然後把 socket 接在一起讓雙向流通 可做 Http reverse-proxy (Http gateway)，自己作為代理 server，把接受到的 connection 傳到後端的 server。 SSL 終端，可支援 client-side 與 server-side 的 ssl/tls 當 tcp/http normalizer 更改 http 的 request 與 response 當 switch，決定 request 後送的目標 做 load balancer，為後端 server 做負載均衡 調節流量，設定 rate limit，或是根據內容調整流量 HAProxy 還有其他非常多的功能，想了解細節可以來看原理解說文件
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Topology</title>
      <link>https://chechia.net/post/2019-09-30-redis-ha-topology/</link>
      <pubDate>Mon, 30 Sep 2019 16:12:10 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-30-redis-ha-topology/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 Redis Sentinel Topology Topology Masters: M1, M2, M3, &amp;hellip;, Mn. Slaves: R1, R2, R3, &amp;hellip;, Rn (R stands for replica). Sentinels: S1, S2, S3, &amp;hellip;, Sn. Clients: C1, C2, C3, &amp;hellip;, Cn.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Sentinel</title>
      <link>https://chechia.net/post/2019-09-29-redis-ha-sentinel/</link>
      <pubDate>Sun, 29 Sep 2019 17:14:38 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-29-redis-ha-sentinel/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
摘要 redis-sentinel redis sentinel 與 redis 使用相容的 api，直接使用 redis-cli 透過 26479 port 連入，可以連到 sentinel，透過 sentinel 可以取得 redis master 的狀態與連線設定。
1redis-cli -h redis-redis-ha -p 26479 上篇我們的 redis-ha 安裝完變這樣
1$ kubectl get po | grep redis 2 3NAME READY STATUS RESTARTS AGE 4redis-1-redis-ha-server-0 3/3 Running 0 3d4h 5redis-1-redis-ha-server-1 3/3 Running 0 3d5h 6redis-1-redis-ha-server-2 3/3 Running 0 3d4h 有三個 Pod，裡面都是一個 redis, sentinel, 跟 exporter，這篇文章會專注講 sentinel 的功能與機制
          
          
        
      </description>
    </item>
    
    <item>
      <title>Redis Ha Deployment</title>
      <link>https://chechia.net/post/2019-09-28-redis-ha-deployment/</link>
      <pubDate>Sat, 28 Sep 2019 15:14:23 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-28-redis-ha-deployment/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
在 GKE 上部署 Redis HA (5) 使用 helm 部署 redis-ha Redis HA with sentinel Redis sentinel topology Redis HA with HAproxy Redis HA Failure Recovery Prometheus Metrics Exporter 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.net 閱讀其他技術文章，有任何謬誤也請各方大德直接聯繫我，感激不盡。
今天的文會比較短，因為我早上在綠島已經水肺潛水潛了三趟，有點累哈哈
Redis introduction Redis 是常用的 in-memory 的資料儲存庫，可作為資料庫，快取，message broker 使用，都非常好用。Redis 官方支援 high availability，使用的是 redis-sentinel ，今天我們就來部署一個有完整 sentinel 的 redis-ha。
Redis 另外提供了一個 solution Redis cluster (multiple writer solution)，作為增加資料輸出帶寬，與增加資料耐用度的分散式解決方案，與 redis sentinel 所處理的 ha 問題是不相同的。有機會我們也來談。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka HA Continued</title>
      <link>https://chechia.net/post/2019-09-26-kafka-ha-continued/</link>
      <pubDate>Thu, 26 Sep 2019 22:50:32 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-26-kafka-ha-continued/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Operation Scripts</title>
      <link>https://chechia.net/post/2019-09-25-kafka-operation-scripts/</link>
      <pubDate>Wed, 25 Sep 2019 22:50:32 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-25-kafka-operation-scripts/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka-basic-usage</title>
      <link>https://chechia.net/post/2019-09-24-kafka-basic-usage/</link>
      <pubDate>Tue, 24 Sep 2019 21:59:49 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-24-kafka-basic-usage/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka-introduction</title>
      <link>https://chechia.net/post/2019-09-23-kafka-introduction/</link>
      <pubDate>Mon, 23 Sep 2019 21:59:49 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-23-kafka-introduction/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
寫文章真的是體力活，覺得我的文章還有參考價值，請左邊幫我點讚按個喜歡，右上角幫我按個追縱，底下歡迎留言討論。給我一點繼續走下去的動力。
對我的文章有興趣，歡迎到我的網站上 https://chechia.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Helm Configuration</title>
      <link>https://chechia.net/post/2019-09-23-kafka-helm-configuration/</link>
      <pubDate>Mon, 23 Sep 2019 21:55:29 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-23-kafka-helm-configuration/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Kafka Deployment on Kubernetes</title>
      <link>https://chechia.net/post/2019-09-22-kafka-deployment-on-kubernetes/</link>
      <pubDate>Sun, 22 Sep 2019 09:58:41 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-22-kafka-deployment-on-kubernetes/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
ELK Stack Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP Kafka HA on Kubernetes(6) Deploy kafka-ha Kafka Introduction kafka 基本使用 kafka operation scripts 集群內部的 HA topology 集群內部的 HA 細節 Prometheus Metrics Exporter 很重要 效能調校 由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
碎念 30 天每天一文真的蠻逼人的，每一篇都是新寫，還要盡可能顧及文章品質，下班趕文章，各位大德寫看看就知道
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitoring GKE With Elk</title>
      <link>https://chechia.net/post/2019-09-19-monitoring-gke-with-elk/</link>
      <pubDate>Thu, 19 Sep 2019 17:06:29 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-19-monitoring-gke-with-elk/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：
node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar 上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。
          
          
        
      </description>
    </item>
    
    <item>
      <title>Monitoring GCE With ELK</title>
      <link>https://chechia.net/post/2019-09-18-monitoring-gce-with-elk/</link>
      <pubDate>Wed, 18 Sep 2019 19:10:50 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-18-monitoring-gce-with-elk/</guid>
      <description>
        
          
            2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
ELK 的 beats 是輕量級的系統監測收集器，beats 收集到的 data 經過 mapping 可以送到 Elasticsearch 後，進行彈性的搜尋比對。
beat 有許多種類，依據收集的 data 區別：
Auditbeat: Audit data Filebeat: Log files Functionbeat: Cloud data Heartbeat: Availability Journalbeat: Systemd journals Metricbeat: Metrics Packetbeat: Network traffic Winlogbeat: Windows event logs 這邊先以 filebeat 為例，在 GCE 上收集圓端服務節點上的服務日誌與系統日誌，並在 ELK 中呈現。
          
          
        
      </description>
    </item>
    
    <item>
      <title>2019 IT邦幫忙鐵人賽</title>
      <link>https://chechia.net/post/2019-09-09-ithome-ironman-challenge/</link>
      <pubDate>Mon, 09 Sep 2019 16:56:03 +0800</pubDate>
      
      <guid>https://chechia.net/post/2019-09-09-ithome-ironman-challenge/</guid>
      <description>
        
          
            2019 IT邦幫忙鐵人賽
          
          
        
      </description>
    </item>
    
    <item>
      <title>2020 IT邦幫忙鐵人賽</title>
      <link>https://chechia.net/post/2020-09-09-ithome-ironman-challenge/</link>
      <pubDate>Mon, 09 Sep 2019 16:56:03 +0800</pubDate>
      
      <guid>https://chechia.net/post/2020-09-09-ithome-ironman-challenge/</guid>
      <description>
        
          
            2020 IT邦幫忙鐵人賽
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
