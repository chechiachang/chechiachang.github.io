<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Monitoring GKE With Elk | Che-Chia Chang</title><meta name=keywords content="鐵人賽2019,kubernetes,logstash,ithome,filebeat,fluentd"><meta name=description content="2020 It邦幫忙鐵人賽 系列文章

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP

作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。

這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：

node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics)
cluster: 處理 cluster 等級的 log,  event 或是 metrics
pod: 針對特定 pod 直接去掛一個 sidecar

上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。"><meta name=author content="chechiachang"><link rel=canonical href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/><meta name=google-site-verification content="G-QYR8JCDGM9"><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://chechia.net/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://chechia.net/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://chechia.net/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://chechia.net/favicon/favicon-32x32.png><link rel=mask-icon href=https://chechia.net/favicon/favicon-32x32.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-QYR8JCDGM9"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QYR8JCDGM9")}</script><meta property="og:url" content="https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/"><meta property="og:site_name" content="Che-Chia Chang"><meta property="og:title" content="Monitoring GKE With Elk"><meta property="og:description" content="2020 It邦幫忙鐵人賽 系列文章
Self-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。
這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：
node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar 上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-09-19T17:06:29+08:00"><meta property="article:modified_time" content="2019-09-19T17:06:29+08:00"><meta property="article:tag" content="鐵人賽2019"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Logstash"><meta property="article:tag" content="Ithome"><meta property="article:tag" content="Filebeat"><meta property="article:tag" content="Fluentd"><meta property="og:image" content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Monitoring GKE With Elk"><meta name=twitter:description content="2020 It邦幫忙鐵人賽 系列文章

Self-host ELK stack on GCP
Secure ELK Stask
監測 Google Compute Engine 上服務的各項數據
監測 Google Kubernetes Engine 的各項數據
是否選擇 ELK 作為解決方案
使用 logstash pipeline 做數據前處理
Elasticsearch 日常維護：數據清理，效能調校，永久儲存
Debug ELK stack on GCP

作為範例的 ELK 的版本是當前的 stable release 7.3.1。
由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。

這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。
官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。
這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：

node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics)
cluster: 處理 cluster 等級的 log,  event 或是 metrics
pod: 針對特定 pod 直接去掛一個 sidecar

上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://chechia.net/posts/"},{"@type":"ListItem","position":2,"name":"Monitoring GKE With Elk","item":"https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Monitoring GKE With Elk","name":"Monitoring GKE With Elk","description":"2020 It邦幫忙鐵人賽 系列文章\nSelf-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。\n由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。\n官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。\n這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：\nnode: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar 上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。\n","keywords":["鐵人賽2019","kubernetes","logstash","ithome","filebeat","fluentd"],"articleBody":"2020 It邦幫忙鐵人賽 系列文章\nSelf-host ELK stack on GCP Secure ELK Stask 監測 Google Compute Engine 上服務的各項數據 監測 Google Kubernetes Engine 的各項數據 是否選擇 ELK 作為解決方案 使用 logstash pipeline 做數據前處理 Elasticsearch 日常維護：數據清理，效能調校，永久儲存 Debug ELK stack on GCP 作為範例的 ELK 的版本是當前的 stable release 7.3.1。\n由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。\n這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。\n官方文件 ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。\n這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：\nnode: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics) cluster: 處理 cluster 等級的 log, event 或是 metrics pod: 針對特定 pod 直接去掛一個 sidecar 上面的方法是可以混搭的，kubernetes 個個層級有log 處理流程，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。\n簡單來說，是去對的地方找對的 log。在架構上要注意 scalability 與 resource 分配，不要影響本身提供服務的 GKE ，但又能獲得盡量即時的 log。\n我們這邊直接進入 kubernetes resource 的設定，底下會附上在 GKE 找 log 的過程。\nNode level log harvest 為每一個 node 配置 filebeat，然後在 node 上面尋找 log，然後如我們上篇所敘述加到 input ，就可以把 log 倒出來。\n直覺想到就是透過 daemonsets 為每個 node 部署一個 filebeat pod，然後 mount node 的 log 資料夾，在設置 input。\nDeploy daemonsets kubernetes resource 的 yaml 請參考 我的 github elk-kubernetes\n給予足夠的 clusterrolebinding 到 elk\nkubectl apply -f filebeat/7.3.1/clusterrolebinding.yaml 先更改 filebeat 的設定，如何設定 elasticsearch 與 kibana，請參考上篇。至於 input 的部份已經配置好了。\nvim filebeat/7.3.1/daemonsets-config-configmap.yaml kubectl apply -f filebeat/7.3.1/daemonsets-config-configmap.yaml 部屬 filebeat daemonsets，會每一個 node 部屬一個 filebeat\nkubectl apply -f filebeat/7.3.1/daemonsets.yaml 取得 daemonsets 的狀態\nkubectl --namespcae elk get pods NAME READY STATUS RESTARTS AGE filebeat-bjfp9 1/1 Running 0 6m56s filebeat-fzr9n 1/1 Running 0 6m56s filebeat-vpkm7 1/1 Running 0 6m56s ... 有設定成功的話，kibana 這邊就會收到 kubernetes 上面 pod 的 log\nlog havest for specific pods 由於 kubernetes 上我們可以便利的調度 filebeat 的部屬方式，這邊也可以也可以使用 deployment ，配合 pod affinity，把 filebeat 放到某個想要監測的 pod，這邊的例子是 nginx-ingress-controller。\nKubernetes 上有一個或多個 nginx ingress controller 部屬一個或多個 filebeat 到有 nginx 的 node 上 filebeat 去抓取 nginx 的 input， 並使用 filebeat 的 nginx module 做預處理 nginx module 預設路徑需要調整，這邊使用 filebeat autodiscover 來處理 一樣 apply 前記得先檢查跟設定\nvim filebeat/7.3.1/nginx-config-configmap.yaml kubectl apply -f filebeat/7.3.1/nginx-config-configmap.yaml 部屬 filebeat deployment 由於有設定 pod affinity ，這個 filebeat 只會被放到有 nginx ingress controller 的這個節點上，並且依照 autodiscover 設定的條件去蒐集 nginx 的 log\nkubectl apply -f filebeat/7.3.1/nginx-deployment.yaml 有設定成功的話，kibana 這邊就會收到 kubernetes 上面 pod 的 log\n另外，由於有啟動 nginx module，logstash 收到的內容已經是處理過得內容。\nGCP fluentd 如果是使用 GKE 的朋友，可以投過開啟 stackdriver logging 的功能，把集群中服務的 log 倒到 stackdriver，基本上就是 node -\u003e (daemonsets) fluentd -\u003e stackdriver。\n這個 fluentd 是 GCP 如果有啟動 Stackdriver Logging 的話，自動幫你維護的 daemonsets，設定不可改，改了會被 overwrite 會去，所以不太方便從這邊動手腳。\nBtw stackdriver 最近好像改版，目前做 example 的版本已經變成 lagency （淚\n但我們先假設我們對這個 pod 的 log 很有興趣，然後把這邊的 log 透過 filebeat 送到 ELK 上XD\n因為 GKE 透過 fluentd 把 GKE 上面的 log 倒到 stackdriver，而我們是想把 log 倒到 ELK，既然這樣我們的 input 來源是相同的，而且很多處理步驟都可以在 ELK 上面互通，真的可以偷看一下 fluentd 是去哪收集 log ，怎麼處理 log pipeline，我們只要做相應設定就好。\n畢竟 google 都幫我們弄得妥妥的，不參考一下他的流程太可惜。\n偷看一下 GKE 上 fluentd 是去哪找 log ，這個是 fluentd gcp configmap，雖然看到這邊感覺扯遠了，但因為很有趣所有我就繼續看下去，各位大德可以跳過XD\nconfigmap 中的這個 input 設定檔，其中一個 source 就是一個資料來源，相當於 filebeat 的 input。這邊這個 source 就是去 /var/log/containers/*.log 收 log\n這邊還做了幾件事：\n打上 reform.* tag，讓下個 match 可以 收進去 pipeline 處理 附帶 parse 出 time containers.input.conf @type tail path /var/log/containers/*.log pos_file /var/log/gcp-containers.log.pos # Tags at this point are in the format of: # reform.var.log.containers.__-.log tag reform.* read_from_head true @type multi_format format json time_key time time_format %Y-%m-%dT%H:%M:%S.%NZ format /^(?.+) (?stdout|stderr) [^ ]* (?.*)$/ time_format %Y-%m-%dT%H:%M:%S.%N%:z 他這邊做一些 error handling，然後用 ruby (!) parse，這邊就真的太遠，細節大家可以 google ＸＤ。不過這邊使用的 pattern matching 我們後幾篇在 logstash pipeline 上，也會有機會提到，機制是類似的。\n@type parser format /^(?\\w)(?\\d{4} [^\\s]*)\\s+(?\\d+)\\s+(?[^ \\]]+)\\] (?.*)/ reserve_data true suppress_parse_error_log true emit_invalid_record_to_error false key_name log @type record_reformer enable_ruby true # Extract local_resource_id from tag for 'k8s_container' monitored # resource. The format is: # 'k8s_container...'. \"logging.googleapis.com/local_resource_id\" ${\"k8s_container.#{tag_suffix[4].rpartition('.')[0].split('_')[1]}.#{tag_suffix[4].rpartition('.')[0].split('_')[0]}.#{tag_suffix[4].rpartition('.')[0].split('_')[2].rpartition('-')[0]}\"} # Rename the field 'log' to a more generic field 'message'. This way the # fluent-plugin-google-cloud knows to flatten the field as textPayload # instead of jsonPayload after extracting 'time', 'severity' and # 'stream' from the record. message ${record['log']} # If 'severity' is not set, assume stderr is ERROR and stdout is INFO. severity ${record['severity'] || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end} tag ${if record['stream'] == 'stderr' then 'raw.stderr' else 'raw.stdout' end} remove_keys stream,log ssh 進去逛 想看機器上實際的 log 狀況，我們也可以直接 ssh 進去\n先透過 kubectl 看一下 pod\n$ kubectl get daemonsets --namespace kube-system NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE fluentd-gcp-v3.2.0 7 7 7 7 7 beta.kubernetes.io/fluentd-ds-ready=true 196d $ kubectl get pods --output wide --namespace kube-system NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES fluentd-gcp-scaler-1234567890-vfbhc 1/1 Running 0 37d 10.140.0. gke-chechiachang-pool-1-123456789-5gqn fluentd-gcp-v3.2.0-44tl7 2/2 Running 0 37d 10.140.0. gke-chechiachang-pool-1-123456789-wcq0 fluentd-gcp-v3.2.0-5vc6l 2/2 Running 0 37d 10.140.0. gke-chechiachang-pool-1-123456789-tp05 fluentd-gcp-v3.2.0-6rqvc 2/2 Running 0 37d 10.140.0. gke-chechiachang-pool-1-123456789-5gqn fluentd-gcp-v3.2.0-mmwk4 2/2 Running 0 37d 10.140.0. gke-chechiachang-pool-1-123456789-vxld 先透過 kubectl 看一下 node\n$ kubectl get node NAME STATUS ROLES AGE VERSION gke-chechaichang-pool-1-123456789-3bzp Ready 37d v1.13.7-gke.8 gke-chechaichang-pool-1-123456789-5gqn Ready 37d v1.13.7-gke.8 gke-chechaichang-pool-1-123456789-8n8z Ready 37d v1.13.7-gke.8 ... gcloud compute ssh gke-chechaichang-pool-1-123456789-3bzp 如使用其他雲平台的 kubernetes service，或是 bare metal 的集群，請依照各自系統的方式連進去看看。\nssh node 找 log ssh 進去後就可以到處來探險，順便看看 GKE 跑在機器上到底做了什麼事情。\n如果官方有出文件，可能可以不用進來看。各位大德有發現文件請留言跟我說。我個人很喜歡自己架集群起來連就去看，面對照官方文件上寫的東西，當然大部份時候都是文件沒有帶到，有很多發現。\n$ ls /var/log gcp-*-log.pos kube-proxy.log containers/ metrics/ pods/ ... /var/log/containers 看一下，格式是 pod_namespace_container 這邊是 link 到 /var/log/pods/\n$ ls -al /var/log/containers lrwxrwxrwx 1 root root 105 Aug 12 07:42 fluentd-gcp-v3.2.0-st6cl_kube-system_fluentd-gcp-5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac.log -\u003e /var/log/pods/kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008/fluentd-gcp/0.log 看到 pods 就覺得是你了，裡面有 pod 資料夾，格式是 namespace_pod_uuid\nls /var/log/pods default_pod-1-1234567890-fxxhp_uuid kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008 kube-system_heapster-v1.6.0-beta.1- kube-system_kube-proxy-gke- kube-system_l7-default-backend- kube-system_prometheus-to-sd- 再進去有 container log，格式是 pod_namespace_container.log，也是 link\nls -al /var/log/pods/kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008/fluentd-gcp/ lrwxrwxrwx 1 root root 165 Aug 12 07:42 0.log -\u003e /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log 最終 link 到\nsudo su $ ls -alh /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/ total 3.9M drwx------ 4 root root 4.0K Aug 12 07:42 . drwx------ 92 root root 20K Sep 18 11:28 .. -rw-r----- 1 root root 3.8M Sep 18 11:29 5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log drwx------ 2 root root 4.0K Aug 12 07:42 checkpoints -rw------- 1 root root 7.8K Aug 12 07:42 config.v2.json -rw-r--r-- 1 root root 2.3K Aug 12 07:42 hostconfig.json drwx------ 2 root root 4.0K Aug 12 07:42 mounts 頭尾偷喵一下，確定是我們在找的東西\nhead /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log tail /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log 這樣就找到我們的 log 了\n小節 使用 filebeat 去查找 透過 kubernetes daemonsets 可以快速佈置一份 filebeat 到所有 node，且設定都是一起更新 透過 kubernetes deployment 可以指定 filebeat 的位置，去跟隨想要監測的服務 如果不熟 log 處理流程，可以直接看偷看大廠的服務，會有很多靈感 沒事可以多跑進 Kubernetes 服務節點逛逛，有很多有趣的東西 ","wordCount":"912","inLanguage":"en","image":"https://chechia.net/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2019-09-19T17:06:29+08:00","dateModified":"2019-09-19T17:06:29+08:00","author":{"@type":"Person","name":"chechiachang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/"},"publisher":{"@type":"Organization","name":"Che-Chia Chang","logo":{"@type":"ImageObject","url":"https://chechia.net/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://chechia.net/ accesskey=h title="Home (Alt + H)"><img src=https://chechia.net/favicon/favicon-32x32.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://chechia.net/#posts title=Posts><span>Posts</span></a></li><li><a href=https://mvp.microsoft.com/zh-TW/mvp/profile/e407d0b9-5c01-eb11-a815-000d3a8ccaf5 title=MVP><span>MVP</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://chechia.net/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://chechia.net/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://chechia.net/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://chechia.net/>Home</a>&nbsp;»&nbsp;<a href=https://chechia.net/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Monitoring GKE With Elk</h1><div class=post-meta><span title='2019-09-19 17:06:29 +0800 CST'>September 19, 2019</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;912 words&nbsp;·&nbsp;chechiachang&nbsp;|&nbsp;<a href=https://github.com/chechiachang.github.io-src/content/posts/2019-09-19-monitoring-gke-with-elk.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#ssh-進去逛>ssh 進去逛</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p><a href=https://ithelp.ithome.com.tw/2020ironman>2020 It邦幫忙鐵人賽</a> 系列文章</p><ul><li><a href=https://chechia.net/posts/2019-09-15-self-host-elk-stack-on-gcp/>Self-host ELK stack on GCP</a></li><li><a href=https://chechia.net/posts/2019-09-15-secure-elk-stack/>Secure ELK Stask</a></li><li><a href=https://chechia.net/posts/2019-09-18-monitoring-gce-with-elk/>監測 Google Compute Engine 上服務的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-19-monitoring-gke-with-elk/>監測 Google Kubernetes Engine 的各項數據</a></li><li><a href=https://chechia.net/posts/2019-09-18-elastic-or-not-elastic/>是否選擇 ELK 作為解決方案</a></li><li><a href=https://chechia.net/posts/2019-09-21-logstash-on-gke/>使用 logstash pipeline 做數據前處理</a></li><li>Elasticsearch 日常維護：數據清理，效能調校，永久儲存</li><li>Debug ELK stack on GCP</li></ul><p>作為範例的 ELK 的版本是當前的 stable release 7.3.1。</p><p>由於我比較熟悉 GCP / GKE 的服務，這篇的操作過程都會以 GCP 平台作為範例，不過操作過程大體上是跨平台通用的。</p><hr><p>這篇來要 Kubernetes 環境(GKE)裡面的 log 抓出來，送到 ELK 上。</p><p><a href=https://www.elastic.co/guide/en/beats/filebeat/7.3/running-on-kubernetes.html>官方文件</a> ，寫得很簡易，如果已經很熟 kubernetes 的人可以直接腦補其他的部屬設定。</p><p>這邊有幾個做法，依照 filebeat 部署的位置與收集目標簡單分為：</p><ul><li>node: 處理每一台 node 的 log ，包含 system log 與 node 監測資料(metrics)</li><li>cluster: 處理 cluster 等級的 log, event 或是 metrics</li><li>pod: 針對特定 pod 直接去掛一個 sidecar</li></ul><p>上面的方法是可以混搭的，kubernetes 個個層級有<a href=https://kubernetes.io/docs/concepts/cluster-administration/logging/>log 處理流程</a>，我們這邊把 log 送往第三方平台，也是需要依照原本的 log 流程，去收取我們想收集的 log。</p><p>簡單來說，是去對的地方找對的 log。在架構上要注意 scalability 與 resource 分配，不要影響本身提供服務的 GKE ，但又能獲得盡量即時的 log。</p><p>我們這邊直接進入 kubernetes resource 的設定，底下會附上在 GKE 找 log 的過程。</p><h1 id=node-level-log-harvest>Node level log harvest<a hidden class=anchor aria-hidden=true href=#node-level-log-harvest>#</a></h1><p>為每一個 node 配置 filebeat，然後在 node 上面尋找 log，然後如我們上篇所敘述加到 input ，就可以把 log 倒出來。</p><p>直覺想到就是透過 daemonsets 為每個 node 部署一個 filebeat pod，然後 mount node 的 log 資料夾，在設置 input。</p><h1 id=deploy-daemonsets>Deploy daemonsets<a hidden class=anchor aria-hidden=true href=#deploy-daemonsets>#</a></h1><p>kubernetes resource 的 yaml 請參考 <a href=https://github.com/chechiachang/elk-kubernetes/tree/master/filebeat/7.3.1>我的 github elk-kubernetes</a></p><p>給予足夠的 clusterrolebinding 到 elk</p><pre><code>kubectl apply -f filebeat/7.3.1/clusterrolebinding.yaml
</code></pre><p>先更改 filebeat 的設定，如何設定 elasticsearch 與 kibana，請參考上篇。至於 input 的部份已經配置好了。</p><pre><code>vim filebeat/7.3.1/daemonsets-config-configmap.yaml

kubectl apply -f filebeat/7.3.1/daemonsets-config-configmap.yaml
</code></pre><p>部屬 filebeat daemonsets，會每一個 node 部屬一個 filebeat</p><pre><code>kubectl apply -f filebeat/7.3.1/daemonsets.yaml
</code></pre><p>取得 daemonsets 的狀態</p><pre><code>kubectl --namespcae elk get pods

NAME             READY   STATUS    RESTARTS   AGE
filebeat-bjfp9   1/1     Running   0          6m56s
filebeat-fzr9n   1/1     Running   0          6m56s
filebeat-vpkm7   1/1     Running   0          6m56s
...
</code></pre><p>有設定成功的話，kibana 這邊就會收到 kubernetes 上面 pod 的 log</p><h1 id=log-havest-for-specific-pods>log havest for specific pods<a hidden class=anchor aria-hidden=true href=#log-havest-for-specific-pods>#</a></h1><p>由於 kubernetes 上我們可以便利的調度 filebeat 的部屬方式，這邊也可以也可以使用 deployment ，配合 pod affinity，把 filebeat 放到某個想要監測的 pod，這邊的例子是 nginx-ingress-controller。</p><ul><li>Kubernetes 上有一個或多個 nginx ingress controller</li><li>部屬一個或多個 filebeat 到有 nginx 的 node 上</li><li>filebeat 去抓取 nginx 的 input， 並使用 filebeat 的 nginx module 做預處理<ul><li>nginx module 預設路徑需要調整，這邊使用 filebeat autodiscover 來處理</li></ul></li></ul><p>一樣 apply 前記得先檢查跟設定</p><pre><code>vim filebeat/7.3.1/nginx-config-configmap.yaml

kubectl apply -f filebeat/7.3.1/nginx-config-configmap.yaml
</code></pre><p>部屬 filebeat deployment
由於有設定 pod affinity ，這個 filebeat 只會被放到有 nginx ingress controller 的這個節點上，並且依照 autodiscover 設定的條件去蒐集 nginx 的 log</p><pre><code>kubectl apply -f filebeat/7.3.1/nginx-deployment.yaml
</code></pre><p>有設定成功的話，kibana 這邊就會收到 kubernetes 上面 pod 的 log</p><p>另外，由於有啟動 nginx module，logstash 收到的內容已經是處理過得內容。</p><hr><h1 id=gcp-fluentd>GCP fluentd<a hidden class=anchor aria-hidden=true href=#gcp-fluentd>#</a></h1><p>如果是使用 GKE 的朋友，可以投過開啟 stackdriver logging 的功能，把集群中服務的 log 倒到 stackdriver，基本上就是 node -> (daemonsets) fluentd -> stackdriver。</p><p>這個 fluentd 是 GCP 如果有啟動 Stackdriver Logging 的話，自動幫你維護的 daemonsets，設定不可改，改了會被 overwrite 會去，所以不太方便從這邊動手腳。</p><p>Btw stackdriver 最近好像改版，目前做 example 的版本已經變成 lagency （淚</p><p>但我們先假設我們對這個 pod 的 log 很有興趣，然後把這邊的 log 透過 filebeat 送到 ELK 上XD</p><p>因為 GKE 透過 fluentd 把 GKE 上面的 log 倒到 stackdriver，而我們是想把 log 倒到 ELK，既然這樣我們的 input 來源是相同的，而且很多處理步驟都可以在 ELK 上面互通，真的可以偷看一下 fluentd 是去哪收集 log ，怎麼處理 log pipeline，我們只要做相應設定就好。</p><p>畢竟 google 都幫我們弄得妥妥的，不參考一下他的流程太可惜。</p><p>偷看一下 GKE 上 fluentd 是去哪找 log ，這個是 <a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-gcp/fluentd-gcp-configmap.yaml>fluentd gcp configmap</a>，雖然看到這邊感覺扯遠了，但因為很有趣所有我就繼續看下去，各位大德可以跳過XD</p><p>configmap 中的這個 input 設定檔，其中一個 source 就是一個資料來源，相當於 filebeat 的 input。這邊這個 source 就是去 <code>/var/log/containers/*.log</code> 收 log</p><p>這邊還做了幾件事：</p><ul><li>打上 <code>reform.*</code> tag，讓下個 match 可以 收進去 pipeline 處理</li><li>附帶 parse 出 time</li></ul><pre><code>containers.input.conf

&lt;source&gt;
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/gcp-containers.log.pos
  # Tags at this point are in the format of:
  # reform.var.log.containers.&lt;POD_NAME&gt;_&lt;NAMESPACE_NAME&gt;_&lt;CONTAINER_NAME&gt;-&lt;CONTAINER_ID&gt;.log
  tag reform.*
  read_from_head true
  &lt;parse&gt;
    @type multi_format
    &lt;pattern&gt;
      format json
      time_key time
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    &lt;/pattern&gt;
    &lt;pattern&gt;
      format /^(?&lt;time&gt;.+) (?&lt;stream&gt;stdout|stderr) [^ ]* (?&lt;log&gt;.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    &lt;/pattern&gt;
  &lt;/parse&gt;
&lt;/source&gt;
</code></pre><p>他這邊做一些 error handling，然後用 ruby (!) parse，這邊就真的太遠，細節大家可以 google ＸＤ。不過這邊使用的 pattern matching 我們後幾篇在 logstash pipeline 上，也會有機會提到，機制是類似的。</p><pre><code>&lt;filter reform.**&gt;
  @type parser
  format /^(?&lt;severity&gt;\w)(?&lt;time&gt;\d{4} [^\s]*)\s+(?&lt;pid&gt;\d+)\s+(?&lt;source&gt;[^ \]]+)\] (?&lt;log&gt;.*)/
  reserve_data true
  suppress_parse_error_log true
  emit_invalid_record_to_error false
  key_name log
&lt;/filter&gt;

&lt;match reform.**&gt;
  @type record_reformer
  enable_ruby true
  &lt;record&gt;
    # Extract local_resource_id from tag for 'k8s_container' monitored
    # resource. The format is:
    # 'k8s_container.&lt;namespace_name&gt;.&lt;pod_name&gt;.&lt;container_name&gt;'.
    &quot;logging.googleapis.com/local_resource_id&quot; ${&quot;k8s_container.#{tag_suffix[4].rpartition('.')[0].split('_')[1]}.#{tag_suffix[4].rpartition('.')[0].split('_')[0]}.#{tag_suffix[4].rpartition('.')[0].split('_')[2].rpartition('-')[0]}&quot;}
    # Rename the field 'log' to a more generic field 'message'. This way the
    # fluent-plugin-google-cloud knows to flatten the field as textPayload
    # instead of jsonPayload after extracting 'time', 'severity' and
    # 'stream' from the record.
    message ${record['log']}
    # If 'severity' is not set, assume stderr is ERROR and stdout is INFO.
    severity ${record['severity'] || if record['stream'] == 'stderr' then 'ERROR' else 'INFO' end}
  &lt;/record&gt;
  tag ${if record['stream'] == 'stderr' then 'raw.stderr' else 'raw.stdout' end}
  remove_keys stream,log
&lt;/match&gt;
</code></pre><h3 id=ssh-進去逛>ssh 進去逛<a hidden class=anchor aria-hidden=true href=#ssh-進去逛>#</a></h3><p>想看機器上實際的 log 狀況，我們也可以直接 ssh 進去</p><p>先透過 kubectl 看一下 pod</p><pre><code>$ kubectl get daemonsets --namespace kube-system

NAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                                  AGE
fluentd-gcp-v3.2.0         7         7         7       7            7           beta.kubernetes.io/fluentd-ds-ready=true       196d

$ kubectl get pods --output wide --namespace kube-system

NAME                                      READY   STATUS    RESTARTS   AGE   IP          NODE                                     NOMINATED NODE   READINESS GATES
fluentd-gcp-scaler-1234567890-vfbhc       1/1     Running   0          37d   10.140.0.   gke-chechiachang-pool-1-123456789-5gqn   &lt;none&gt;           &lt;none&gt;
fluentd-gcp-v3.2.0-44tl7                  2/2     Running   0          37d   10.140.0.   gke-chechiachang-pool-1-123456789-wcq0   &lt;none&gt;           &lt;none&gt;
fluentd-gcp-v3.2.0-5vc6l                  2/2     Running   0          37d   10.140.0.   gke-chechiachang-pool-1-123456789-tp05   &lt;none&gt;           &lt;none&gt;
fluentd-gcp-v3.2.0-6rqvc                  2/2     Running   0          37d   10.140.0.   gke-chechiachang-pool-1-123456789-5gqn   &lt;none&gt;           &lt;none&gt;
fluentd-gcp-v3.2.0-mmwk4                  2/2     Running   0          37d   10.140.0.   gke-chechiachang-pool-1-123456789-vxld   &lt;none&gt;           &lt;none&gt;
</code></pre><p>先透過 kubectl 看一下 node</p><pre><code>$ kubectl get node

NAME                                     STATUS   ROLES    AGE   VERSION
gke-chechaichang-pool-1-123456789-3bzp   Ready    &lt;none&gt;   37d   v1.13.7-gke.8
gke-chechaichang-pool-1-123456789-5gqn   Ready    &lt;none&gt;   37d   v1.13.7-gke.8
gke-chechaichang-pool-1-123456789-8n8z   Ready    &lt;none&gt;   37d   v1.13.7-gke.8
...

gcloud compute ssh gke-chechaichang-pool-1-123456789-3bzp
</code></pre><p>如使用其他雲平台的 kubernetes service，或是 bare metal 的集群，請依照各自系統的方式連進去看看。</p><h1 id=ssh-node-找-log>ssh node 找 log<a hidden class=anchor aria-hidden=true href=#ssh-node-找-log>#</a></h1><p>ssh 進去後就可以到處來探險，順便看看 GKE 跑在機器上到底做了什麼事情。</p><p>如果官方有出文件，可能可以不用進來看。各位大德有發現文件請留言跟我說。我個人很喜歡自己架集群起來連就去看，面對照官方文件上寫的東西，當然大部份時候都是文件沒有帶到，有很多發現。</p><pre><code>$ ls /var/log

gcp-*-log.pos
kube-proxy.log
containers/
metrics/
pods/
...

</code></pre><p>/var/log/containers 看一下，格式是 <code>pod_namespace_container</code> 這邊是 link 到 /var/log/pods/</p><pre><code>$ ls -al /var/log/containers

lrwxrwxrwx 1 root root   105 Aug 12 07:42 fluentd-gcp-v3.2.0-st6cl_kube-system_fluentd-gcp-5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac.log -&gt; /var/log/pods/kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008/fluentd-gcp/0.log
</code></pre><p>看到 pods 就覺得是你了，裡面有 pod 資料夾，格式是 <code>namespace_pod_uuid</code></p><pre><code>ls /var/log/pods

default_pod-1-1234567890-fxxhp_uuid
kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008
kube-system_heapster-v1.6.0-beta.1-
kube-system_kube-proxy-gke-
kube-system_l7-default-backend-
kube-system_prometheus-to-sd-
</code></pre><p>再進去有 container log，格式是 <code>pod_namespace_container.log</code>，也是 link</p><pre><code>ls -al /var/log/pods/kube-system_fluentd-gcp-v3.2.0-st6cl_b76bed0b-bcd4-11e9-a55c-42010a8c0008/fluentd-gcp/

lrwxrwxrwx 1 root root  165 Aug 12 07:42 0.log -&gt; /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log
</code></pre><p>最終 link 到</p><pre><code>sudo su

$ ls -alh /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/
total 3.9M
drwx------  4 root root 4.0K Aug 12 07:42 .
drwx------ 92 root root  20K Sep 18 11:28 ..
-rw-r-----  1 root root 3.8M Sep 18 11:29 5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log
drwx------  2 root root 4.0K Aug 12 07:42 checkpoints
-rw-------  1 root root 7.8K Aug 12 07:42 config.v2.json
-rw-r--r--  1 root root 2.3K Aug 12 07:42 hostconfig.json
drwx------  2 root root 4.0K Aug 12 07:42 mounts
</code></pre><p>頭尾偷喵一下，確定是我們在找的東西</p><pre><code>head /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log
tail /var/lib/docker/containers/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac/5e38c9b63c8d767091b122a9aa48c576a88cc20b4470d9ca18a820afa5c168ac-json.log
</code></pre><p>這樣就找到我們的 log 了</p><h1 id=小節>小節<a hidden class=anchor aria-hidden=true href=#小節>#</a></h1><ul><li>使用 filebeat 去查找</li><li>透過 kubernetes daemonsets 可以快速佈置一份 filebeat 到所有 node，且設定都是一起更新</li><li>透過 kubernetes deployment 可以指定 filebeat 的位置，去跟隨想要監測的服務</li><li>如果不熟 log 處理流程，可以直接看偷看大廠的服務，會有很多靈感</li><li>沒事可以多跑進 Kubernetes 服務節點逛逛，有很多有趣的東西</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://chechia.net/tags/%E9%90%B5%E4%BA%BA%E8%B3%BD2019/>鐵人賽2019</a></li><li><a href=https://chechia.net/tags/kubernetes/>Kubernetes</a></li><li><a href=https://chechia.net/tags/logstash/>Logstash</a></li><li><a href=https://chechia.net/tags/ithome/>Ithome</a></li><li><a href=https://chechia.net/tags/filebeat/>Filebeat</a></li><li><a href=https://chechia.net/tags/fluentd/>Fluentd</a></li></ul><nav class=paginav><a class=prev href=https://chechia.net/posts/2019-09-21-logstash-on-gke/><span class=title>« Prev</span><br><span>Logstash on GKE</span>
</a><a class=next href=https://chechia.net/posts/2019-09-18-monitoring-gce-with-elk/><span class=title>Next »</span><br><span>Monitoring GCE With ELK</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on x" href="https://x.com/intent/tweet/?text=Monitoring%20GKE%20With%20Elk&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f&amp;hashtags=%e9%90%b5%e4%ba%ba%e8%b3%bd2019%2ckubernetes%2clogstash%2cithome%2cfilebeat%2cfluentd"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f&amp;title=Monitoring%20GKE%20With%20Elk&amp;summary=Monitoring%20GKE%20With%20Elk&amp;source=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f&title=Monitoring%20GKE%20With%20Elk"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on whatsapp" href="https://api.whatsapp.com/send?text=Monitoring%20GKE%20With%20Elk%20-%20https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on telegram" href="https://telegram.me/share/url?text=Monitoring%20GKE%20With%20Elk&amp;url=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Monitoring GKE With Elk on ycombinator" href="https://news.ycombinator.com/submitlink?t=Monitoring%20GKE%20With%20Elk&u=https%3a%2f%2fchechia.net%2fposts%2f2019-09-19-monitoring-gke-with-elk%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://chechia.net/>Che-Chia Chang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>